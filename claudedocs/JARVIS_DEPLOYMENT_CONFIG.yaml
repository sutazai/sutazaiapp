# JARVIS Multi-Agent System - Complete Deployment Configuration
# Production-ready Docker Compose for full system deployment

version: '3.9'

networks:
  sutazai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres-data:
  redis-data:
  neo4j-data:
  chromadb-data:
  qdrant-data:
  rabbitmq-data:
  consul-data:
  kong-data:
  prometheus-data:
  grafana-data:
  loki-data:
  jarvis-models:
  agent-workspaces:
  voice-recordings:

services:
  # ===========================================
  # CORE INFRASTRUCTURE (10000-10099)
  # ===========================================
  
  postgres:
    image: postgres:16-alpine
    container_name: sutazai-postgres
    environment:
      POSTGRES_DB: jarvis_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jarvis_secure_2025}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
    ports:
      - "10000:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts/postgres:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    networks:
      - sutazai-network

  redis:
    image: redis:7-alpine
    container_name: sutazai-redis
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --requirepass ${REDIS_PASSWORD:-jarvis_redis_2025}
    ports:
      - "10001:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M
    networks:
      - sutazai-network

  neo4j:
    image: neo4j:5-community
    container_name: sutazai-neo4j
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-jarvis_neo4j_2025}
      NEO4J_dbms_memory_heap_max__size: 512M
      NEO4J_dbms_memory_pagecache_size: 256M
    ports:
      - "10002:7474"  # HTTP
      - "10003:7687"  # Bolt
    volumes:
      - neo4j-data:/data
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "${NEO4J_PASSWORD:-jarvis_neo4j_2025}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: sutazai-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-jarvis_rabbit_2025}
    ports:
      - "10007:5672"   # AMQP
      - "10008:15672"  # Management UI
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    networks:
      - sutazai-network

  # ===========================================
  # SERVICE MESH (10050-10099)
  # ===========================================

  kong:
    image: kong:3.5-alpine
    container_name: sutazai-kong
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /kong/kong.yml
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
    ports:
      - "10005:8000"  # Proxy
      - "10006:8001"  # Admin API
    volumes:
      - ./config/kong:/kong
      - kong-data:/usr/local/kong
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - consul
    networks:
      - sutazai-network

  consul:
    image: consul:1.17
    container_name: sutazai-consul
    command: agent -server -bootstrap -ui -client=0.0.0.0
    ports:
      - "10015:8500"  # HTTP API/UI
      - "10016:8600"  # DNS
    volumes:
      - consul-data:/consul/data
      - ./config/consul:/consul/config
    healthcheck:
      test: ["CMD", "consul", "members"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - sutazai-network

  # ===========================================
  # VECTOR DATABASES (10100-10199)
  # ===========================================

  chromadb:
    image: chromadb/chroma:latest
    container_name: sutazai-chromadb
    environment:
      CHROMA_SERVER_AUTH_CREDENTIALS: ${CHROMA_TOKEN:-jarvis_chroma_2025}
      CHROMA_SERVER_AUTH_PROVIDER: "token"
    ports:
      - "10100:8000"
    volumes:
      - chromadb-data:/chroma/chroma
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  qdrant:
    image: qdrant/qdrant:latest
    container_name: sutazai-qdrant
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
    ports:
      - "10101:6333"  # HTTP
      - "10102:6334"  # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  # ===========================================
  # MONITORING STACK (10200-10299)
  # ===========================================

  prometheus:
    image: prom/prometheus:latest
    container_name: sutazai-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "10200:9090"
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sutazai-network

  grafana:
    image: grafana/grafana:latest
    container_name: sutazai-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-jarvis_grafana_2025}
      GF_INSTALL_PLUGINS: redis-datasource,redis-app
    ports:
      - "10201:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - prometheus
    networks:
      - sutazai-network

  loki:
    image: grafana/loki:latest
    container_name: sutazai-loki
    command: -config.file=/etc/loki/loki.yml
    ports:
      - "10202:3100"
    volumes:
      - ./config/loki:/etc/loki
      - loki-data:/loki
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sutazai-network

  # ===========================================
  # OLLAMA & MODEL SERVICE (10300-10399)
  # ===========================================

  ollama:
    image: ollama/ollama:latest
    container_name: sutazai-ollama
    ports:
      - "10104:11434"
    volumes:
      - jarvis-models:/root/.ollama
      - ./scripts/models:/models
    environment:
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_MODELS: /root/.ollama/models
      OLLAMA_NUM_PARALLEL: 2
      OLLAMA_MAX_LOADED_MODELS: 2
      OLLAMA_KEEP_ALIVE: 5m
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    networks:
      - sutazai-network

  # ===========================================
  # JARVIS CORE SERVICES (11320-11399)
  # ===========================================

  jarvis-core:
    build:
      context: ./services/jarvis-core
      dockerfile: Dockerfile
    image: sutazai/jarvis-core:latest
    container_name: sutazai-jarvis-core
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: jarvis_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jarvis_secure_2025}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-jarvis_redis_2025}
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-jarvis_neo4j_2025}
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: admin
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD:-jarvis_rabbit_2025}
      OLLAMA_HOST: http://ollama:11434
      KONG_ADMIN_URL: http://kong:8001
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      LOG_LEVEL: INFO
    ports:
      - "11321:8000"  # Main JARVIS API
      - "11322:8001"  # WebSocket endpoint
    volumes:
      - ./services/jarvis-core:/app
      - jarvis-models:/models
      - voice-recordings:/voice
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      ollama:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    networks:
      - sutazai-network

  jarvis-voice:
    build:
      context: ./services/jarvis-voice
      dockerfile: Dockerfile
    image: sutazai/jarvis-voice:latest
    container_name: sutazai-jarvis-voice
    environment:
      JARVIS_CORE_URL: http://jarvis-core:8000
      WHISPER_MODEL: tiny
      TTS_ENGINE: pyttsx3
      SAMPLE_RATE: 16000
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-jarvis_redis_2025}
    ports:
      - "11323:8000"  # Voice processing API
    volumes:
      - voice-recordings:/recordings
      - jarvis-models:/models
    devices:
      - /dev/snd:/dev/snd  # Audio device access
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-core
      - redis
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  jarvis-orchestrator:
    build:
      context: ./services/jarvis-orchestrator
      dockerfile: Dockerfile
    image: sutazai/jarvis-orchestrator:latest
    container_name: sutazai-jarvis-orchestrator
    environment:
      JARVIS_CORE_URL: http://jarvis-core:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: admin
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD:-jarvis_rabbit_2025}
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: jarvis_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jarvis_secure_2025}
      MAX_CONCURRENT_AGENTS: 5
    ports:
      - "11324:8000"  # Orchestrator API
    volumes:
      - agent-workspaces:/workspaces
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-core
      - consul
      - rabbitmq
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  # ===========================================
  # AI AGENTS (11400-11599)
  # ===========================================

  letta-agent:
    build:
      context: ./agents/letta
      dockerfile: Dockerfile
    image: sutazai/letta-agent:latest
    container_name: sutazai-letta-agent
    environment:
      AGENT_NAME: letta
      ORCHESTRATOR_URL: http://jarvis-orchestrator:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: tinyllama
    ports:
      - "11400:8000"
    volumes:
      - agent-workspaces/letta:/workspace
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-orchestrator
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  autogpt-agent:
    build:
      context: ./agents/autogpt
      dockerfile: Dockerfile
    image: sutazai/autogpt-agent:latest
    container_name: sutazai-autogpt-agent
    environment:
      AGENT_NAME: autogpt
      ORCHESTRATOR_URL: http://jarvis-orchestrator:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      CHROMADB_HOST: chromadb
      CHROMADB_PORT: 8000
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: tinyllama
    ports:
      - "11401:8000"
    volumes:
      - agent-workspaces/autogpt:/workspace
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-orchestrator
      - chromadb
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  crewai-agent:
    build:
      context: ./agents/crewai
      dockerfile: Dockerfile
    image: sutazai/crewai-agent:latest
    container_name: sutazai-crewai-agent
    environment:
      AGENT_NAME: crewai
      ORCHESTRATOR_URL: http://jarvis-orchestrator:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: qwen3:0.5b
    ports:
      - "11402:8000"
    volumes:
      - agent-workspaces/crewai:/workspace
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-orchestrator
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  agent-zero:
    build:
      context: ./agents/agent-zero
      dockerfile: Dockerfile
    image: sutazai/agent-zero:latest
    container_name: sutazai-agent-zero
    environment:
      AGENT_NAME: agent-zero
      ORCHESTRATOR_URL: http://jarvis-orchestrator:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-jarvis_neo4j_2025}
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: qwen3:0.5b
    ports:
      - "11403:8000"
    volumes:
      - agent-workspaces/agent-zero:/workspace
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-orchestrator
      - neo4j
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  gpt-engineer-agent:
    build:
      context: ./agents/gpt-engineer
      dockerfile: Dockerfile
    image: sutazai/gpt-engineer-agent:latest
    container_name: sutazai-gpt-engineer-agent
    environment:
      AGENT_NAME: gpt-engineer
      ORCHESTRATOR_URL: http://jarvis-orchestrator:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      OLLAMA_HOST: http://ollama:11434
      MODEL_NAME: qwen3:0.5b
      CODE_EXECUTION: sandboxed
    ports:
      - "11404:8000"
    volumes:
      - agent-workspaces/gpt-engineer:/workspace
      - /var/run/docker.sock:/var/run/docker.sock:ro  # For code execution
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-orchestrator
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  # ===========================================
  # DOCKER-IN-DOCKER ORCHESTRATOR (11600-11699)
  # ===========================================

  dind-orchestrator:
    image: docker:24-dind
    container_name: sutazai-dind-orchestrator
    privileged: true
    environment:
      DOCKER_TLS_CERTDIR: ""
    ports:
      - "11600:2375"  # Docker API
    volumes:
      - /var/lib/docker
      - agent-workspaces:/workspaces
    healthcheck:
      test: ["CMD", "docker", "info"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sutazai-network

  # ===========================================
  # UI SERVICES (10010-10020)
  # ===========================================

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: sutazai/backend:latest
    container_name: sutazai-backend
    environment:
      JARVIS_CORE_URL: http://jarvis-core:8000
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: jarvis_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jarvis_secure_2025}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-jarvis_redis_2025}
      KONG_PROXY_URL: http://kong:8000
      CONSUL_HOST: consul
      CONSUL_PORT: 8500
    ports:
      - "10010:8000"
    volumes:
      - ./backend:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - jarvis-core
      - postgres
      - redis
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - sutazai-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: sutazai/frontend:latest
    container_name: sutazai-frontend
    environment:
      BACKEND_URL: http://backend:8000
      JARVIS_WS_URL: ws://jarvis-core:8001
    ports:
      - "10011:8501"
    volumes:
      - ./frontend:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      - backend
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    networks:
      - sutazai-network

  # ===========================================
  # MANAGEMENT UI (11700)
  # ===========================================

  portainer:
    image: portainer/portainer-ce:latest
    container_name: sutazai-portainer
    ports:
      - "11700:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer-data:/data
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9000"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - sutazai-network

volumes:
  portainer-data: