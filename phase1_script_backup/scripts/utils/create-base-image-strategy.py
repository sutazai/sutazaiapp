#!/usr/bin/env python3
"""
Purpose: Create shared base image strategy for SutazAI container optimization
Usage: python create-base-image-strategy.py [--execute]
Requirements: Python 3.8+, Docker

Creates shared base images to reduce redundancy and improve build times.
Based on the analysis showing 54 identical requirements files.
"""

import os
import sys
import json
import logging
import shutil
import datetime
from pathlib import Path
from typing import Dict, List, Set
import subprocess

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class BaseImageStrategy:
    def __init__(self, project_root: str = "/opt/sutazaiapp"):
        self.project_root = Path(project_root)
        self.strategy = {}
        
    def analyze_common_dependencies(self) -> Dict:
        """Analyze the common dependencies from the health-monitor requirements"""
        health_monitor_req = self.project_root / "agents/health-monitor/requirements.txt"
        
        if not health_monitor_req.exists():
            logger.error("Health monitor requirements not found")
            return {}
            
        # This file is used by 54 agents according to our analysis
        common_deps = []
        try:
            with open(health_monitor_req) as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        common_deps.append(line)
        except Exception as e:
            logger.error(f"Could not read {health_monitor_req}: {e}")
            return {}
            
        return {
            'base_requirements_file': str(health_monitor_req),
            'dependencies': common_deps,
            'used_by_agents': 54  # From our analysis
        }
        
    def create_base_dockerfiles(self) -> Dict[str, str]:
        """Create optimized base Dockerfiles"""
        
        base_dockerfiles = {}
        
        # 1. Python Agent Base
        python_agent_base = """FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    curl \\
    git \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Copy and install common Python requirements
COPY base-requirements.txt .
RUN pip install --no-cache-dir -r base-requirements.txt

# Create agent user for security
RUN groupadd -r agent && useradd -r -g agent agent
RUN chown -R agent:agent /app

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

USER agent

# Default command
CMD ["python", "app.py"]
"""
        base_dockerfiles['python-agent-base'] = python_agent_base
        
        # 2. Node.js Base (for flowise, n8n, etc.)
        nodejs_base = """FROM node:18-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    python3 \\
    python3-pip \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Create app user
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app

USER appuser

EXPOSE 3000

CMD ["npm", "start"]
"""
        base_dockerfiles['nodejs-base'] = nodejs_base
        
        # 3. Monitoring Base (Prometheus, Grafana, etc.)
        monitoring_base = """FROM alpine:3.18

# Install common monitoring tools
RUN apk add --no-cache \\
    ca-certificates \\
    curl \\
    bash \\
    tzdata

# Create monitoring user
RUN addgroup -g 1000 monitoring && \\
    adduser -D -u 1000 -G monitoring monitoring

USER monitoring

WORKDIR /app
"""
        base_dockerfiles['monitoring-base'] = monitoring_base
        
        # 4. GPU-enabled Python base
        gpu_base = """FROM nvidia/cuda:11.8-runtime-ubuntu20.04

ENV DEBIAN_FRONTEND=noninteractive

# Install Python and system dependencies
RUN apt-get update && apt-get install -y \\
    python3.11 \\
    python3-pip \\
    python3.11-dev \\
    git \\
    curl \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Create symbolic links
RUN ln -s /usr/bin/python3.11 /usr/bin/python

WORKDIR /app

# Copy GPU-optimized requirements
COPY gpu-requirements.txt .
RUN pip install --no-cache-dir -r gpu-requirements.txt

# Create user
RUN groupadd -r gpuuser && useradd -r -g gpuuser gpuuser
RUN chown -R gpuuser:gpuuser /app

USER gpuuser

ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

CMD ["python", "app.py"]
"""
        base_dockerfiles['gpu-python-base'] = gpu_base
        
        return base_dockerfiles
        
    def create_requirements_hierarchy(self) -> Dict[str, List[str]]:
        """Create a hierarchy of requirements files"""
        
        requirements_hierarchy = {
            'base-requirements.txt': [
                # Core Python packages that most agents need
                'fastapi==0.104.1',
                'uvicorn==0.24.0',
                'pydantic==2.5.0',
                'httpx==0.25.2',
                'python-dotenv==1.0.0',
                'loguru==0.7.2',
                'redis==5.0.1',
                'psycopg2-binary==2.9.9',
                'sqlalchemy==2.0.23',
                'alembic==1.13.1'
            ],
            
            'ai-requirements.txt': [
                # Common AI/ML packages
                'openai==1.3.0',
                'langchain==0.0.350',
                'chromadb',
                'sentence-transformers==2.2.2',
                'numpy==1.24.3',
                'pandas==2.0.3'
            ],
            
            'gpu-requirements.txt': [
                # GPU-optimized packages
                'torch==2.1.0+cu118',
                'torchvision==0.16.0+cu118',
                'tensorflow-gpu==2.14.0',
                'transformers==4.36.0',
                'accelerate==0.25.0'
            ],
            
            'monitoring-requirements.txt': [
                # Monitoring and observability
                'prometheus-client==0.19.0',
                'grafana-api==1.0.3',
                'elasticsearch==8.11.0',
                'py-healthcheck==1.10.1'
            ]
        }
        
        return requirements_hierarchy
        
    def generate_optimized_dockerfiles(self) -> Dict[str, str]:
        """Generate optimized Dockerfiles using base images"""
        
        optimized_dockerfiles = {}
        
        # Example: Optimized agent Dockerfile
        agent_template = """FROM sutazai/python-agent-base:latest

# Copy agent-specific requirements (if any)
COPY requirements-extra.txt* ./
RUN if [ -f requirements-extra.txt ]; then pip install --no-cache-dir -r requirements-extra.txt; fi

# Copy application code
COPY --chown=agent:agent . .

# Agent-specific setup
RUN if [ -f setup.sh ]; then bash setup.sh; fi

EXPOSE 8000

CMD ["python", "app.py"]
"""
        optimized_dockerfiles['agent-template'] = agent_template
        
        # Example: Optimized service Dockerfile
        service_template = """FROM sutazai/nodejs-base:latest

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy application code
COPY --chown=appuser:appuser . .

# Service-specific build
RUN if [ -f build.sh ]; then bash build.sh; fi

EXPOSE 3000

CMD ["npm", "start"]
"""
        optimized_dockerfiles['service-template'] = service_template
        
        return optimized_dockerfiles
        
    def create_build_system(self) -> Dict[str, str]:
        """Create automated build system for base images"""
        
        build_scripts = {}
        
        # Main build script
        main_build = """#!/bin/bash
set -e

# Build SutazAI base images
echo "ðŸ—ï¸  Building SutazAI base images..."

# Build Python agent base
echo "Building python-agent-base..."
docker build -t sutazai/python-agent-base:latest -f docker/base/Dockerfile.python-agent-base docker/base/

# Build Node.js base  
echo "Building nodejs-base..."
docker build -t sutazai/nodejs-base:latest -f docker/base/Dockerfile.nodejs-base docker/base/

# Build monitoring base
echo "Building monitoring-base..."
docker build -t sutazai/monitoring-base:latest -f docker/base/Dockerfile.monitoring-base docker/base/

# Build GPU base (if NVIDIA runtime available)
if docker info | grep -q nvidia; then
    echo "Building gpu-python-base..."
    docker build -t sutazai/gpu-python-base:latest -f docker/base/Dockerfile.gpu-python-base docker/base/
else
    echo "âš ï¸  NVIDIA runtime not available, skipping GPU base image"
fi

echo "âœ… Base images built successfully!"

# Tag with version
VERSION=${1:-latest}
if [ "$VERSION" != "latest" ]; then
    docker tag sutazai/python-agent-base:latest sutazai/python-agent-base:$VERSION
    docker tag sutazai/nodejs-base:latest sutazai/nodejs-base:$VERSION
    docker tag sutazai/monitoring-base:latest sutazai/monitoring-base:$VERSION
    if docker info | grep -q nvidia; then
        docker tag sutazai/gpu-python-base:latest sutazai/gpu-python-base:$VERSION
    fi
fi

echo "ðŸŽ¯ Base images ready for use!"
"""
        build_scripts['build-base-images.sh'] = main_build
        
        # Update script for existing Dockerfiles
        update_script = """#!/bin/bash
set -e

echo "ðŸ”„ Updating existing Dockerfiles to use base images..."

# Find all agent Dockerfiles and update them
find agents/ -name "Dockerfile" -type f | while read dockerfile; do
    if grep -q "FROM python:" "$dockerfile"; then
        echo "Updating $dockerfile to use python-agent-base"
        # Backup original
        cp "$dockerfile" "$dockerfile.backup"
        
        # Replace FROM line and optimize
        sed -e 's|FROM python:.*|FROM sutazai/python-agent-base:latest|' \\
            -e '/RUN apt-get update/,/rm -rf \/var\/lib\/apt\/lists\*/d' \\
            -e '/RUN pip install.*fastapi\|uvicorn\|pydantic/d' \\
            "$dockerfile.backup" > "$dockerfile"
            
        echo "âœ… Updated $dockerfile"
    fi
done

echo "ðŸŽ¯ Dockerfile updates complete!"
"""
        build_scripts['update-dockerfiles.sh'] = update_script
        
        return build_scripts
        
    def estimate_savings(self) -> Dict:
        """Estimate storage and build time savings"""
        
        # Based on our analysis
        current_stats = {
            'total_dockerfiles': 125,
            'duplicate_requirements': 54,  # All using health-monitor requirements
            'total_requirements_files': 142,
            'exact_duplicates': 7,
            'avg_build_time_per_agent': 120,  # seconds
            'avg_image_size': 800  # MB
        }
        
        optimized_stats = {
            'base_images': 4,
            'unique_requirements_files': 142 - 54,  # Remove 54 duplicates
            'estimated_build_time_reduction': 0.6,  # 60% faster due to cached layers
            'estimated_size_reduction': 0.4,  # 40% smaller due to shared base
        }
        
        savings = {
            'build_time_saved_per_agent': current_stats['avg_build_time_per_agent'] * optimized_stats['estimated_build_time_reduction'],
            'total_build_time_saved': current_stats['total_dockerfiles'] * current_stats['avg_build_time_per_agent'] * optimized_stats['estimated_build_time_reduction'],
            'storage_saved_per_image': current_stats['avg_image_size'] * optimized_stats['estimated_size_reduction'],
            'total_storage_saved': current_stats['total_dockerfiles'] * current_stats['avg_image_size'] * optimized_stats['estimated_size_reduction'],
            'requirements_files_removed': 54,
            'maintenance_complexity_reduction': '70%'
        }
        
        return {
            'current': current_stats,
            'optimized': optimized_stats,
            'savings': savings
        }
        
    def create_implementation_plan(self) -> Dict:
        """Create phased implementation plan"""
        
        phases = {
            'phase_1_preparation': {
                'description': 'Prepare base images and requirements',
                'tasks': [
                    'Create /docker/base/ directory structure',
                    'Generate base requirements files',
                    'Create base Dockerfiles',
                    'Set up build scripts'
                ],
                'risk': 'low',
                'estimated_time': '2 hours'
            },
            
            'phase_2_base_build': {
                'description': 'Build and test base images',
                'tasks': [
                    'Build all base images locally',
                    'Test base images can start successfully',
                    'Verify all common dependencies work',
                    'Tag and prepare for distribution'
                ],
                'risk': 'low',
                'estimated_time': '1 hour'
            },
            
            'phase_3_pilot_migration': {
                'description': 'Migrate 5 non-critical agents as pilot',
                'tasks': [
                    'Select 5 agents using health-monitor requirements',
                    'Update their Dockerfiles to use base image',
                    'Remove duplicate requirements files',
                    'Test builds and functionality'
                ],
                'risk': 'medium',
                'estimated_time': '3 hours'
            },
            
            'phase_4_bulk_migration': {
                'description': 'Migrate remaining 49 agents with identical requirements',
                'tasks': [
                    'Run automated Dockerfile updates',
                    'Remove 49 duplicate requirements files',
                    'Batch test all builds',
                    'Verify no functionality regression'
                ],
                'risk': 'medium',
                'estimated_time': '4 hours'
            },
            
            'phase_5_optimization': {
                'description': 'Optimize other services and final cleanup',
                'tasks': [
                    'Migrate Node.js services to nodejs-base',
                    'Update monitoring services',
                    'Clean up old base images in /docker/base/',
                    'Update CI/CD to use new base images'
                ],
                'risk': 'low',
                'estimated_time': '2 hours'
            }
        }
        
        return phases
        
    def generate_rollback_plan(self) -> Dict:
        """Generate comprehensive rollback plan"""
        
        rollback = {
            'backup_strategy': {
                'dockerfile_backups': 'All Dockerfiles backed up with .backup extension',
                'requirements_backup': 'Full backup in /archive/base_image_migration_TIMESTAMP/',
                'image_backups': 'Docker save for all current images before changes'
            },
            
            'rollback_steps': [
                'Stop all running containers',
                'Restore all Dockerfile.backup files',
                'Restore requirements files from archive',
                'Rebuild affected images',
                'Restart services',
                'Verify functionality'
            ],
            
            'validation_commands': [
                'docker-compose build --no-cache',
                'docker-compose up -d',
                'python scripts/validate-container-infrastructure.py --critical-only',
                'curl health check endpoints'
            ]
        }
        
        return rollback
        
    def execute_strategy(self, execute: bool = False) -> Dict:
        """Execute the base image strategy"""
        
        logger.info("ðŸš€ Creating base image optimization strategy...")
        
        # Analyze current state
        common_deps = self.analyze_common_dependencies()
        
        # Generate artifacts
        base_dockerfiles = self.create_base_dockerfiles()
        requirements_hierarchy = self.create_requirements_hierarchy()
        optimized_dockerfiles = self.generate_optimized_dockerfiles()
        build_scripts = self.create_build_system()
        
        # Calculate savings
        savings_analysis = self.estimate_savings()
        
        # Create implementation plan
        implementation_plan = self.create_implementation_plan()
        rollback_plan = self.generate_rollback_plan()
        
        strategy = {
            'timestamp': datetime.datetime.now().isoformat(),
            'common_dependencies': common_deps,
            'base_dockerfiles': base_dockerfiles,
            'requirements_hierarchy': requirements_hierarchy,
            'optimized_dockerfiles': optimized_dockerfiles,
            'build_scripts': build_scripts,
            'savings_analysis': savings_analysis,
            'implementation_plan': implementation_plan,
            'rollback_plan': rollback_plan
        }
        
        if execute:
            logger.info("âš¡ EXECUTING base image strategy creation...")
            self._create_base_image_files(strategy)
        else:
            logger.info("ðŸ§ª DRY RUN - Strategy created but not executed")
            
        return strategy
        
    def _create_base_image_files(self, strategy: Dict):
        """Create the actual base image files"""
        
        base_dir = self.project_root / "docker/base"
        base_dir.mkdir(parents=True, exist_ok=True)
        
        # Create Dockerfiles
        for name, content in strategy['base_dockerfiles'].items():
            dockerfile_path = base_dir / f"Dockerfile.{name}"
            with open(dockerfile_path, 'w') as f:
                f.write(content)
            logger.info(f"âœ… Created {dockerfile_path}")
            
        # Create requirements files
        for name, deps in strategy['requirements_hierarchy'].items():
            req_path = base_dir / name
            with open(req_path, 'w') as f:
                f.write('\n'.join(deps) + '\n')
            logger.info(f"âœ… Created {req_path}")
            
        # Create build scripts
        scripts_dir = self.project_root / "scripts"
        for name, content in strategy['build_scripts'].items():
            script_path = scripts_dir / name
            with open(script_path, 'w') as f:
                f.write(content)
            script_path.chmod(0o755)
            logger.info(f"âœ… Created {script_path}")
            
        logger.info("ðŸŽ¯ Base image strategy files created successfully!")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Create base image optimization strategy")
    parser.add_argument("--execute", action="store_true",
                       help="Execute strategy creation (create files)")
    parser.add_argument("--report-format", choices=["json", "markdown"],
                       default="json", help="Report format")
    
    args = parser.parse_args()
    
    # Ensure directories exist
    os.makedirs("/opt/sutazaiapp/reports", exist_ok=True)
    
    try:
        strategy_creator = BaseImageStrategy()
        strategy = strategy_creator.execute_strategy(execute=args.execute)
        
        # Save report
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"/opt/sutazaiapp/reports/base_image_strategy_{timestamp}.json"
        
        with open(report_path, 'w') as f:
            json.dump(strategy, f, indent=2, default=str)
            
        # Print summary
        savings = strategy['savings_analysis']['savings']
        
        print(f"\nðŸ“Š Base Image Strategy Summary")
        print(f"{'='*50}")
        print(f"Requirements Files to Remove: {savings['requirements_files_removed']}")
        print(f"Build Time Saved per Agent: {savings['build_time_saved_per_agent']:.0f}s")
        print(f"Total Build Time Saved: {savings['total_build_time_saved']/60:.0f} minutes")
        print(f"Storage Saved per Image: {savings['storage_saved_per_image']:.0f}MB")
        print(f"Total Storage Saved: {savings['total_storage_saved']/1024:.1f}GB")
        print(f"Maintenance Complexity Reduction: {savings['maintenance_complexity_reduction']}")
        
        print(f"\nðŸš€ Implementation Phases:")
        for phase_name, phase_info in strategy['implementation_plan'].items():
            print(f"  {phase_name}: {phase_info['estimated_time']} ({phase_info['risk']} risk)")
            
        print(f"\nðŸ“„ Strategy report: {report_path}")
        
        if args.execute:
            print(f"\nâœ… Base image files created!")
            print(f"Next step: cd docker/base && bash ../../scripts/build-base-images.sh")
        else:
            print(f"\nðŸ§ª This was a DRY RUN. Use --execute to create files.")
            
    except Exception as e:
        logger.error(f"Strategy creation failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()