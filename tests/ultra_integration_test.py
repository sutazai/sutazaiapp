#!/usr/bin/env python3
"""
ULTRA Integration Test Suite
End-to-end integration testing across all system components
Target: 100% service integration, zero failures, complete workflow validation
"""

import asyncio
import aiohttp
import json
import time
import logging
import sys
import os
import subprocess
import psycopg2
import redis
import requests
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
import uuid
import hashlib

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/opt/sutazaiapp/tests/ultra_integration_test.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class IntegrationTestResult:
    """Store integration test results"""
    test_name: str
    category: str
    status: str  # PASS, FAIL, SKIP, ERROR
    description: str
    execution_time: float
    details: Dict[str, Any]
    error_message: Optional[str] = None

@dataclass
class ServiceStatus:
    """Service health status"""
    name: str
    url: str
    status: str
    response_time: float
    version: Optional[str] = None
    dependencies: List[str] = None

class UltraIntegrationTester:
    """Comprehensive integration testing system"""
    
    def __init__(self):
        self.base_url = "http://localhost"
        self.test_results: List[IntegrationTestResult] = []
        self.service_status: List[ServiceStatus] = []
        
        # Core services to test
        self.services = {
            "backend": {"url": f"{self.base_url}:10010", "critical": True, "health_endpoint": "/health"},
            "frontend": {"url": f"{self.base_url}:10011", "critical": True, "health_endpoint": "/"},
            "ollama": {"url": f"{self.base_url}:10104", "critical": True, "health_endpoint": "/api/tags"},
            "postgres": {"url": f"{self.base_url}:10000", "critical": True, "health_endpoint": None},
            "redis": {"url": f"{self.base_url}:10001", "critical": True, "health_endpoint": None},
            "rabbitmq": {"url": f"{self.base_url}:10008", "critical": True, "health_endpoint": "/"},
            "neo4j": {"url": f"{self.base_url}:10002", "critical": True, "health_endpoint": "/"},
            "qdrant": {"url": f"{self.base_url}:10101", "critical": False, "health_endpoint": "/"},
            "chromadb": {"url": f"{self.base_url}:10100", "critical": False, "health_endpoint": "/api/v1/heartbeat"},
            "faiss": {"url": f"{self.base_url}:10103", "critical": False, "health_endpoint": "/health"},
            "grafana": {"url": f"{self.base_url}:10201", "critical": False, "health_endpoint": "/api/health"},
            "prometheus": {"url": f"{self.base_url}:10200", "critical": False, "health_endpoint": "/-/healthy"},
            "ai_orchestrator": {"url": f"{self.base_url}:8589", "critical": True, "health_endpoint": "/health"},
            "ollama_integration": {"url": f"{self.base_url}:8090", "critical": True, "health_endpoint": "/health"},
            "hardware_optimizer": {"url": f"{self.base_url}:11110", "critical": True, "health_endpoint": "/health"},
            "resource_arbitration": {"url": f"{self.base_url}:8588", "critical": True, "health_endpoint": "/health"},
            "task_coordinator": {"url": f"{self.base_url}:8551", "critical": True, "health_endpoint": "/health"}
        }
        
        # Database connection parameters
        self.db_config = {
            "host": "localhost",
            "port": 10000,
            "database": "sutazai",
            "user": "sutazai",
            "password": "sutazai_password"
        }
        
        self.redis_config = {
            "host": "localhost",
            "port": 10001,
            "db": 0
        }
    
    def add_result(self, test_name: str, category: str, status: str, description: str,
                   execution_time: float, details: Dict[str, Any], error_message: str = None):
        """Add test result"""
        result = IntegrationTestResult(
            test_name=test_name,
            category=category,
            status=status,
            description=description,
            execution_time=execution_time,
            details=details,
            error_message=error_message
        )
        self.test_results.append(result)
        
        if status == "FAIL":
            logger.error(f"INTEGRATION TEST FAILED: {test_name} - {description}")
        elif status == "PASS":
            logger.info(f"INTEGRATION TEST PASSED: {test_name}")
    
    async def test_service_health(self) -> None:
        """Test health of all services"""
        logger.info("ğŸ¥ Testing service health...")
        
        timeout = aiohttp.ClientTimeout(total=10)
        connector = aiohttp.TCPConnector(limit=20)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            tasks = []
            for service_name, config in self.services.items():
                task = self.check_service_health(session, service_name, config)
                tasks.append(task)
            
            # Execute all health checks concurrently
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            healthy_services = 0
            critical_failures = 0
            
            for i, result in enumerate(results):
                service_name = list(self.services.keys())[i]
                service_config = self.services[service_name]
                
                if isinstance(result, Exception):
                    status = ServiceStatus(
                        name=service_name,
                        url=service_config['url'],
                        status="ERROR",
                        response_time=0.0
                    )
                    self.service_status.append(status)
                    
                    if service_config['critical']:
                        critical_failures += 1
                        
                    self.add_result(
                        f"service_health_{service_name}",
                        "Service Health",
                        "FAIL",
                        f"Service {service_name} health check failed with exception",
                        0.0,
                        {"service": service_name, "error": str(result)}
                    )
                else:
                    self.service_status.append(result)
                    
                    if result.status == "HEALTHY":
                        healthy_services += 1
                        self.add_result(
                            f"service_health_{service_name}",
                            "Service Health",
                            "PASS",
                            f"Service {service_name} is healthy",
                            result.response_time,
                            {"service": service_name, "url": result.url, "response_time": result.response_time}
                        )
                    else:
                        if service_config['critical']:
                            critical_failures += 1
                            
                        self.add_result(
                            f"service_health_{service_name}",
                            "Service Health",
                            "FAIL",
                            f"Service {service_name} is unhealthy",
                            result.response_time,
                            {"service": service_name, "status": result.status, "url": result.url}
                        )
            
            # Overall health summary
            total_services = len(self.services)
            health_percentage = (healthy_services / total_services) * 100
            
            self.add_result(
                "overall_service_health",
                "Service Health",
                "PASS" if critical_failures == 0 else "FAIL",
                f"Overall service health: {healthy_services}/{total_services} services healthy",
                0.0,
                {
                    "healthy_services": healthy_services,
                    "total_services": total_services,
                    "health_percentage": health_percentage,
                    "critical_failures": critical_failures
                }
            )
    
    async def check_service_health(self, session: aiohttp.ClientSession, 
                                   service_name: str, config: Dict[str, Any]) -> ServiceStatus:
        """Check health of a single service"""
        start_time = time.time()
        url = config['url']
        health_endpoint = config.get('health_endpoint', '/')
        
        if health_endpoint:
            test_url = f"{url}{health_endpoint}"
        else:
            test_url = url
        
        try:
            async with session.get(test_url) as response:
                response_time = time.time() - start_time
                
                if response.status in [200, 201, 202]:
                    # Try to get version info if available
                    version = None
                    try:
                        if response.headers.get('content-type', '').startswith('application/json'):
                            data = await response.json()
                            version = data.get('version') or data.get('build_version')
                    except:
                        pass
                    
                    return ServiceStatus(
                        name=service_name,
                        url=url,
                        status="HEALTHY",
                        response_time=response_time,
                        version=version
                    )
                else:
                    return ServiceStatus(
                        name=service_name,
                        url=url,
                        status=f"UNHEALTHY_{response.status}",
                        response_time=response_time
                    )
                    
        except Exception as e:
            response_time = time.time() - start_time
            return ServiceStatus(
                name=service_name,
                url=url,
                status=f"ERROR: {str(e)[:50]}",
                response_time=response_time
            )
    
    def test_database_connectivity(self) -> None:
        """Test database connectivity and operations"""
        logger.info("ğŸ—„ï¸ Testing database connectivity...")
        
        # Test PostgreSQL
        start_time = time.time()
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # Test basic query
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            
            # Test table creation and operations
            test_table = f"integration_test_{uuid.uuid4().hex[:8]}"
            cursor.execute(f"""
                CREATE TABLE {test_table} (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    name VARCHAR(100),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Insert test data
            cursor.execute(f"INSERT INTO {test_table} (name) VALUES ('test_integration')")
            
            # Query test data
            cursor.execute(f"SELECT COUNT(*) FROM {test_table}")
            count = cursor.fetchone()[0]
            
            # Clean up
            cursor.execute(f"DROP TABLE {test_table}")
            
            conn.commit()
            conn.close()
            
            execution_time = time.time() - start_time
            
            self.add_result(
                "database_postgresql",
                "Database",
                "PASS",
                "PostgreSQL connectivity and operations successful",
                execution_time,
                {
                    "version": version[:50],
                    "operations": ["connect", "create_table", "insert", "select", "drop"],
                    "test_records": count
                }
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "database_postgresql",
                "Database",
                "FAIL",
                "PostgreSQL connectivity failed",
                execution_time,
                {"error": str(e)},
                str(e)
            )
        
        # Test Redis
        start_time = time.time()
        try:
            r = redis.Redis(**self.redis_config)
            
            # Test basic operations
            test_key = f"integration_test_{uuid.uuid4().hex[:8]}"
            test_value = "test_integration_value"
            
            # Set and get
            r.set(test_key, test_value)
            retrieved_value = r.get(test_key).decode('utf-8')
            
            # Test other operations
            r.lpush(f"{test_key}_list", "item1", "item2")
            list_length = r.llen(f"{test_key}_list")
            
            # Test hash operations
            r.hset(f"{test_key}_hash", "field1", "value1")
            hash_value = r.hget(f"{test_key}_hash", "field1").decode('utf-8')
            
            # Clean up
            r.delete(test_key, f"{test_key}_list", f"{test_key}_hash")
            
            execution_time = time.time() - start_time
            
            self.add_result(
                "database_redis",
                "Database",
                "PASS",
                "Redis connectivity and operations successful",
                execution_time,
                {
                    "operations": ["set", "get", "lpush", "llen", "hset", "hget"],
                    "test_value_match": retrieved_value == test_value,
                    "list_length": list_length,
                    "hash_value_match": hash_value == "value1"
                }
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "database_redis",
                "Database",
                "FAIL",
                "Redis connectivity failed",
                execution_time,
                {"error": str(e)},
                str(e)
            )
    
    async def test_api_endpoints(self) -> None:
        """Test critical API endpoints"""
        logger.info("ğŸ”Œ Testing API endpoints...")
        
        timeout = aiohttp.ClientTimeout(total=30)
        connector = aiohttp.TCPConnector(limit=10)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            
            # Test backend API endpoints
            backend_endpoints = [
                {"path": "/health", "method": "GET", "expected_status": 200},
                {"path": "/metrics", "method": "GET", "expected_status": 200},
                {"path": "/api/v1/models/", "method": "GET", "expected_status": 200},
                {"path": "/docs", "method": "GET", "expected_status": 200}
            ]
            
            for endpoint in backend_endpoints:
                await self.test_api_endpoint(
                    session, 
                    f"{self.base_url}:10010{endpoint['path']}",
                    endpoint['method'],
                    endpoint['expected_status'],
                    f"backend_{endpoint['path'].replace('/', '_')}"
                )
            
            # Test Ollama endpoints
            ollama_endpoints = [
                {"path": "/api/tags", "method": "GET", "expected_status": 200},
                {"path": "/api/version", "method": "GET", "expected_status": 200}
            ]
            
            for endpoint in ollama_endpoints:
                await self.test_api_endpoint(
                    session,
                    f"{self.base_url}:10104{endpoint['path']}",
                    endpoint['method'],
                    endpoint['expected_status'],
                    f"ollama_{endpoint['path'].replace('/', '_')}"
                )
            
            # Test agent service endpoints
            agent_endpoints = [
                {"service": "ai_orchestrator", "port": 8589},
                {"service": "ollama_integration", "port": 8090},
                {"service": "hardware_optimizer", "port": 11110},
                {"service": "resource_arbitration", "port": 8588},
                {"service": "task_coordinator", "port": 8551}
            ]
            
            for agent in agent_endpoints:
                await self.test_api_endpoint(
                    session,
                    f"{self.base_url}:{agent['port']}/health",
                    "GET",
                    200,
                    f"agent_{agent['service']}_health"
                )
    
    async def test_api_endpoint(self, session: aiohttp.ClientSession, url: str, 
                                method: str, expected_status: int, test_name: str) -> None:
        """Test a single API endpoint"""
        start_time = time.time()
        
        try:
            if method.upper() == "GET":
                async with session.get(url) as response:
                    response_time = time.time() - start_time
                    content = await response.text()
                    
                    if response.status == expected_status:
                        self.add_result(
                            f"api_endpoint_{test_name}",
                            "API Testing",
                            "PASS",
                            f"API endpoint {url} responded correctly",
                            response_time,
                            {
                                "url": url,
                                "method": method,
                                "expected_status": expected_status,
                                "actual_status": response.status,
                                "response_time": response_time,
                                "content_length": len(content)
                            }
                        )
                    else:
                        self.add_result(
                            f"api_endpoint_{test_name}",
                            "API Testing",
                            "FAIL",
                            f"API endpoint {url} returned unexpected status",
                            response_time,
                            {
                                "url": url,
                                "expected_status": expected_status,
                                "actual_status": response.status,
                                "response_time": response_time
                            },
                            f"Expected {expected_status}, got {response.status}"
                        )
                        
        except Exception as e:
            response_time = time.time() - start_time
            self.add_result(
                f"api_endpoint_{test_name}",
                "API Testing",
                "ERROR",
                f"API endpoint {url} test failed with exception",
                response_time,
                {"url": url, "method": method, "error": str(e)},
                str(e)
            )
    
    async def test_end_to_end_workflows(self) -> None:
        """Test complete end-to-end workflows"""
        logger.info("ğŸ”„ Testing end-to-end workflows...")
        
        # Test AI text generation workflow
        await self.test_ai_text_generation_workflow()
        
        # Test task orchestration workflow
        await self.test_task_orchestration_workflow()
        
        # Test hardware optimization workflow
        await self.test_hardware_optimization_workflow()
    
    async def test_ai_text_generation_workflow(self) -> None:
        """Test AI text generation end-to-end workflow"""
        start_time = time.time()
        
        try:
            # Test Ollama text generation
            timeout = aiohttp.ClientTimeout(total=60)  # Longer timeout for AI operations
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                # Generate text using Ollama
                payload = {
                    "model": "tinyllama",
                    "prompt": "What is artificial intelligence?",
                    "stream": False
                }
                
                async with session.post(f"{self.base_url}:10104/api/generate", json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        generated_text = result.get('response', '')
                        
                        execution_time = time.time() - start_time
                        
                        if len(generated_text) > 10:  # Basic validation
                            self.add_result(
                                "ai_text_generation_workflow",
                                "End-to-End Workflows",
                                "PASS",
                                "AI text generation workflow successful",
                                execution_time,
                                {
                                    "model": "tinyllama",
                                    "prompt_length": len(payload['prompt']),
                                    "response_length": len(generated_text),
                                    "response_preview": generated_text[:100] + "..." if len(generated_text) > 100 else generated_text
                                }
                            )
                        else:
                            self.add_result(
                                "ai_text_generation_workflow",
                                "End-to-End Workflows",
                                "FAIL",
                                "AI text generation produced insufficient output",
                                execution_time,
                                {"generated_text": generated_text}
                            )
                    else:
                        execution_time = time.time() - start_time
                        content = await response.text()
                        self.add_result(
                            "ai_text_generation_workflow",
                            "End-to-End Workflows",
                            "FAIL",
                            f"AI text generation failed with status {response.status}",
                            execution_time,
                            {"status_code": response.status, "response": content[:200]}
                        )
                        
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "ai_text_generation_workflow",
                "End-to-End Workflows",
                "ERROR",
                "AI text generation workflow failed with exception",
                execution_time,
                {"error": str(e)},
                str(e)
            )
    
    async def test_task_orchestration_workflow(self) -> None:
        """Test task orchestration workflow"""
        start_time = time.time()
        
        try:
            timeout = aiohttp.ClientTimeout(total=30)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                # Create a test task through the orchestrator
                task_payload = {
                    "task_type": "test_integration",
                    "parameters": {"test_id": str(uuid.uuid4())},
                    "priority": "normal"
                }
                
                # Submit task to orchestrator
                async with session.post(f"{self.base_url}:8589/tasks", json=task_payload) as response:
                    if response.status in [200, 201, 202]:
                        result = await response.json()
                        task_id = result.get('task_id') or result.get('id')
                        
                        execution_time = time.time() - start_time
                        
                        self.add_result(
                            "task_orchestration_workflow",
                            "End-to-End Workflows",
                            "PASS",
                            "Task orchestration workflow successful",
                            execution_time,
                            {
                                "task_id": task_id,
                                "task_type": task_payload['task_type'],
                                "status_code": response.status,
                                "orchestrator_response": result
                            }
                        )
                    else:
                        execution_time = time.time() - start_time
                        content = await response.text()
                        self.add_result(
                            "task_orchestration_workflow",
                            "End-to-End Workflows",
                            "FAIL",
                            f"Task orchestration failed with status {response.status}",
                            execution_time,
                            {"status_code": response.status, "response": content[:200]}
                        )
                        
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "task_orchestration_workflow",
                "End-to-End Workflows",
                "ERROR",
                "Task orchestration workflow failed with exception",
                execution_time,
                {"error": str(e)},
                str(e)
            )
    
    async def test_hardware_optimization_workflow(self) -> None:
        """Test hardware optimization workflow"""
        start_time = time.time()
        
        try:
            timeout = aiohttp.ClientTimeout(total=30)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                # Get system metrics
                async with session.get(f"{self.base_url}:11110/metrics") as response:
                    if response.status == 200:
                        metrics = await response.json()
                        
                        # Request optimization
                        optimization_payload = {
                            "target": "cpu_usage",
                            "threshold": 80
                        }
                        
                        async with session.post(f"{self.base_url}:11110/optimize", json=optimization_payload) as opt_response:
                            if opt_response.status in [200, 201, 202]:
                                optimization_result = await opt_response.json()
                                
                                execution_time = time.time() - start_time
                                
                                self.add_result(
                                    "hardware_optimization_workflow",
                                    "End-to-End Workflows",
                                    "PASS",
                                    "Hardware optimization workflow successful",
                                    execution_time,
                                    {
                                        "metrics_retrieved": bool(metrics),
                                        "optimization_target": optimization_payload['target'],
                                        "optimization_result": optimization_result
                                    }
                                )
                            else:
                                execution_time = time.time() - start_time
                                self.add_result(
                                    "hardware_optimization_workflow",
                                    "End-to-End Workflows",
                                    "FAIL",
                                    f"Hardware optimization failed with status {opt_response.status}",
                                    execution_time,
                                    {"status_code": opt_response.status}
                                )
                    else:
                        execution_time = time.time() - start_time
                        self.add_result(
                            "hardware_optimization_workflow",
                            "End-to-End Workflows",
                            "FAIL",
                            f"Hardware metrics retrieval failed with status {response.status}",
                            execution_time,
                            {"status_code": response.status}
                        )
                        
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "hardware_optimization_workflow",
                "End-to-End Workflows",
                "ERROR",
                "Hardware optimization workflow failed with exception",
                execution_time,
                {"error": str(e)},
                str(e)
            )
    
    def test_container_orchestration(self) -> None:
        """Test Docker container orchestration"""
        logger.info("ğŸ³ Testing container orchestration...")
        
        start_time = time.time()
        
        try:
            # Get container information
            result = subprocess.run(
                ["docker", "ps", "--format", "json"],
                capture_output=True, text=True, timeout=30
            )
            
            if result.returncode == 0:
                containers = []
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        try:
                            container_info = json.loads(line)
                            containers.append(container_info)
                        except json.JSONDecodeError:
                            continue
                
                # Check container health
                healthy_containers = 0
                unhealthy_containers = 0
                
                for container in containers:
                    status = container.get('Status', '').lower()
                    if 'healthy' in status:
                        healthy_containers += 1
                    elif 'unhealthy' in status:
                        unhealthy_containers += 1
                
                execution_time = time.time() - start_time
                
                self.add_result(
                    "container_orchestration",
                    "Infrastructure",
                    "PASS",
                    "Container orchestration validated successfully",
                    execution_time,
                    {
                        "total_containers": len(containers),
                        "healthy_containers": healthy_containers,
                        "unhealthy_containers": unhealthy_containers,
                        "container_names": [c.get('Names', '') for c in containers[:10]]  # First 10
                    }
                )
                
            else:
                execution_time = time.time() - start_time
                self.add_result(
                    "container_orchestration",
                    "Infrastructure",
                    "FAIL",
                    "Failed to get container information",
                    execution_time,
                    {"error": result.stderr},
                    result.stderr
                )
                
        except Exception as e:
            execution_time = time.time() - start_time
            self.add_result(
                "container_orchestration",
                "Infrastructure",
                "ERROR",
                "Container orchestration test failed with exception",
                execution_time,
                {"error": str(e)},
                str(e)
            )
    
    def generate_integration_summary(self) -> Dict[str, Any]:
        """Generate comprehensive integration test summary"""
        if not self.test_results:
            return {"status": "no_results"}
        
        # Count results by status
        passed = sum(1 for r in self.test_results if r.status == "PASS")
        failed = sum(1 for r in self.test_results if r.status == "FAIL")
        errors = sum(1 for r in self.test_results if r.status == "ERROR")
        skipped = sum(1 for r in self.test_results if r.status == "SKIP")
        
        total_tests = len(self.test_results)
        success_rate = (passed / total_tests * 100) if total_tests > 0 else 0
        
        # Calculate average execution time
        execution_times = [r.execution_time for r in self.test_results if r.execution_time > 0]
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0
        
        # Category breakdown
        categories = {}
        for result in self.test_results:
            category = result.category
            if category not in categories:
                categories[category] = {"passed": 0, "failed": 0, "errors": 0, "total": 0}
            
            categories[category]["total"] += 1
            if result.status == "PASS":
                categories[category]["passed"] += 1
            elif result.status == "FAIL":
                categories[category]["failed"] += 1
            elif result.status == "ERROR":
                categories[category]["errors"] += 1
        
        # Integration health score
        integration_score = success_rate
        if failed == 0 and errors == 0:
            integration_grade = "A+ (PERFECT INTEGRATION)"
        elif success_rate >= 95:
            integration_grade = "A (EXCELLENT)"
        elif success_rate >= 90:
            integration_grade = "B+ (VERY GOOD)"
        elif success_rate >= 80:
            integration_grade = "B (GOOD)"
        elif success_rate >= 70:
            integration_grade = "C (ACCEPTABLE)"
        else:
            integration_grade = "F (NEEDS IMPROVEMENT)"
        
        # Service health summary
        healthy_services = sum(1 for s in self.service_status if s.status == "HEALTHY")
        total_services = len(self.service_status)
        service_health_rate = (healthy_services / total_services * 100) if total_services > 0 else 0
        
        return {
            "integration_grade": integration_grade,
            "integration_score": round(integration_score, 1),
            "total_tests": total_tests,
            "passed_tests": passed,
            "failed_tests": failed,
            "error_tests": errors,
            "skipped_tests": skipped,
            "success_rate": round(success_rate, 1),
            "avg_execution_time": round(avg_execution_time, 3),
            "category_breakdown": categories,
            "service_health": {
                "healthy_services": healthy_services,
                "total_services": total_services,
                "health_rate": round(service_health_rate, 1)
            },
            "perfect_integration": failed == 0 and errors == 0,
            "production_ready": success_rate >= 95 and failed == 0
        }
    
    async def run_comprehensive_integration_test(self) -> Dict[str, Any]:
        """Run all integration tests"""
        logger.info("ğŸ”§ Starting ULTRA Integration Test Suite")
        start_time = time.time()
        
        # Run all integration tests
        await self.test_service_health()
        self.test_database_connectivity()
        await self.test_api_endpoints()
        await self.test_end_to_end_workflows()
        self.test_container_orchestration()
        
        end_time = time.time()
        test_duration = end_time - start_time
        
        # Generate summary
        summary = self.generate_integration_summary()
        
        return {
            "test_type": "comprehensive_integration_test",
            "timestamp": datetime.now().isoformat(),
            "test_duration": test_duration,
            "summary": summary,
            "detailed_results": [asdict(result) for result in self.test_results],
            "service_status": [asdict(status) for status in self.service_status]
        }
    
    def save_results(self, test_data: Dict[str, Any]) -> str:
        """Save integration test results"""
        filename = f"/opt/sutazaiapp/tests/ultra_integration_test_results_{int(time.time())}.json"
        
        try:
            with open(filename, 'w') as f:
                json.dump(test_data, f, indent=2)
            logger.info(f"Integration test results saved to: {filename}")
            return filename
        except Exception as e:
            logger.error(f"Failed to save integration results: {e}")
            return ""

async def main():
    """Run the ULTRA integration test suite"""
    print("ğŸ”§ ULTRA INTEGRATION TEST SUITE")
    print("=" * 50)
    
    tester = UltraIntegrationTester()
    
    # Run comprehensive integration test
    results = await tester.run_comprehensive_integration_test()
    
    # Save results
    results_file = tester.save_results(results)
    
    # Print summary
    summary = results['summary']
    
    print("\n" + "=" * 50)
    print("ğŸ¯ INTEGRATION TEST RESULTS")
    print("=" * 50)
    print(f"Integration Grade: {summary['integration_grade']}")
    print(f"Integration Score: {summary['integration_score']}/100")
    print(f"Success Rate: {summary['success_rate']}%")
    print(f"Total Tests: {summary['total_tests']}")
    print(f"Passed: {summary['passed_tests']}")
    print(f"Failed: {summary['failed_tests']}")
    print(f"Errors: {summary['error_tests']}")
    
    print(f"\nğŸ¥ Service Health:")
    service_health = summary['service_health']
    print(f"Healthy Services: {service_health['healthy_services']}/{service_health['total_services']}")
    print(f"Service Health Rate: {service_health['health_rate']}%")
    
    print(f"\nğŸ“Š Test Categories:")
    for category, stats in summary['category_breakdown'].items():
        print(f"{category}: {stats['passed']}/{stats['total']} passed")
    
    print(f"\nPerfect Integration: {'âœ… YES' if summary['perfect_integration'] else 'âŒ NO'}")
    print(f"Production Ready: {'âœ… YES' if summary['production_ready'] else 'âŒ NO'}")
    print(f"Results saved to: {results_file}")
    
    # Return exit code based on success
    return 0 if summary['failed_tests'] == 0 and summary['error_tests'] == 0 else 1

if __name__ == "__main__":
    exit(await main())