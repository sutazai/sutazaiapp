[tool:pytest]
# Comprehensive pytest configuration for SutazAI system per Rules 1-19

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Async support
asyncio_mode = auto

# Output and formatting
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --showlocals
    --durations=10
    --durations-min=1.0
    --maxfail=5
    --disable-warnings

# Markers for comprehensive test categorization
markers =
    unit: Unit tests for individual components
    integration: Integration tests between components and APIs
    e2e: End-to-end tests for complete user workflows
    performance: Performance and load testing
    security: Security vulnerability and penetration tests
    regression: Regression tests for backward compatibility
    failure: Failure scenario and resilience tests
    slow: Slow-running tests (>30 seconds)
    network: Tests requiring network access
    ollama: Tests requiring Ollama service
    ci: Tests suitable for CI/CD pipelines
    smoke: Quick smoke tests for basic functionality
    load: Load testing for scalability validation
    stress: Stress testing for system limits
    
# Timeout settings (extended for comprehensive testing)
timeout = 600
timeout_method = thread

# Coverage settings for 80% target
coverage_report = term-missing:skip-covered
coverage_html = tests/reports/coverage/html
coverage_xml = tests/reports/coverage/coverage.xml
coverage_json = tests/reports/coverage/coverage.json

# Detailed coverage configuration
coverage_omit = 
    */test*
    */conftest.py
    */venv/*
    */virtualenv/*
    */.venv/*

# Warnings configuration
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning:aiohttp.*
    ignore::PendingDeprecationWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::DeprecationWarning:cryptography.*
    ignore::DeprecationWarning:jwt.*

# Test output formats
junit_family = xunit2
junit_suite_name = sutazai_comprehensive_tests
junit_logging = all
junit_log_passing_tests = true

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/reports/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Performance and resource limits
addopts = 
    --maxfail=10
    --tb=short
    -ra
    --cov-report=term-missing:skip-covered
    --cov-report=html:tests/reports/coverage/html
    --cov-report=json:tests/reports/coverage/coverage.json
    --cov-report=xml:tests/reports/coverage/coverage.xml
    --junitxml=tests/reports/junit/results.xml

# Minimum Python version
minversion = 3.8

# Test environment variables
env =
    PYTHONPATH = backend:agents:.:$PYTHONPATH
    LOG_LEVEL = WARNING
    TESTING = true
    PYTEST_CURRENT_TEST = true
    TEST_BASE_URL = http://localhost:10010
    FRONTEND_URL = http://localhost:10011
    OLLAMA_URL = http://localhost:10104

# Parallel execution (when pytest-xdist is available)
# addopts = -n auto

# Test collection
collect_ignore = [
    "setup.py",
    "archive/",
    "backups/",
    "scripts/"
]