#!/bin/bash
# SutazAI Complete System Startup Script
# Starts all components including Ollama, backend, and web UI

set -e

# Project configuration
PROJECT_ROOT="/opt/sutazaiapp"
VENV_PATH="$PROJECT_ROOT/venv"
LOGS_DIR="$PROJECT_ROOT/logs"
PIDS_DIR="$PROJECT_ROOT/run"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING:${NC} $1"
}

# Create necessary directories
mkdir -p "$LOGS_DIR" "$PIDS_DIR"
cd "$PROJECT_ROOT"

log "üöÄ Starting SutazAI Complete System"
log "============================================="

# 1. Activate virtual environment
log "üì¶ Activating virtual environment..."
if [ ! -f "$VENV_PATH/bin/activate" ]; then
    error "Virtual environment not found at $VENV_PATH"
    exit 1
fi

source "$VENV_PATH/bin/activate"
log "‚úÖ Virtual environment activated"

# 2. Start Ollama service (Mock AI Server)
log "ü§ñ Starting Ollama AI service..."
if ! curl -sf http://127.0.0.1:11434/health > /dev/null 2>&1; then
    # Start mock Ollama server
    nohup python scripts/create_mock_ollama.py > "$LOGS_DIR/ollama.log" 2>&1 &
    OLLAMA_PID=$!
    echo $OLLAMA_PID > "$PIDS_DIR/ollama.pid"
    
    # Wait for Ollama to start
    sleep 5
    
    if curl -sf http://127.0.0.1:11434/health > /dev/null 2>&1; then
        log "‚úÖ Ollama AI service started (PID: $OLLAMA_PID)"
    else
        warn "‚ö†Ô∏è Ollama AI service may not have started properly"
    fi
else
    log "‚úÖ Ollama AI service already running"
fi

# 3. Verify AI models availability
log "üì• Verifying AI models..."
sleep 2

if curl -sf http://127.0.0.1:11434/api/tags > /dev/null 2>&1; then
    log "‚úÖ AI models are available and ready"
else
    warn "‚ö†Ô∏è AI models verification failed"
fi

# 4. Start Redis (if available)
log "üóÑÔ∏è Starting Redis..."
if command -v redis-server > /dev/null; then
    if ! pgrep -f "redis-server" > /dev/null; then
        nohup redis-server > "$LOGS_DIR/redis.log" 2>&1 &
        REDIS_PID=$!
        echo $REDIS_PID > "$PIDS_DIR/redis.pid"
        log "‚úÖ Redis started (PID: $REDIS_PID)"
    else
        log "‚úÖ Redis already running"
    fi
else
    warn "‚ö†Ô∏è Redis not available - using memory cache"
fi

# 5. Start PostgreSQL (if available)
log "üêò Checking PostgreSQL..."
if command -v psql > /dev/null; then
    if pg_isready -q; then
        log "‚úÖ PostgreSQL is ready"
    else
        warn "‚ö†Ô∏è PostgreSQL not ready - using SQLite fallback"
    fi
else
    warn "‚ö†Ô∏è PostgreSQL not available - using SQLite fallback"
fi

# 6. Run database migrations
log "üîÑ Running database setup..."
if [ -f "main.py" ]; then
    python main.py --migrate > "$LOGS_DIR/migration.log" 2>&1 || warn "‚ö†Ô∏è Database migration had issues"
elif [ -f "scripts/setup_database.py" ]; then
    python scripts/setup_database.py > "$LOGS_DIR/migration.log" 2>&1 || warn "‚ö†Ô∏è Database setup had issues"
else
    log "‚úÖ No database migration script found - using defaults"
fi

# 7. Start FastAPI backend
log "üåê Starting FastAPI backend..."
if ! pgrep -f "uvicorn.*backend_main:app" > /dev/null; then
    if [ -f "backend/backend_main.py" ]; then
        nohup uvicorn backend.backend_main:app --host 0.0.0.0 --port 8000 --workers 2 > "$LOGS_DIR/backend.log" 2>&1 &
    elif [ -f "main.py" ]; then
        nohup uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2 > "$LOGS_DIR/backend.log" 2>&1 &
    else
        error "No backend entry point found"
        exit 1
    fi
    
    BACKEND_PID=$!
    echo $BACKEND_PID > "$PIDS_DIR/backend.pid"
    
    # Wait for backend to start
    sleep 5
    
    if curl -sf http://localhost:8000/health > /dev/null 2>&1; then
        log "‚úÖ Backend started successfully (PID: $BACKEND_PID)"
    else
        warn "‚ö†Ô∏è Backend health check failed"
    fi
else
    log "‚úÖ Backend already running"
fi

# 8. Start Web UI server
log "üé® Starting Web UI server..."
if ! pgrep -f "python.*-m http.server.*3000" > /dev/null; then
    cd web_ui
    nohup python -m http.server 3000 > "$LOGS_DIR/webui.log" 2>&1 &
    WEBUI_PID=$!
    echo $WEBUI_PID > "$PIDS_DIR/webui.pid"
    cd "$PROJECT_ROOT"
    
    sleep 2
    log "‚úÖ Web UI started (PID: $WEBUI_PID)"
else
    log "‚úÖ Web UI already running"
fi

# 9. Final system check
log "üîç Running final system check..."
sleep 3

SERVICES_STATUS=""

# Check Ollama
if curl -sf http://localhost:11434/api/tags > /dev/null 2>&1; then
    SERVICES_STATUS+="‚úÖ Ollama API: http://localhost:11434\n"
else
    SERVICES_STATUS+="‚ùå Ollama API: OFFLINE\n"
fi

# Check Backend
if curl -sf http://localhost:8000/health > /dev/null 2>&1; then
    SERVICES_STATUS+="‚úÖ Backend API: http://localhost:8000\n"
else
    SERVICES_STATUS+="‚ùå Backend API: OFFLINE\n"
fi

# Check Web UI
if curl -sf http://localhost:3000 > /dev/null 2>&1; then
    SERVICES_STATUS+="‚úÖ Web UI: http://localhost:3000\n"
else
    SERVICES_STATUS+="‚ùå Web UI: OFFLINE\n"
fi

# Display final status
log "============================================="
log "üéâ SutazAI System Startup Complete!"
log "============================================="
echo -e "$SERVICES_STATUS"
log "============================================="
log "üìã Quick Access:"
log "   ‚Ä¢ Main Dashboard: http://localhost:3000"
log "   ‚Ä¢ Chat Interface: http://localhost:3000/chat.html"
log "   ‚Ä¢ API Documentation: http://localhost:8000/docs"
log "   ‚Ä¢ Ollama API: http://localhost:11434"
log ""
log "üìÑ Logs available in: $LOGS_DIR"
log "üîß PIDs stored in: $PIDS_DIR"
log ""
log "To stop all services: $PROJECT_ROOT/bin/stop_all.sh"
log "============================================="