# SutazAI Performance Configuration

# API Performance
api:
  max_request_size: 100MB
  request_timeout: 300  # 5 minutes
  keepalive_timeout: 75
  max_connections: 1000
  backlog: 2048

# Worker Configuration
workers:
  count: 4  # Number of worker processes
  class: "uvicorn.workers.UvicornWorker"
  max_requests: 1000  # Restart worker after N requests
  max_requests_jitter: 50
  timeout: 300
  graceful_timeout: 30
  keepalive: 75

# Database Optimization
database:
  pool_size: 20
  max_overflow: 40
  pool_timeout: 30
  pool_recycle: 3600
  echo: false
  statement_cache_size: 1200
  query_cache_size: 1200
  
  # PostgreSQL specific
  postgresql:
    jit: off
    random_page_cost: 1.1
    effective_cache_size: "4GB"
    shared_buffers: "1GB"
    work_mem: "50MB"
    maintenance_work_mem: "256MB"
    max_connections: 200
    
# Redis Configuration
redis:
  max_connections: 50
  socket_keepalive: true
  socket_keepalive_options:
    TCP_KEEPIDLE: 1
    TCP_KEEPINTVL: 2
    TCP_KEEPCNT: 3
  decode_responses: false
  health_check_interval: 30
  
# Caching Strategy
cache:
  default_ttl: 3600  # 1 hour
  max_local_size: 1000
  compression_threshold: 1024  # Compress if > 1KB
  
  # Cache TTLs by endpoint
  endpoints:
    "/api/v1/models/list": 1800  # 30 minutes
    "/api/v1/agents/list": 600   # 10 minutes
    "/api/v1/system/status": 60  # 1 minute
    
# Rate Limiting
rate_limit:
  default_limit: "100/minute"
  burst: 200
  
  # Custom limits by endpoint
  endpoints:
    "/api/v1/brain/think": "10/minute"
    "/api/v1/models/generate": "20/minute"
    "/api/v1/self-improvement/start": "1/hour"

# Load Balancing
load_balancer:
  algorithm: "round_robin"  # or "least_connections", "random"
  health_check_interval: 30
  health_check_timeout: 5
  
# Monitoring
monitoring:
  prometheus:
    enabled: true
    port: 9090
    path: "/metrics"
    
  logging:
    level: "INFO"
    slow_query_threshold: 1.0  # Log queries slower than 1s
    
  profiling:
    enabled: false  # Enable for debugging
    profile_dir: "/tmp/profiles"
    
# Memory Management
memory:
  max_memory_percent: 80  # Restart if memory > 80%
  gc_threshold: 100  # Run GC every N requests
  
# Model Optimization
models:
  max_concurrent_inferences: 5
  inference_timeout: 60
  batch_size: 8
  cache_embeddings: true
  
# Vector Database
vector_db:
  batch_insert_size: 100
  max_search_results: 1000
  similarity_threshold: 0.7
  index_refresh_interval: 300  # 5 minutes
  
# Self-Improvement
self_improvement:
  batch_size: 50
  min_confidence_threshold: 0.7
  max_concurrent_improvements: 5
  scan_interval: 3600  # 1 hour
  
# Security
security:
  max_login_attempts: 5
  lockout_duration: 300  # 5 minutes
  token_expiry: 86400  # 24 hours
  
# Compression
compression:
  enabled: true
  minimum_size: 500  # bytes
  level: 6  # 1-9