version: '3.8'

services:
  postgresql:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: sutazai
      POSTGRES_USER: sutazai
      POSTGRES_PASSWORD: sutazai2024
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    command: >
      postgres
      -c shared_buffers=128MB
      -c work_mem=2MB
      -c maintenance_work_mem=32MB
      -c effective_cache_size=256MB
      -c max_connections=50

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    command: >
      redis-server
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_NUM_PARALLEL: 1
      OLLAMA_MAX_LOADED_MODELS: 1
      OLLAMA_KEEP_ALIVE: 2m
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  streamlit-frontend:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    ports:
      - "8501:8501"
    environment:
      BACKEND_URL: http://localhost:8000
      STREAMLIT_SERVER_MAX_MESSAGE_SIZE: 50
      STREAMLIT_SERVER_MAX_UPLOAD_SIZE: 50
    volumes:
      - ./intelligent_chat_app_fixed.py:/app/app.py:ro
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    depends_on:
      - ollama

volumes:
  postgres_data:
  redis_data:
  ollama_data:
