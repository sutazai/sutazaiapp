networks:
  sutazai-network:
    # Use existing network created by deploy script
    external: true
    name: sutazai-network

services:
  # ========================================================================
  # CORE INFRASTRUCTURE
  # ========================================================================
  
  # --------------------------------------------------------
  # Database: PostgreSQL (Primary Database)
  # Port: 10000
  postgres:
    container_name: sutazai-postgres
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-sutazai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER:-sutazai}
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 60s
      test:
      - CMD-SHELL
      - pg_isready -U ${POSTGRES_USER:-sutazai}
      timeout: 5s
    image: sutazai-postgres-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10000:5432
    restart: unless-stopped
    volumes:
    - postgres_data:/var/lib/postgresql/data
    - ./IMPORTANT/init_db.sql:/docker-entrypoint-initdb.d/init.sql:ro

  # --------------------------------------------------------
  # Cache: Redis (Cache Layer)
  # Port: 10001
  redis:
    command: redis-server --save "" --appendonly no --maxmemory 512mb --maxmemory-policy allkeys-lru
    container_name: sutazai-redis
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      interval: 10s
      retries: 5
      test:
      - CMD-SHELL
      - redis-cli ping
      timeout: 5s
    image: sutazai-redis-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10001:6379
    restart: unless-stopped
    volumes:
    - redis_data:/data

  # --------------------------------------------------------
  # Graph Database: Neo4j
  # Ports: 10002 (browser), 10003 (bolt)
  neo4j:
    container_name: sutazai-neo4j
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD}
      # Optimized memory settings for Neo4j 5.x
      NEO4J_server_memory_heap_max__size: 512m
      NEO4J_server_memory_heap_initial__size: 256m
      NEO4J_server_memory_pagecache_size: 256m
      # JVM optimization for low memory usage
      NEO4J_server_jvm_additional: -XX:+UseG1GC -XX:G1HeapRegionSize=4m -XX:+DisableExplicitGC -XX:+ExitOnOutOfMemoryError
      # Database optimization - updated for Neo4j 5.x
      NEO4J_initial_dbms_default__database: sutazai
      NEO4J_db_checkpoint_interval_time: 30s
      NEO4J_db_transaction_timeout: 30s
      # Disable query logging to reduce I/O - updated for Neo4j 5.x
      NEO4J_db_logs_query_enabled: OFF
      # Disable strict validation to allow optimization
      NEO4J_server_config_strict__validation_enabled: false
      # Additional Neo4j 5.x specific settings for stability
      NEO4J_db_transaction_bookmark_ready_timeout: 5s
      NEO4J_dbms_cluster_discovery_type: SINGLE
    healthcheck:
      interval: 60s
      retries: 3
      start_period: 45s
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:7474/ || exit 1
      timeout: 15s
    image: sutazai-neo4j-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10002:7474
    - 10003:7687
    restart: unless-stopped
    volumes:
    - neo4j_data:/data

  # --------------------------------------------------------
  # LLM Server: Ollama (Local AI Models)
  # Port: 10104
  ollama:
    container_name: sutazai-ollama
    deploy:
      resources:
        limits:
          cpus: '10'
          memory: 20G
        reservations:
          cpus: '4'
          memory: 8G
    environment:
      CLAUDE_RULES_PATH: /app/CLAUDE.md
      ENFORCE_CLAUDE_RULES: 'true'
      OLLAMA_API_KEY: local
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_DEBUG: false
      OLLAMA_FLASH_ATTENTION: 1
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_KEEP_ALIVE: 10m
      OLLAMA_MAX_LOADED_MODELS: 3
      OLLAMA_MODELS: /home/ollama/.ollama/models
      OLLAMA_NUM_PARALLEL: 50
      OLLAMA_NUM_THREADS: 10
      OLLAMA_ORIGINS: '*'
      OLLAMA_RUNNERS_DIR: /tmp
      OLLAMA_TMPDIR: /tmp/ollama
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 60s
      test:
      - CMD-SHELL
      - ollama list > /dev/null || exit 1
      timeout: 30s
    image: sutazai-ollama-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10104:11434
    restart: unless-stopped
    sysctls:
    - net.core.somaxconn=65535
    ulimits:
      nofile:
        hard: 65536
        soft: 65536
    volumes:
    - ollama_data:/home/ollama/.ollama
    - models_data:/models
    - /opt/sutazaiapp/CLAUDE.md:/app/CLAUDE.md:ro
    - /opt/sutazaiapp/config/ollama.yaml:/app/config/ollama.yaml:ro

  # ========================================================================
  # VECTOR DATABASES
  # ========================================================================

  # --------------------------------------------------------
  # ChromaDB: Vector Database
  # Port: 10100
  chromadb:
    container_name: sutazai-chromadb
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    environment:
    - CHROMA_SERVER_AUTH_PROVIDER=chromadb.auth.token.TokenAuthenticationServerProvider
    - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMADB_API_KEY:-test-token}
    - CHROMA_SERVER_HOST=0.0.0.0
    - CHROMA_SERVER_HTTP_PORT=8000
    - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["http://localhost:8501", "http://backend:8000"]
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 120s
      test:
      - CMD
      - sh
      - -c
      - 'curl -f http://localhost:8000/api/v1/heartbeat || exit 1'
      timeout: 30s
    image: sutazai-chromadb-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10100:8000
    restart: unless-stopped
    volumes:
    - chromadb_data:/chroma/chroma

  # --------------------------------------------------------
  # Qdrant: Vector Database
  # Ports: 10101 (HTTP), 10102 (gRPC)
  qdrant:
    container_name: sutazai-qdrant
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      QDRANT__LOG_LEVEL: INFO
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__SERVICE__HTTP_PORT: 6333
    healthcheck:
      interval: 60s
      retries: 5
      test:
      - CMD
      - sh
      - -c
      - echo 'use IO::Socket::INET; my $$s = IO::Socket::INET->new(PeerAddr => q{localhost:6333},
        Proto => q{tcp}, Timeout => 2); if ($$s) { print $$s qq{GET / HTTP/1.0\r\n\r\n};
        while (<$$s>) { if (/200 OK/) { exit 0; } } } exit 1;' | perl
      timeout: 30s
    image: sutazai-qdrant-secure:latest
    networks:
    - sutazai-network
    ports:
    - 10101:6333
    - 10102:6334
    restart: unless-stopped
    volumes:
    - qdrant_data:/qdrant/storage

  # --------------------------------------------------------
  # FAISS: Vector Database
  # Port: 10103
  faiss:
    build:
      context: ./docker/faiss
      dockerfile: Dockerfile
    container_name: sutazai-faiss
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    environment:
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      interval: 60s
      retries: 5
      test:
      - CMD
      - python
      - -c
      - import urllib.request; urllib.request.urlopen('http://localhost:8000/health').read()
      timeout: 30s
    networks:
    - sutazai-network
    ports:
    - 10103:8000
    restart: unless-stopped
    volumes:
    - faiss_data:/data

  # ========================================================================
  # SERVICE MESH
  # ========================================================================

  # --------------------------------------------------------
  # API Gateway: Kong (DB-less)
  # Ports: 10005 (proxy), 10015 (admin)
  kong:
    image: kong:3.5
    container_name: sutazai-kong
    # SECURITY FIX: Increased memory to prevent exhaustion (was at 99.82% usage)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G  # Increased from 1G to prevent memory exhaustion
        reservations:
          cpus: '0.5'
          memory: 512M  # Increased from 256M for better performance
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: "/etc/kong/kong.yml"
      KONG_PROXY_LISTEN: "0.0.0.0:8000"
      KONG_ADMIN_LISTEN: "0.0.0.0:8001"
      KONG_LOG_LEVEL: "notice"
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep '[k]ong' > /dev/null || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
    - sutazai-network
    ports:
    - 10005:8000
    - 10015:8001
    restart: unless-stopped
    volumes:
    - ./config/kong/kong.yml:/etc/kong/kong.yml:ro

  # --------------------------------------------------------
  # Service Discovery: Consul
  # Port: 10006
  consul:
    image: hashicorp/consul:1.17
    container_name: sutazai-consul
    command: ["agent", "-server", "-bootstrap-expect=1", "-ui", "-client=0.0.0.0"]
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8500/v1/status/leader"]
      interval: 30s
      timeout: 5s
      retries: 10
      start_period: 10s
    networks:
    - sutazai-network
    ports:
    - 10006:8500
    restart: unless-stopped
    volumes:
    - ./config/consul/consul.hcl:/consul/config/consul.hcl:ro
    - consul_data:/consul/data

  # --------------------------------------------------------
  # Message Queue: RabbitMQ
  # Ports: 10007 (AMQP), 10008 (management UI)
  rabbitmq:
    image: sutazai-rabbitmq-secure:latest
    container_name: sutazai-rabbitmq
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER:-sutazai}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_running"]
      interval: 30s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
    - sutazai-network
    ports:
    - 10007:5672
    - 10008:15672
    restart: unless-stopped
    volumes:
    - rabbitmq_data:/var/lib/rabbitmq

  # ========================================================================
  # APPLICATION LAYER
  # ========================================================================

  # --------------------------------------------------------
  # Backend API: FastAPI
  # Port: 10010
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    container_name: sutazai-backend
    depends_on:
      chromadb:
        condition: service_healthy
      neo4j:
        condition: service_started
      ollama:
        condition: service_healthy
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 1G
    environment:
      API_V1_STR: /api/v1
      BACKEND_CORS_ORIGINS: '["http://localhost:10011", "http://172.31.77.193:10011"]'
      CHROMADB_HOST: chromadb
      CHROMADB_PORT: 8000
      CHROMADB_URL: http://chromadb:8000
      DATABASE_URL: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-sutazai}
      FAISS_INDEX_PATH: /data/faiss
      GRAFANA_PASSWORD: ${GRAFANA_PASSWORD}
      JWT_SECRET: ${JWT_SECRET}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      NEO4J_HOST: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      NEO4J_PORT: 7687
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      OLLAMA_API_KEY: local
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_ORIGINS: '*'
      POSTGRES_DB: ${POSTGRES_DB:-sutazai}
      POSTGRES_HOST: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-sutazai}
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      QDRANT_URL: http://qdrant:6333
      REDIS_HOST: sutazai-redis
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_PORT: 6379
      REDIS_URL: redis://sutazai-redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 120s
      test: &backend_health_test
      - CMD
      - python3
      - -c
      - import socket; s=socket.socket(); s.settimeout(5); exit(0 if s.connect_ex(("localhost",
        8000))==0 else 1)
      timeout: 30s
    networks:
    - sutazai-network
    ports:
    - 10010:8000
    restart: unless-stopped
    volumes:
    - ./backend:/app
    - ./data:/data
    - ./logs:/logs
    - agent_workspaces:/app/agent_workspaces

  # --------------------------------------------------------
  # Frontend UI: Streamlit
  # Port: 10011
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    command: streamlit run app.py --server.port 8501 --server.address 0.0.0.0
    container_name: sutazai-frontend
    depends_on:
      backend:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      BACKEND_URL: http://backend:8000
      STREAMLIT_SERVER_ADDRESS: 0.0.0.0
      STREAMLIT_SERVER_PORT: 8501
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 120s
      test:
      - CMD
      - python3
      - -c
      - import socket; s=socket.socket(); s.settimeout(5); exit(0 if s.connect_ex(("localhost",
        8501))==0 else 1)
      timeout: 30s
    networks:
    - sutazai-network
    ports:
    - 10011:8501
    restart: unless-stopped
    volumes:
    - ./frontend:/app
    - ./data:/data

  # ========================================================================
  # MONITORING STACK
  # ========================================================================

  # --------------------------------------------------------
  # Metrics Collection: Prometheus
  # Port: 10200
  prometheus:
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --storage.tsdb.path=/prometheus
    - --web.console.libraries=/usr/share/prometheus/console_libraries
    - --web.console.templates=/usr/share/prometheus/consoles
    - --web.enable-lifecycle
    - --storage.tsdb.retention.time=7d
    - --web.enable-admin-api
    - --storage.tsdb.max-block-duration=2h
    - --storage.tsdb.min-block-duration=2h
    - --storage.tsdb.retention.size=1GB
    container_name: sutazai-prometheus
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 90s
      test:
      - CMD
      - wget
      - --no-verbose
      - --tries=1
      - --spider
      - http://localhost:9090/-/healthy
      timeout: 30s
    image: prom/prometheus:latest
    networks:
    - sutazai-network
    ports:
    - 10200:9090
    restart: unless-stopped
    volumes:
    - ./monitoring/prometheus:/etc/prometheus
    - prometheus_data:/prometheus

  # --------------------------------------------------------
  # Visualization: Grafana
  # Port: 10201
  grafana:
    container_name: sutazai-grafana
    depends_on:
    - prometheus
    - loki
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    environment:
    - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    - GF_USERS_ALLOW_SIGN_UP=false
    - GF_INSTALL_PLUGINS=
    - GF_ANALYTICS_REPORTING_ENABLED=false
    - GF_ANALYTICS_CHECK_FOR_UPDATES=false
    - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/system-overview.json
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 60s
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit
        1
      timeout: 30s
    image: grafana/grafana:latest
    networks:
    - sutazai-network
    ports:
    - 10201:3000
    restart: unless-stopped
    volumes:
    - grafana_data:/var/lib/grafana
    - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards

  # --------------------------------------------------------
  # Log Aggregation: Loki
  # Port: 10202
  loki:
    command: -config.file=/etc/loki/local-config.yaml
    container_name: sutazai-loki
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 60s
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1
      timeout: 30s
    image: grafana/loki:2.9.0
    networks:
    - sutazai-network
    ports:
    - 10202:3100
    restart: unless-stopped
    volumes:
    - loki_data:/loki
    - ./monitoring/loki/config.yml:/etc/loki/local-config.yaml

  # --------------------------------------------------------
  # Alert Management: AlertManager
  # Port: 10203
  alertmanager:
    command:
    - --config.file=/etc/alertmanager/config.yml
    - --storage.path=/alertmanager
    - --web.external-url=http://localhost:9093
    container_name: sutazai-alertmanager
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    environment:
    - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
    - SLACK_AI_WEBHOOK_URL=${SLACK_AI_WEBHOOK_URL:-}
    - SLACK_SECURITY_WEBHOOK_URL=${SLACK_SECURITY_WEBHOOK_URL:-}
    - PAGERDUTY_SERVICE_KEY=${PAGERDUTY_SERVICE_KEY:-}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/ready"]
      interval: 60s
      timeout: 30s
      retries: 5
    image: prom/alertmanager:latest
    networks:
    - sutazai-network
    ports:
    - 10203:9093
    restart: unless-stopped
    volumes:
    - ./monitoring/alertmanager:/etc/alertmanager
    - alertmanager_data:/alertmanager

  # --------------------------------------------------------
  # Blackbox Monitoring: Blackbox Exporter
  # Port: 10204
  blackbox-exporter:
    command:
    - --config.file=/etc/blackbox_exporter/config.yml
    container_name: sutazai-blackbox-exporter
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      interval: 60s
      retries: 5
      test:
      - CMD
      - wget
      - --no-verbose
      - --tries=1
      - --spider
      - http://localhost:9115/
      timeout: 30s
    image: prom/blackbox-exporter:latest
    networks:
    - sutazai-network
    ports:
    - 10204:9115
    restart: unless-stopped
    volumes:
    - ./monitoring/blackbox/config.yml:/etc/blackbox_exporter/config.yml

  # --------------------------------------------------------
  # System Metrics: Node Exporter
  # Port: 10205
  node-exporter:
    command:
    - --path.procfs=/host/proc
    - --path.sysfs=/host/sys
    - --path.rootfs=/rootfs
    - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
    container_name: sutazai-node-exporter
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M
    image: prom/node-exporter:latest
    networks:
    - sutazai-network
    ports:
    - 10205:9100
    restart: unless-stopped
    volumes:
    - /proc:/host/proc:ro
    - /sys:/host/sys:ro
    - /:/rootfs:ro

  # --------------------------------------------------------
  # Container Metrics: cAdvisor
  # Port: 10206
  cadvisor:
    container_name: sutazai-cadvisor
    devices:
    - /dev/kmsg
    image: gcr.io/cadvisor/cadvisor:latest
    networks:
    - sutazai-network
    ports:
    - 10206:8080
    # SECURITY NOTE: cAdvisor requires privileged mode for container metrics collection
    privileged: true
    # ULTRA-SECURE: Add security constraints while maintaining functionality
    security_opt:
      - no-new-privileges:true
      # NOTE: Cannot use seccomp:default as cAdvisor needs system calls
    read_only: false  # cAdvisor needs write access for temporary files
    restart: unless-stopped
    command:
      - '--housekeeping_interval=30s'
      - '--max_housekeeping_interval=35s'
      - '--allow_dynamic_housekeeping=true'
      - '--global_housekeeping_interval=1m'
      - '--disable_metrics=advtcp,cpu_topology,disk,hugetlb,memory_numa,percpu,referenced_memory,resctrl,tcp,udp'
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 200M
        reservations:
          cpus: '0.1'
          memory: 50M
    volumes:
    # SECURITY NOTE: These mounts are required for cAdvisor metrics collection
    - /:/rootfs:ro                          # Host filesystem (read-only)
    - /var/run:/var/run:ro                  # Docker socket (read-only)
    - /sys:/sys:ro                          # System information (read-only)
    - /var/lib/docker/:/var/lib/docker:ro   # Docker data (read-only)
    - /dev/disk/:/dev/disk:ro               # Disk information (read-only)

  # --------------------------------------------------------
  # Database Metrics: PostgreSQL Exporter
  # Port: 10207
  postgres-exporter:
    container_name: sutazai-postgres-exporter
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-sutazai}?sslmode=disable
    image: prometheuscommunity/postgres-exporter:latest
    networks:
    - sutazai-network
    ports:
    - 10207:9187
    restart: unless-stopped

  # --------------------------------------------------------
  # Redis Metrics: Redis Exporter
  # Port: 10208
  redis-exporter:
    container_name: sutazai-redis-exporter
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M
    environment:
      REDIS_ADDR: redis://redis:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    image: oliver006/redis_exporter:latest
    networks:
    - sutazai-network
    ports:
    - 10208:9121
    restart: unless-stopped

  # ========================================================================
  # AI AGENT SERVICES
  # ========================================================================

  # --------------------------------------------------------
  # Ollama Integration Agent
  # Port: 8090
  ollama-integration:
    build:
      context: ./agents/ollama_integration
      dockerfile: Dockerfile
    container_name: sutazai-ollama-integration
    depends_on:
      ollama:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: ollama-integration
      API_ENDPOINT: http://backend:8000
      LOG_LEVEL: INFO
      OLLAMA_BASE_URL: http://ollama:11434
      PORT: 8090
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
      MAX_RETRIES: 3
      BACKOFF_BASE: 2
      REQUEST_TIMEOUT: 30
      CONNECTION_POOL_SIZE: 10
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
    - sutazai-network
    ports:
    - 8090:8090
    restart: unless-stopped
    volumes:
    - ./agents/core:/app/agents/core:ro

  # --------------------------------------------------------
  # Hardware Resource Optimizer
  # Port: 11110
  hardware-resource-optimizer:
    build:
      context: ./agents/hardware-resource-optimizer
      dockerfile: Dockerfile
    container_name: sutazai-hardware-resource-optimizer
    depends_on:
      backend:
        condition: service_started
      ollama:
        condition: service_started
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: hardware-resource-optimizer
      API_ENDPOINT: http://backend:8000
      DATABASE_URL: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-sutazai}
      LOG_LEVEL: INFO
      OLLAMA_API_KEY: local
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_MODEL: tinyllama:latest
      OLLAMA_ORIGINS: '*'
      PORT: 8080
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      interval: 60s
      retries: 5
      start_period: 120s
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      timeout: 30s
    networks:
    - sutazai-network
    # ULTRA-SECURE: Removed pid: host - not needed for optimization tasks
    ports:
    - 11110:8080
    # ULTRA-SECURE: Removed privileged mode for security
    privileged: false
    # ULTRA-SECURE: Minimal capabilities with enhanced security
    cap_drop:
      - ALL                    # Drop all capabilities first
    cap_add:
      - SYS_PTRACE            # For process monitoring only
      # SYS_ADMIN removed - too permissive for container
    security_opt:
      - no-new-privileges:true
      - seccomp:unconfined
      # apparmor:docker-default  # Enable if AppArmor available
    restart: unless-stopped
    volumes:
    # ULTRA-SECURE: Minimal volume mounts with proper restrictions
    - ./data:/app/data:rw,noexec        # Data access without execution
    - ./configs:/app/configs:ro         # Read-only configuration files
    - ./logs:/app/logs:rw,noexec        # Log writing without execution
    # ULTRA-SECURE: Removed dangerous system mounts
    # - ./agents/core:/app/agents/core:ro  # REMOVED - not needed
    # - /proc:/host/proc:ro                # REMOVED - host process exposure risk
    # - /sys:/host/sys:ro                  # REMOVED - host system exposure risk
    # - /var/run/docker.sock:/var/run/docker.sock  # REMOVED - container escape risk
    # - /tmp:/host/tmp                     # REMOVED - write access to host

  # --------------------------------------------------------
  # Jarvis Hardware Resource Optimizer
  # Port: 11104
  jarvis-hardware-resource-optimizer:
    build:
      context: ./agents/jarvis-hardware-resource-optimizer
      dockerfile: Dockerfile
    container_name: sutazai-jarvis-hardware-resource-optimizer
    depends_on:
      backend:
        condition: service_started
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: jarvis-hardware-resource-optimizer
      API_ENDPOINT: http://backend:8000
      LOG_LEVEL: INFO
      PORT: 8080
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 60s
    networks:
    - sutazai-network
    # ULTRA-SECURE: Removed pid: host - not needed for optimization tasks
    ports:
    - 11104:8080
    # ULTRA-SECURE: Removed privileged mode for security
    privileged: false
    # ULTRA-SECURE: Minimal capabilities with enhanced security
    cap_drop:
      - ALL                    # Drop all capabilities first
    cap_add:
      - SYS_PTRACE            # For process monitoring only
      # SYS_ADMIN removed - too permissive for container
    security_opt:
      - no-new-privileges:true
      - seccomp:unconfined
      # apparmor:docker-default  # Enable if AppArmor available
    user: "1001:1001"          # Non-root user for security
    restart: unless-stopped
    volumes:
    # ULTRA-SECURE: Minimal volume mounts with proper restrictions
    - ./agents/core:/app/agents/core:ro  # Read-only shared agent code
    - ./data:/app/data:rw,noexec        # Data access without execution
    - ./configs:/app/configs:ro         # Read-only configuration files
    - ./logs:/app/logs:rw,noexec        # Log writing without execution
    # ULTRA-SECURE: Removed dangerous system mounts
    # - /proc:/host/proc:ro                # REMOVED - host process exposure risk
    # - /sys:/host/sys:ro                  # REMOVED - host system exposure risk
    # - /var/run/docker.sock:/var/run/docker.sock  # REMOVED - container escape risk

  # --------------------------------------------------------
  # Jarvis Automation Agent
  # Port: 11102
  jarvis-automation-agent:
    build:
      context: ./agents/jarvis-automation-agent
      dockerfile: Dockerfile
    container_name: sutazai-jarvis-automation-agent
    depends_on:
      backend:
        condition: service_started
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: jarvis-automation-agent
      API_ENDPOINT: http://backend:8000
      DATABASE_URL: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-sutazai}
      LOG_LEVEL: INFO
      OLLAMA_BASE_URL: http://ollama:11434
      PORT: 8080
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 60s
    networks:
    - sutazai-network
    ports:
    - 11102:8080
    restart: unless-stopped
    volumes:
    - ./agents/core:/app/agents/core:ro
    - ./data:/app/data
    - ./configs:/app/configs
    - ./logs:/app/logs
    - /tmp:/tmp
    - /opt/sutazaiapp:/opt/sutazaiapp:ro

  # --------------------------------------------------------
  # AI Agent Orchestrator
  # Port: 8589
  ai-agent-orchestrator:
    build:
      context: ./agents/ai_agent_orchestrator
      dockerfile: Dockerfile
    container_name: sutazai-ai-agent-orchestrator
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: ai-agent-orchestrator
      API_ENDPOINT: http://backend:8000
      LOG_LEVEL: INFO
      PORT: 8589
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8589/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks:
    - sutazai-network
    ports:
    - 8589:8589
    restart: unless-stopped
    volumes:
    - ./agents/core:/app/agents/core:ro
    - ./logs:/app/logs

  # --------------------------------------------------------
  # Task Assignment Coordinator
  # Port: 8551
  task-assignment-coordinator:
    build:
      context: ./agents
      dockerfile: task_assignment_coordinator/Dockerfile
    container_name: sutazai-task-assignment-coordinator
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: task-assignment-coordinator
      API_ENDPOINT: http://backend:8000
      LOG_LEVEL: INFO
      PORT: 8551
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8551/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks:
    - sutazai-network
    ports:
    - 8551:8551
    restart: unless-stopped
    volumes:
    - ./agents/core:/app/agents/core:ro
    - ./logs:/app/logs

  # --------------------------------------------------------
  # Resource Arbitration Agent
  # Port: 8588
  resource-arbitration-agent:
    build:
      context: ./agents/resource_arbitration_agent
      dockerfile: Dockerfile
    container_name: sutazai-resource-arbitration-agent
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      AGENT_TYPE: resource-arbitration-agent
      API_ENDPOINT: http://backend:8000
      LOG_LEVEL: INFO
      PORT: 8588
      RABBITMQ_URL: amqp://${RABBITMQ_DEFAULT_USER:-sutazai}:${RABBITMQ_DEFAULT_PASS}@rabbitmq:5672/
      REDIS_URL: redis://sutazai-redis:6379/0
      SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
      TZ: ${TZ:-UTC}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8588/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks:
    - sutazai-network
    # ULTRA-SECURE: Removed pid: host - not needed for resource arbitration
    ports:
    - 8588:8588
    # ULTRA-SECURE: Removed privileged mode for security
    privileged: false
    # ULTRA-SECURE: Minimal capabilities with enhanced security
    cap_drop:
      - ALL                    # Drop all capabilities first
    cap_add:
      - SYS_PTRACE            # For process monitoring only
      # SYS_ADMIN removed - too permissive for container
    security_opt:
      - no-new-privileges:true
      - seccomp:unconfined
      # apparmor:docker-default  # Enable if AppArmor available
    user: "1001:1001"          # Non-root user for security
    restart: unless-stopped
    volumes:
    # ULTRA-SECURE: Minimal volume mounts with proper restrictions
    - ./agents/core:/app/agents/core:ro  # Read-only shared agent code
    - ./data:/app/data:rw,noexec        # Data access without execution
    - ./logs:/app/logs:rw,noexec        # Log writing without execution
    # ULTRA-SECURE: Removed dangerous system mounts
    # - /proc:/host/proc:ro                # REMOVED - host process exposure risk
    # - /sys:/host/sys:ro                  # REMOVED - host system exposure risk

# ========================================================================
# VOLUMES
# ========================================================================
volumes:
  agent_outputs: null
  agent_workspaces: null
  alertmanager_data: null
  chromadb_data: null
  consul_data: null
  faiss_data: null
  grafana_data: null
  loki_data: null
  models_data: null
  neo4j_data: null
  ollama_data: null
  postgres_data: null
  prometheus_data: null
  qdrant_data: null
  rabbitmq_data: null
  redis_data: null

# ========================================================================
# SHARED CONFIGURATIONS
# ========================================================================
x-common-variables:
  SUTAZAI_ENV: ${SUTAZAI_ENV:-production}
  TZ: ${TZ:-UTC}

x-database-config:
  DATABASE_URL: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-sutazai}
  REDIS_URL: redis://redis:6379/0

x-ollama-config:
  OLLAMA_API_KEY: local
  OLLAMA_BASE_URL: http://ollama:11434
  OLLAMA_HOST: 0.0.0.0
  OLLAMA_ORIGINS: '*'

x-vector-config:
  CHROMADB_URL: http://chromadb:8000
  FAISS_INDEX_PATH: /data/faiss
  NEO4J_PASSWORD: ${NEO4J_PASSWORD}
  NEO4J_URI: bolt://neo4j:7687
  NEO4J_USER: neo4j
  QDRANT_URL: http://qdrant:6333