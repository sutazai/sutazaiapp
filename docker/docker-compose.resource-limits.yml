version: '3.8'

# Resource Limits Override Configuration
# Created: 2025-08-20
# Purpose: Apply memory and CPU limits to prevent resource exhaustion

services:
  # High memory usage services
  mcp-orchestrator:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  neo4j:
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
    environment:
      - NEO4J_HEAP_MEMORY=256M
      - NEO4J_PAGECACHE_MEMORY=128M
      - NEO4J_dbms_memory_transaction_global_max__size=128M
    restart: unless-stopped

  ollama:
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
    environment:
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_MODELS_MEMORY=256M
    restart: unless-stopped

  grafana:
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
    restart: unless-stopped

  prometheus:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--storage.tsdb.retention.size=1GB'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  backend:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    environment:
      - PYTHONUNBUFFERED=1
      - MALLOC_TRIM_THRESHOLD_=100000
    restart: unless-stopped

  frontend:
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
    restart: unless-stopped

  rabbitmq:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    environment:
      - RABBITMQ_VM_MEMORY_HIGH_WATERMARK=0.4
      - RABBITMQ_DISK_FREE_LIMIT=1GB
    restart: unless-stopped

  redis:
    deploy:
      resources:
        limits:
          memory: 64M
          cpus: '0.25'
        reservations:
          memory: 32M
    command: redis-server --maxmemory 50mb --maxmemory-policy allkeys-lru
    restart: unless-stopped

  postgres:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    environment:
      - POSTGRES_SHARED_BUFFERS=64MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=128MB
      - POSTGRES_WORK_MEM=2MB
    restart: unless-stopped

  kong:
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
    environment:
      - KONG_MEM_CACHE_SIZE=64m
      - KONG_WORKER_CONNECTIONS=1024
    restart: unless-stopped

  # MCP containers
  mcp-manager:
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
    restart: unless-stopped

  # Low-resource monitoring containers
  node-exporter:
    deploy:
      resources:
        limits:
          memory: 32M
          cpus: '0.1'
    restart: unless-stopped

  cadvisor:
    deploy:
      resources:
        limits:
          memory: 64M
          cpus: '0.1'
    restart: unless-stopped

  loki:
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
    restart: unless-stopped

  alertmanager:
    deploy:
      resources:
        limits:
          memory: 32M
          cpus: '0.1'
    restart: unless-stopped