version: '3.8'

# ULTRA-PERFORMANCE Docker Compose Configuration
# Optimized for <2s response times and 1000+ concurrent users
# Target: 3.5GB total memory usage (from 8GB)

services:
  # Core Databases - Optimized memory limits
  postgres:
    container_name: sutazai-postgres
    image: postgres:15-alpine
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 512M  # Reduced from 2G
        reservations:
          cpus: '0.5'
          memory: 256M
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-sutazai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER:-sutazai}
      # Performance tuning
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --data-checksums"
      POSTGRES_HOST_AUTH_METHOD: "scram-sha-256"
      # Optimized settings
      POSTGRES_SHARED_BUFFERS: "128MB"
      POSTGRES_EFFECTIVE_CACHE_SIZE: "256MB"
      POSTGRES_WORK_MEM: "4MB"
      POSTGRES_MAINTENANCE_WORK_MEM: "32MB"
      POSTGRES_MAX_CONNECTIONS: "100"
      POSTGRES_RANDOM_PAGE_COST: "1.1"
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: "200"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    command: >
      postgres
      -c shared_buffers=128MB
      -c effective_cache_size=256MB
      -c maintenance_work_mem=32MB
      -c work_mem=4MB
      -c max_connections=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c wal_buffers=16MB
      -c checkpoint_completion_target=0.9
      -c max_wal_size=1GB
      -c min_wal_size=80MB
    networks:
      - sutazai-network

  redis:
    container_name: sutazai-redis
    image: redis:7-alpine
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 256M  # Reduced from 1G
        reservations:
          cpus: '0.25'
          memory: 128M
    command: >
      redis-server
      --maxmemory 200mb
      --maxmemory-policy allkeys-lru
      --save ""
      --appendonly no
      --tcp-backlog 511
      --tcp-keepalive 60
      --timeout 0
      --databases 16
      --always-show-logo no
      --protected-mode no
    volumes:
      - redis_data:/data
    networks:
      - sutazai-network

  # Ollama - Optimized for fast inference
  ollama:
    container_name: sutazai-ollama
    image: ollama/ollama:latest
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 2G  # Optimized for TinyLlama
        reservations:
          cpus: '2.0'
          memory: 1G
    environment:
      OLLAMA_MODELS: "/root/.ollama/models"
      OLLAMA_NUM_PARALLEL: "4"
      OLLAMA_MAX_LOADED_MODELS: "2"
      OLLAMA_KEEP_ALIVE: "10m"
      OLLAMA_MAX_QUEUE: "512"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - sutazai-network
    command: serve

  # Backend - Optimized with caching
  backend:
    container_name: sutazai-backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 512M  # Reduced from 1G
        reservations:
          cpus: '1.0'
          memory: 256M
    environment:
      # Core settings
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-sutazai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-sutazai}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      OLLAMA_URL: http://ollama:11434
      
      # Performance settings
      WORKERS: "4"
      WORKER_CLASS: "uvicorn.workers.UvicornWorker"
      WORKER_CONNECTIONS: "1000"
      MAX_REQUESTS: "1000"
      MAX_REQUESTS_JITTER: "50"
      TIMEOUT: "30"
      KEEP_ALIVE: "5"
      
      # Cache settings
      CACHE_TTL: "3600"
      CACHE_MAX_SIZE: "1000"
      USE_CACHE: "true"
      CACHE_STRATEGY: "aggressive"
      
      # Pool settings
      DB_POOL_MIN: "20"
      DB_POOL_MAX: "50"
      REDIS_POOL_MAX: "100"
      HTTP_POOL_MAX: "100"
    depends_on:
      - postgres
      - redis
      - ollama
    networks:
      - sutazai-network
    ports:
      - "10010:10010"
    command: >
      gunicorn app.main:app
      --worker-class uvicorn.workers.UvicornWorker
      --workers 4
      --bind 0.0.0.0:10010
      --max-requests 1000
      --max-requests-jitter 50
      --timeout 30
      --keep-alive 5
      --access-logfile -
      --error-logfile -
      --preload

  # Frontend - Lightweight
  frontend:
    container_name: sutazai-frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 256M  # Reduced from 512M
        reservations:
          cpus: '0.5'
          memory: 128M
    environment:
      BACKEND_URL: http://backend:10010
      STREAMLIT_SERVER_PORT: 10011
      STREAMLIT_SERVER_MAX_UPLOAD_SIZE: 10
      STREAMLIT_SERVER_ENABLE_CORS: "false"
      STREAMLIT_BROWSER_GATHER_USAGE_STATS: "false"
      STREAMLIT_THEME_BASE: "dark"
    depends_on:
      - backend
    networks:
      - sutazai-network
    ports:
      - "10011:10011"

  # Load Balancer for horizontal scaling
  nginx:
    container_name: sutazai-nginx
    image: nginx:alpine
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 64M
        reservations:
          cpus: '0.25'
          memory: 32M
    volumes:
      - ./nginx.ultra.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
      - frontend
    networks:
      - sutazai-network

  # Monitoring - Lightweight
  prometheus:
    container_name: sutazai-prometheus
    image: prom/prometheus:latest
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    volumes:
      - ./prometheus.ultra.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--storage.tsdb.retention.size=1GB'
      - '--web.enable-lifecycle'
    networks:
      - sutazai-network
    ports:
      - "10200:9090"

  # Caching layer for static content
  varnish:
    container_name: sutazai-varnish
    image: varnish:7-alpine
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.25'
          memory: 64M
    environment:
      VARNISH_SIZE: 100M
    volumes:
      - ./varnish.vcl:/etc/varnish/default.vcl:ro
    command: >
      varnishd
      -F
      -f /etc/varnish/default.vcl
      -a :6081
      -T :6082
      -s malloc,100M
      -p thread_pools=2
      -p thread_pool_min=50
      -p thread_pool_max=500
    networks:
      - sutazai-network
    ports:
      - "6081:6081"

networks:
  sutazai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/sutazai/postgres
  
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/sutazai/redis
  
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/sutazai/ollama
  
  prometheus_data:
    driver: local

# Total Memory Usage Estimate:
# PostgreSQL: 512M
# Redis: 256M
# Ollama: 2G
# Backend: 512M
# Frontend: 256M
# Nginx: 64M
# Prometheus: 256M
# Varnish: 128M
# TOTAL: ~3.5GB (down from 8GB)