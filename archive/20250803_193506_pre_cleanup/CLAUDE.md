ğŸ”§ Codebase Hygiene
A clean, consistent, and organized codebase is non-negotiable. It reflects engineering discipline and enables scalability, team velocity, and fault tolerance.

Every contributor is accountable for maintaining and improving hygieneâ€”not just avoiding harm.

ğŸ§¼ Enforce Consistency Relentlessly
âœ… Follow the existing structure, naming patterns, and conventions. Never introduce your own style or shortcuts.

âœ… Centralize logic â€” do not duplicate code across files, modules, or services.

ğŸš« Avoid multiple versions of:

APIs doing the same task (REST + GraphQL duplicating effort, for example)

UI components or CSS/SCSS modules with near-identical logic or styling

Scripts that solve the same problem in slightly different ways

Requirements files scattered across environments with conflicting dependencies

Documentation split across folders with different levels of accuracy

ğŸ“‚ Project Structure Discipline
ğŸ“Œ Never dump files or code in random or top-level folders.

ğŸ“Œ Place everything intentionally, following modular boundaries:

components/ for reusable UI parts

services/ or api/ for network interactions

utils/ for pure logic or helpers

hooks/ for reusable frontend logic

schemas/ or types/ for data validation

If the ideal location doesnâ€™t exist, propose a clear structure and open a small RFC (Request for Comments) before proceeding.

ğŸ—‘ï¸ Dead Code is Debt
ğŸ”¥ Regularly delete unused code, legacy assets, stale test files, or experimental stubs.

âŒ â€œJust in caseâ€ or â€œmight be useful laterâ€ is not a valid reason to keep clutter.

ğŸ§ª Temporary test code must be removed or clearly gated (e.g. with feature flags or development-only checks).

ğŸ§ª Use Tools to Automate Discipline
âœ… Mandatory for all contributors:

Linters: ESLint, Flake8, RuboCop

Formatters: Prettier, Black, gofmt

Static analysis: TypeScript, mypy, SonarQube, Bandit

Dependency managers: pip-tools, Poetry, pnpm, npm lockfiles

Schema enforcement: JSON schema, Pydantic, zod

Test coverage tooling: Jest, pytest-cov, Istanbul

ğŸ”„ Integrate these tools in pre-commit, pre-push, and CI/CD workflows:

No code gets into production branches without passing hygiene checks.

Every PR should be green and self-explanatory.

âœï¸ Commits Are Contracts
âœ… Write atomic commitsâ€”one logical change per commit.

ğŸ§¾ Follow conventional commit patterns or similar style guides (feat:, fix:, refactor:, etc.).

ğŸ§ª No skipping reviews or tests for â€œquick fixes.â€ These introduce long-term chaos.

ğŸ§  Execution Mindset: Act Like a Top-Level Engineer
ğŸ› ï¸ Think like an Architect, Engineer, QA, and PMâ€”all at once.

ğŸ”¬ Examine the full context of any change before writing code.

ğŸ§­ Prioritize long-term clarity over short-term speed.

ğŸ§± Every change should make the codebase easier to maintain for someone else later.

ğŸš© Red Flags (Anti-Patterns to Avoid)
ğŸ”´ "I'll just put this here for now" â€” No, there is no â€œfor now.â€

ğŸ”´ "It's just a tiny change" â€” Thatâ€™s how tech debt begins.

ğŸ”´ "We can clean this up later" â€” â€œLaterâ€ rarely comes.

ğŸ”´ Duplicate modules named utils.js, helper.py, or service.ts across packages.

ğŸ”´ PRs that include: unrelated changes, commented-out code, unreviewed temporary logs.

ğŸ§­ Final Reminder
A healthy codebase is a shared responsibility.
Every line of code you touch should be better than you found it.

ğŸš« Rules to Follow

-------
ğŸ“Œ Rule 1: No Fantasy Elements
âœ¨ Only real, production-ready implementations are allowed.
Do not write speculative, placeholder, â€œin-theory,â€ or overly abstract code unless it's been fully validated and grounded in current platform constraints.

âœ¨ Avoid overengineering or unnecessary abstraction.
No fictional components, fake classes, dream APIs, or concrete implementation or real example infrastructure. All code must reflect actual, working systems.

âœ¨ No â€˜specific future version or roadmap itemâ€™ solutions.
Avoid comments like // TODO: automatically, programmatically scale this later or // imagine this uses a future AI module. If it doesnâ€™t exist now, it doesnâ€™t go in the codebase.

âœ¨ Be honest with the present limitations.
Code must work today, not in a hypothetical perfect setup. Assume real-world constraints like flaky hardware, latency, cold starts, and limited memory.
All code and documentation must use real, grounded constructsâ€”no metaphors, specific implementation name (e.g., emailSender, dataProcessor) terms, or hypothetical â€œblack-boxâ€ AI.

âœ¨ Forbidden:

Terms like wizardService, specificHandler (e.g., authHandler, dataHandler), teleportData(), or comments such as // TODO: add telekinesis here.

Pseudo-functions that donâ€™t map to an actual library or API (e.g. superIntuitiveAI.optimize()).

âœ¨ Mandated Practices:

Name things concretely: emailSender, not magicMailer.

Use real libraries: import from nodemailer, not from â€œthe built-in mailer.â€

Link to docs in comments or READMEâ€”every external API or framework must be verifiable.

âœ… Pre-Commit Checks:

 Search for banned keywords (specific implementation name (e.g., emailSender, dataProcessor), wizard, black-box, etc.) in your diff.

 Verify every new dependency is in package.json (or requirements.txt) with a valid version.

 Ensure code examples in docs actually compile or run.

----
 Rule 2: Do Not Break Existing Functionality
âœ¨ Every change must respect what already works.
Before modifying any file, component, or flow, verify exactly what it currently does and why. Donâ€™t assume anything.

âœ¨ Regression = failure.
If your change breaks or downgrades existing featuresâ€”even temporarilyâ€”itâ€™s considered a critical issue. Stability comes first.

âœ¨ Backwards compatibility is a must.
If your refactor or feature update changes existing behavior, either support legacy use cases or migrate them gracefully.

âœ¨ Always test before merging.
Write or update test cases to explicitly cover both new logic and old logic. Nothing ships unless itâ€™s verified to not break production behavior.

âœ¨ Communicate impact clearly.
If thereâ€™s any risk of side effects, escalate and document. Silent changes are forbidden.

ğŸ” Before modifying any file, investigate the full functionality and behavior of the existing codeâ€”understand what it does, how it's used, and whether it's actively supporting a feature or integration.

ğŸ§ª If a change is required, test the full end-to-end flow before and after. Confirm the logic is preserved or improvedâ€”never regressed.

ğŸ” Refactor only when necessary and with proper safeguards. If existing advanced functionality is present (e.g., dynamic routing, lazy loading, caching, etc.), it must be preserved or enhanced, not removed.

ğŸ“Š Maintain proper version control and rollback strategies in case a new change introduces instability or conflict.

ğŸ’¡ Document what was changed, why, and what was verified to ensure that others won't unknowingly override or disrupt a critical flow later.

â— Breaking changes must never be merged without full validation across all dependent systems and deployment scenarios.
Every change must preserve or improve current behaviorâ€”no regressions, ever.

âœ¨ Investigation Steps:

Trace usage:

grep -R "functionName" .

Check import graphs or IDE â€œFind Usages.â€

Run baseline tests:

npm test, pytest, or your CI suite.

Manual sanity check of any affected UI or API endpoints.

Review consumers:

Frontend pages that call an endpoint

Cron jobs or scripts that rely on a helper

âœ¨ Testing & Safeguards:

 Write or update tests covering both old and new behavior.

 Gate big changes behind feature flags until fully validated.

 Prepare a rollback planâ€”document the exact revert commit or steps.

âœ… Merge Criteria:

 Green build with 100% test pass rate

 No new lint/type errors

 Explicit sign-off from the original feature owner or lead

â— Do Not merge breaking changes without:

A clear â€œBreaking Changeâ€ section in the PR description

A migration or upgrade guide in CHANGELOG.md or docs



----
ğŸ“Œ Rule 3: Analyze Everythingâ€”Every Time
Always conduct a thorough and systematic review of the entire application before proceeding.

Files

 Ensure naming conventions are consistent and meaningful

 Remove redundant or obsolete files

 Verify file dependencies and imports

Folders

 Maintain a clear, logical folder structure

 Avoid duplication of modules or components

 Group related functionality properly

Scripts

 Check for reusability and maintainability

 Confirm scripts are version-controlled and documented

 Validate script execution paths and environment variables

Directories

 Ensure consistent layout across environments (dev, staging, prod)

 Remove unused or temporary directories

 Audit for unnecessary nesting and flatten where possible

Code Logic

 Scrutinize conditionals, loops, and function logic for accuracy and efficiency

 Validate edge-case handling and error management

 Check for unnecessary complexityâ€”simplify where possible

 Confirm logic is testable and covered by unit/integration tests

Dependencies & Packages

 Validate all installed packages are in use and up to date

 Remove deprecated or unused dependencies

 Verify security and license compliance

APIs & Integrations

 Confirm external APIs are stable and well-documented

 Check rate limits, error handling, and retry logic

 Validate data mappings and transformation layers

Configuration Files

 Ensure all environment-specific settings are properly scoped

 Avoid hard-coded secretsâ€”use secure environment variables

 Check for misconfigured flags or unused parameters

Build/Deployment Pipelines

 Audit CI/CD pipelines for completeness and reliability

 Ensure testing, linting, and rollback mechanisms are in place

 Check for consistency across branches and environments

Logs & Monitoring

 Confirm logging is present, relevant, and not excessive

 Ensure sensitive data is never logged

 Verify monitoring and alerting are properly configured

Testing Coverage

 Validate coverage reports and ensure tests are passing

 Confirm all new or modified logic is properly tested

 Check for flaky or redundant tests

 Ensure everything is functioning 100% correctly before proceeding.

---
ğŸ“Œ Rule 4: Reuse Before Creating
 Always check for and reuse existing scripts.

 Only create new scripts if absolutely necessaryâ€”and only when no existing solution fits.
 
 ----
 ğŸ“Œ Rule 5: Treat This as a Professional Project â€” Not a Playground
 Approach every task with a professional mindsetâ€”this is not an experiment or personal sandbox.

 Do not treat the codebase as a place for trial-and-error coding, shortcuts, or sloppy work.

 Respect the structure, standards, and long-term maintainability of the project.

 Every decision must be intentional, reviewed, and aligned with best practices.
 
 ----
 ğŸ“Œ Rule 6: Clear, Centralized, and Structured Documentation
Documentation is part of the codebase â€” it must be organized, consistent, and treated with the same discipline as source code. It should enable any contributor or stakeholder to onboard, build, debug, or deploy without confusion.

ğŸ“ Centralized Location & Structure
 Store all documentation in a single, clearly defined location, such as:

A dedicated /docs/ directory in the root of the codebase

An internal wiki (e.g., GitHub Wiki, GitLab Wiki)

A linked platform like Notion, Confluence, or ReadTheDocs

 Do not scatter docs across arbitrary folders, branches, personal notes, or unlinked platforms.

ğŸ“‚ Folder & File Structure
Organize content into logical subfolders for easier navigation. Example structure:

bash
Copy
Edit
/docs
  â”œâ”€â”€ overview.md                      # Project summary, purpose, goals
  â”œâ”€â”€ setup/
  â”‚   â”œâ”€â”€ local_dev.md                 # Local dev setup (tools, dependencies)
  â”‚   â””â”€â”€ environments.md              # Env variables, secrets, staging/prod configs
  â”œâ”€â”€ backend/
  â”‚   â”œâ”€â”€ architecture.md              # System design, flow diagrams
  â”‚   â”œâ”€â”€ auth_flow.md                 # Authentication and session logic
  â”‚   â””â”€â”€ api_reference.md             # Endpoint specs, versioning, response codes
  â”œâ”€â”€ frontend/
  â”‚   â”œâ”€â”€ component_structure.md       # Folder/component layout and naming
  â”‚   â””â”€â”€ styling.md                   # CSS, design tokens, theming
  â”œâ”€â”€ ci-cd/
  â”‚   â”œâ”€â”€ pipeline.md                  # CI/CD flow, build triggers
  â”‚   â””â”€â”€ deploy_process.md            # Manual and auto deployment steps
  â””â”€â”€ changelog.md                    # Release history, patch notes
ğŸ§¹ Naming & Formatting Conventions
 Use lowercase, hyphen-separated file names (auth-flow.md, not AuthFlow or authFlow_v1).

 All documents must be in Markdown (.md) or a consistent readable format (Notion pages, if using Notion).

 Include a clear title and introduction at the top of every file.

 Use consistent headings (##), bullet styles, code blocks, and tables across all files.

 Add anchor links and table of contents in long docs.

ğŸ“ˆ Update Discipline
 Documentation must be updated alongside any feature, refactor, or config change that affects setup, behavior, or architecture.

 Outdated documentation is worse than none â€” all docs must reflect current reality, not past plans.

 Major changes should include:

A changelog entry (changelog.md)

Version tags if docs refer to API versions or release states

 Every PR must include doc updates if it introduces a change requiring explanation. If no doc change is needed, explain why in the PR.

ğŸ‘¥ Ownership & Collaboration
 Assign documentation owners for each section (e.g., backend lead owns backend/, DevOps owns ci-cd/)

 Use reviews to ensure content is technically accurate and clearly written

 Encourage contributions from all team membersâ€”clarity helps everyone

 Periodically review and refactor documentation to keep it lean and useful

ğŸš« What to Avoid
 âŒ Donâ€™t leave setup instructions only in Slack messages or commit comments

 âŒ Donâ€™t rely on tribal knowledgeâ€”write it down

 âŒ Donâ€™t duplicate documents across folders or tools

 âŒ Donâ€™t use inconsistent formats (e.g., some docs in .docx, others in Notion)
 
 ğŸ“Œ Rule 7: Eliminate Script Chaos â€” Clean, Consolidate, and Control
There must be no mess in scripts. All scripts must be centralized, documented, purposeful, and reusable. Treat script sprawl like tech debt â€” every duplicate, broken, or forgotten script is a liability that slows down the team and adds risk.

ğŸ”¥ Immediate Cleanup Required
 Audit all existing scripts in the entire codebase â€” not just in /scripts/, but across all folders.

 Identify and remove:

 Repetitive scripts with overlapping or duplicate logic

 Outdated scripts that are no longer relevant or used

 â€œTemporaryâ€ scripts that were never cleaned up

 Scripts with unclear names or unknown purposes

 Keep only what is actively used, tested, and maintained.

â¡ Outcome: A lean, purposeful set of scripts that can be trusted by anyone on the team.

ğŸ“ Centralized Script Directory with Clear Structure
All valid scripts must be moved into a single, organized folder structure such as:

pgsql
Copy
Edit
/scripts
  â”œâ”€â”€ README.md                  # Explains the purpose and usage of this folder
  â”œâ”€â”€ dev/                       # Local development tools
  â”‚   â”œâ”€â”€ reset-db.sh
  â”‚   â””â”€â”€ start-dev.sh
  â”œâ”€â”€ deploy/
  â”‚   â”œâ”€â”€ release.sh
  â”‚   â””â”€â”€ docker-rebuild.sh
  â”œâ”€â”€ data/
  â”‚   â”œâ”€â”€ seed-users.py
  â”‚   â””â”€â”€ export-db.sh
  â”œâ”€â”€ utils/
  â”‚   â””â”€â”€ format-json.py
  â””â”€â”€ test/
      â””â”€â”€ run-all-tests.sh
 Never store scripts directly in root folders or scattered across feature directories

 Use subfolders by function (/dev/, /data/, /deploy/, /test/, /migrations/)

 Each script must serve a unique, justified purpose

ğŸ“„ Required Standards for Each Script
Every script must follow these conventions:

 Filename: Lowercase, hyphenated, and descriptive (e.g., clear-cache.sh, not a.sh or TestReset2.sh)

 Header Comment:

bash
Copy
Edit
# Purpose: Resets local database to a known state
# Usage: ./reset-db.sh [--with-demo-data]
# Requires: Docker, Postgres running locally
 Inputs & Outputs: Accept parameters and handle them correctly. Do not hard-code logic.

 Exit Codes: Fail gracefully and return non-zero status on errors.

 Security: No hard-coded secrets, passwords, or credentials. Use env vars or vaults.

 Execution: Scripts should be executable (chmod +x) and runnable from root or docs.

 No Dead Code: Remove unused functions, print statements, and commented-out experiments.

ğŸ§¼ Ongoing Script Management Rules
 Rule: One Task = One Script. If two scripts do the same thing, merge or refactor them.

 Rule: Reuse over Rewrite. If logic exists elsewhere (in another script or production code), import it or call it â€” donâ€™t duplicate it.

 Rule: Everything Documented. The /scripts/README.md must include:

 Description of every folder and its purpose

 List of all scripts with a one-line summary

 Any required setup instructions

 Rule: Remove What You Donâ€™t Use. No "just in case" or "conditional logic or feature flag this still works" files.

ğŸš« Absolutely Avoid
 âŒ Scripts with no comments or unclear intent

 âŒ Random script names like test1.py, temp.sh, fix.sh

 âŒ Copy-paste variants that only differ by a few lines

 âŒ Leaving multiple scripts that do the same task in slightly different ways

 âŒ Keeping personal or debug scripts in the main repo
 
--- 
 ğŸ Rule 8: Python Script Sanity â€” Structure, Purpose, and Cleanup
All .py scripts must be purposeful, organized, and maintained like production code â€” no â€œrandom helpers,â€ one-off experiments, or duplications are allowed.

ğŸ“ Location & Structure
 All .py scripts must live in a clear, centralized location like:

bash
Copy
Edit
/scripts
  â”œâ”€â”€ data/
  â”‚   â””â”€â”€ load_mock_users.py
  â”œâ”€â”€ utils/
  â”‚   â””â”€â”€ format_validator.py
  â”œâ”€â”€ deploy/
  â”‚   â””â”€â”€ db_migrate.py
 Avoid having .py files:

In root directories

In random feature folders

In /tests/ unless they are test files

In /notebooks/ unless tied to Jupyter workflows

ğŸ“Œ Each .py Script Must:
âœ… Have a clear purpose
âœ… Be named descriptively (e.g., generate_config.py, not stuff.py)
âœ… Include this at the top:

python
Copy
Edit
"""
Purpose: Explain what this script does in 1â€“2 sentences.
Usage: python path/to/script.py [--options]
Requirements: List any external dependencies or env vars.
"""
âœ… Handle CLI args (use argparse, click, etc.) â€” do NOT hard-code values
âœ… Use __name__ == "__main__" guard properly
âœ… Log properly instead of using print() for important info
âœ… Exit with meaningful codes for CI/CD hooks or automation
âœ… Support imports from main codebase when appropriate
âœ… Be tested â€” use mocks or unit tests if logic is non-trivial

ğŸ§¼ Code Quality Expectations
 Use black or ruff to auto-format code

 No specific implementation name (e.g., emailSender, dataProcessor) numbers or hardcoded file paths â€” use config or arguments

 If a script does something complex, break it into modules

 Add error handling â€” no stack trace dumps to users

âŒ You Must Not:
âŒ Keep local debugging scripts like test2.py, print_stuff.py, old_fix.py

âŒ Duplicate business logic that already exists in main packages

âŒ Leave behind scripts from Jupyter experiments

âŒ Use .py files to log into prod manually or tweak prod data without approval

âŒ Push personal tools or hacks into the repo

âœ… Ideal Python Script Workflow
You create a new script â†’ scripts/data/sync_to_staging.py

You explain its purpose, usage, and requirements at the top

You use argparse to allow flags like --dry-run

You log outputs cleanly and return proper exit codes

You document it in scripts/README.md under the correct section

You remove any old sync1.py, sync2.py, or similar duplicates


---
ğŸ§¹ Rule 9: Backend & Frontend Version Control â€” No More Duplication Chaos
All frontend and backend code must be centralized, single-source, and maintained like a shared production codebase. No forks, no loose copies, no abandoned or duplicate folders.

ğŸ§± 1. ğŸ“ Folder Structure â€” One Source of Truth
Ensure the project root uses clear folder boundaries like:

arduino
Copy
Edit
/backend
  â”œâ”€â”€ app/
  â”œâ”€â”€ config/
  â”œâ”€â”€ routes/
  â”œâ”€â”€ services/
  â””â”€â”€ tests/

/frontend
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ components/
  â”‚   â”œâ”€â”€ pages/
  â”‚   â”œâ”€â”€ assets/
  â”‚   â””â”€â”€ utils/
  â””â”€â”€ public/
âœ… There must be one and only one /frontend and one /backend.
âŒ No legacy folders like /web2, /old_api, /frontend-new, /backend_dev, etc.

ğŸ”¥ 2. Remove Deprecated or Duplicate Versions
Action Required:

 Audit the repo for duplicate or legacy frontend/backend directories

 Remove everything that is:

Not documented or referenced

Not actively maintained

Clearly replaced by newer versions

Marked with old_, copy_, final/, dev_2, or any similar naming

 If unsure, move legacy versions to a dated /archive/ folder with a README

ğŸš¦ 3. Use Branches & Feature Flags â€” Not Clones
 Never duplicate entire frontend or backend code for testing â€” use Git branches

 Use feature flags or toggle systems for unstable features

 Avoid dev/, test1/, or new_feature/ folders in the codebase â€” everything should be version-controlled properly

ğŸ§¼ 4. Code Cleanliness Rules
Frontend
 Every component should have a clear file and naming pattern

 Remove all unused components, CSS files, or legacy UI fragments

 Use linting (eslint, prettier) and type-checking (tsc or prop-types)

 No dead routes, test pages, or unreferenced assets

Backend
 Each service/module should have a clear owner or purpose

 Remove all endpoints that are unused or obsolete

 Use config files, not hardcoded values

 Consolidate repeated logic into shared modules/utilities

 Avoid .bak, v2, copy.py, or temp_routes.js type of files

ğŸ“‹ 5. Document Your Folder Layout
Inside both /frontend and /backend, maintain a top-level README.md describing:

Folder structure

How to run locally

Key services/components

Deployment instructions

ğŸ“ 6. Optional â€” Use Git Tags to Preserve Legacy
If you're afraid of losing old versions:

 Tag them as Git snapshots (e.g., v1.0-legacy-frontend)

 Then safely delete from the mainline repo

ğŸ§  The Philosophy
There is one backend and one frontend â€” no duplicates, no experiments lying around, and no guesswork about what version is live.

----
ğŸ§ª Rule 10: Functionality-First Cleanup â€” Never Delete Blindly
All cleanup activities â€” whether scripts, frontend code, backend services, or documentation â€” must be preceded by functional verification.

Do not remove, rename, or consolidate files unless you've confirmed their role, references, and impact.

âš ï¸ Common Violations (Real Examples Youâ€™re Facing)
Scripts deleted just because â€œthey look duplicatedâ€ â†’ broke automated flows

Components removed from frontend without checking dynamic usage

Backend routes consolidated without verifying their consumers

.py scripts renamed or removed without checking scheduled jobs or imports

---
âœ… Cleanup Must Follow These Steps:
ğŸ“Locate References
Before removing or renaming anything:

 Search the entire codebase (recursive search) for references to the file/class/function

 Check pipelines, scheduled jobs, imports, and CLI calls

 Check for links in the documentation, README files, or user-facing apps

ğŸ§  Understand the Purpose

 Read the script or module

 Identify if itâ€™s legacy, deprecated, or just poorly named

 Ask the original author or team if unclear

âœ… Verify with Tests or Manual Steps

 Check if tests cover the component

 If no tests exist, manually test the functionality

 Document what was tested and why itâ€™s safe to delete or merge

ğŸ“¥ Move to /archive/ Before Permanent Deletion

 Keep a dated snapshot of any file you're removing in /archive/<date>/

 Include a note in archive/README.md explaining why it was moved

ğŸ” All Cleanup PRs Must Include:
 A checklist of what was removed

 Evidence that the removed files are unused or tested

 A link to the archived copy (if applicable)

 Who reviewed and signed off on the deletion

ğŸ§­ Final Principle
âš ï¸ "If you canâ€™t prove a file is safe to delete, donâ€™t delete it."
All deletions must be deliberate, documented, and tested. No "spring cleaning" allowed without validation.

---
ğŸ³ Rule 11: Docker Structure Must Be Clean, Modular, and Predictable
Your Docker-related assets must follow a strict, predictable structure:

âœ… Required Standards:
Each service must have its own Dockerfile or be clearly documented as part of a multi-service build.

All Dockerfiles must:

Use official base images where possible

Be version-pinned (FROM node:18.17, not just node)

Be multi-stage if the image supports it

Avoid installing unnecessary packages

Use .dockerignore to exclude local clutter

ğŸ“‚ Suggested Structure:
bash
Copy
Edit
/docker
  â”œâ”€â”€ backend/
  â”‚   â””â”€â”€ Dockerfile
  â”œâ”€â”€ frontend/
  â”‚   â””â”€â”€ Dockerfile
  â”œâ”€â”€ nginx/
  â”‚   â””â”€â”€ Dockerfile
  â”œâ”€â”€ docker-compose.yml
  â””â”€â”€ .dockerignore
ğŸ“¦ Final Rule:
Containers must be reproducible, minimal, and contain only whatâ€™s necessary for runtime.



----
ğŸš€ Rule 12: One Self-Updating, Intelligent, End-to-End Deployment Script
There must be exactly one canonical deployment script (deploy.sh or equivalent) that serves as the single source of truth for provisioning any environmentâ€”from bare-metal/VM to productionâ€”with a single command.

Core Qualities
Self-Sufficient

Assumes a pristine OS (Ubuntu/CentOS/RHEL) with no prior state.

Updates package repositories and installs OS-level dependencies.

Comprehensive

Installs language runtimes (Node, Python, Java, etc.).

Builds or pulls container images (Docker, Kubernetes).

Provisions databases, queues, caches, storage.

Configures networking, SSL certs, firewalls, DNS.

Runs DB migrations, seed data loads, and smoke tests.

Deterministic & Idempotent

Re-running yields the same end state without duplication.

Uses lockfiles and checksum validation to pin versions.

Resilient

Detects and recovers from partial failures (network hiccups, missing packages).

Includes retry logic and rollback hooks.

Secure

Never embeds secretsâ€”fetches from a vault or secure store.

Logs metadata only; never credentials.

Integrates with CI/CD secrets management.

Self-Updating & Sync Awareness
Before any deployment, the script must:

Detect Changes

Monitor diffs in Dockerfiles, package.json/requirements.txt, IaC (Terraform/CloudFormation), migration scripts, and environment configs.

Run Pre-Deployment Analysis

Validate new dependencies install successfully.

Lint and schema-validate all configuration files.

Check for resource/port conflicts, missing provisions.

Fail Fast on Drift

If the script is out-of-date, exit with a clear error (e.g., â€œERROR: Service X added in docker-compose.yml but not provisioned in deploy.sh.â€).

Command Interface & Phases
bash
Copy
Edit
# Full deploy in one step
./deploy.sh --env production

# Granular phases
./deploy.sh --env staging --phase init    # OS & base deps
./deploy.sh --env staging --phase build   # Build & package
./deploy.sh --env staging --phase deploy  # Provision & launch
./deploy.sh --env staging --phase verify  # Smoke tests & health checks
--env: dev | staging | production

--phase (optional): init | build | deploy | verify | all (default)

Pre-Flight & Validation
Run Tests: unit, integration, and end-to-end suites.

Lint & Validate: Docker configs, YAML, JSON, IaC.

Dry-Run Mode:

bash
Copy
Edit
./deploy.sh --env production --dry-run
Outputs a full plan without executing changes.

Post-Deploy Reporting
Print service endpoints, ports, and admin URLs.

Generate a deployment manifest (deploy-manifest.json) capturing versions, commits, and timestamps.

Optionally notify stakeholders (Slack, email) with a summary.

CI/CD Integration & Enforcement
Pipeline Step: CI/CD must invoke only this script for deployments.

Staging Dry-Run: Any infra or code changes trigger an automated staging dry-run in CI.

Approval Gates: Changes to deploy.sh require Ops sign-off and two-step PR approval.

â€œIf it isnâ€™t in deploy.sh, it doesnâ€™t exist.â€ Every stack changeâ€”new service, dependency, or configâ€”must be handled by, detected in, or documented by this script.

---
ğŸ“Œ Rule 13: No Garbage, No Rot
ğŸ—‘ï¸ Absolutely no junk, clutter, or abandoned code should exist in the repositoryâ€”ever.

âœ¨ Zero-Tolerance for Mess:

No "temporary", "WIP", "old", or "copy-of" files left hanging.

No unused variables, functions, endpoints, branches, or components.

No outdated screenshots, configs, or asset folders that serve no purpose.

âœ¨ Common Violations to Eliminate:

test_final_v2_but_real_this_time.py

old-component.jsx.bak, legacy_code_archive/

Commented-out blocks of code kept "just in case"

Redundant stylesheets or duplicated configs in subfolders

Obsolete .md files with stale instructions

ğŸ”„ Ongoing Clean-Up Habits:

 Regularly audit the codebase (monthly minimum).

 Assign owners for â€œcode debt cleanupâ€ as part of sprint cycles.

 Add clean-up steps to PR reviews (e.g., "Is anything being left behind?").

âœ… Pre-Merge Checklist:

 All added files belong to the correct module or feature

 No unrelated or forgotten files included in the commit

 No leftover debugging or console.log, print() statements

 No commented-out code unless accompanied by a rationale and removal plan

ğŸ§¹ Enforced By:

Git hooks (pre-commit, pre-push)

Lint rules for unused imports, variables, unreachable code

CI checks for dead files or unreferenced modules

Directory visualizations and tree audits (tree -L 2, du -sh *)

ğŸ” If You Add, You Clean:

â€œYou touch it, you own it.â€ Additions come with the duty to remove obsolete or conflicting items nearby.
---
ğŸ“Œ Rule 14: Engage the Correct AI Agent for Every Task
ğŸ¤– Always route the task to the most capable and specialized AI agentâ€”no exceptions.

âœ¨ Do not waste compute or time using general-purpose agents for domain-specific problems (e.g., UI layout, code generation, test coverage, data extraction).

âœ¨ Match the agent to the jobâ€”front-end, back-end, infra, security, testing, documentation, data cleanup, etc.

âœ¨ If a better-suited tool or model exists (even partially), switch or escalateâ€”don't improvise.

âœ¨ Ensure the selected agent is aligned with project context, tech stack, naming conventions, and code standards.

ğŸ§  Responsibility of the implementer:

 Know your agent options and capabilities.

 Use toolchains or orchestration layers (e.g., LangChain, AutoGen, AgentOps) if applicable.

 When in doubt, escalate or document agent limitations.

â—â€œThe right agent, with the right prompt, in the right placeâ€”every time.â€

ğŸ“Œ Rule 15: Keep Documentation Clean, Clear, and Deduplicated
All documentation is as critical as codeâ€”treat it with the same rigor to ensure clarity, findability, and single sourcing.

âœ¨ Core Requirements
Single Source of Truth

Store every doc in the approved location (e.g., /docs/, wiki, Confluence).

No duplicate content across multiple folders or platforms.

Clear Structure & Naming

Use a consistent folder hierarchy (overview, setup, backend, frontend, ci-cd, changelog).

Filenames must be lowercase, hyphen-separated, and descriptive (e.g., api-versioning.md, not versionAPI.txt).

Up-to-Date & Accurate

Every PR that touches code or config must update relevant docs.

Outdated docs are worse than noneâ€”remove or archive stale content immediately.

Concise & Actionable

Keep content focused: one purpose per document.

Use tables, diagrams, or code samples only when they add direct clarity.

ğŸ”„ Ongoing Maintenance
Monthly Documentation Audit

Flag and prune duplicates, obsolete guides, or half-written drafts.

Ownership & Review

Assign a doc owner per section (e.g., backend lead owns /docs/backend/).

Include documentation review as part of your standard PR checklist.

Versioning & Changelog

When docs change significantly, add a brief entry to changelog.md with date, section, and summary.

ğŸš« What to Avoid
âŒ Scattering README files in every subfolderâ€”centralize references instead.

âŒ Copy-pasting the same content into multiple docs. Link back to the master page.

âŒ Long, unstructured â€œwall of textâ€â€”break content into headings, bullet points, and code blocks.

Copy this into your central policy doc or /docs/documentation-standards.md to enforce clean, clear, and unified documentation practices.

ğŸ“Œ Rule 16: Use Local LLMs Exclusively via Ollama, Default to TinyLlama
All on-premise language model usage must go through the Ollama framework to ensure consistency, security, and resource control.

âœ¨ Default Model

For all initial setup, prototyping, and low-compute tasks, use TinyLlama via Ollama.

ğŸ”§ Usage Requirements

Invocation

bash
Copy
Edit
ollama run tinyllama --prompt "Your prompt here"
Configuration

Store Ollama settings in a centralized config (/config/ollama.yaml).

Pin TinyLlama version to avoid drift.

Resource Constraints

Define CPU/GPU limits in Ollama profileâ€”no model may exceed allocated resources.

ğŸ”„ Model Upgrades & Overrides

To use any other local LLM, update the Ollama config and document the change in docs/llm-standards.md.

All overrides require a one-line justification in the PR and sign-off from the AI/Infra lead.

ğŸš« Whatâ€™s Forbidden

Directly calling LLM binaries or APIs outside of Ollama.

Using large, unvetted models for initial setupâ€”always start with TinyLlama.

Copy this into your /docs/llm-standards.md or the central policy file to enforce standardized, secure local LLM usage.
