# SutazAI Resource Pool Configuration
# Defines resource pools for different workload types and scheduling policies

apiVersion: v1
kind: ConfigMap
metadata:
  name: sutazai-resource-pools
  namespace: sutazai
data:
  pools.yaml: |
    # Resource Pool Definitions
    resource_pools:
      
      # Pool 1: Infrastructure Services (Always Running)
      infrastructure:
        name: "Infrastructure Services"
        description: "Core platform services that must always run"
        priority: 1000
        resources:
          cpu_cores: 6
          memory_gb: 14
          cpu_percentage: 50
          memory_percentage: 48
        services:
          - sutazai-backend
          - sutazai-frontend  
          - sutazai-postgres
          - sutazai-redis
          - sutazai-ollama
          - sutazai-neo4j
        scaling_policy:
          type: "fixed"
          min_replicas: 1
          max_replicas: 1
          auto_scale: false
        placement_constraints:
          - "node.labels.pool == infrastructure"
          - "node.labels.tier == critical"
        resource_limits:
          cpu_request: "6000m"
          cpu_limit: "8000m"
          memory_request: "14Gi"
          memory_limit: "16Gi"
        health_check:
          interval: 30
          timeout: 10
          retries: 3
          
      # Pool 2: Active AI Agents (Dynamic Scaling)
      active_agents:
        name: "Active AI Agents"
        description: "Currently running AI agents and monitoring services"
        priority: 800
        resources:
          cpu_cores: 4
          memory_gb: 8
          cpu_percentage: 33
          memory_percentage: 27
        services:
          - sutazai-hardware-resource-optimizer
          - sutazai-health-monitor
          - sutazai-prometheus
          - sutazai-grafana
          - sutazai-chromadb
          - sutazai-qdrant
          - sutazai-ai-metrics-exporter
        scaling_policy:
          type: "auto"
          min_replicas: 1
          max_replicas: 3
          auto_scale: true
          scale_up_threshold: 70
          scale_down_threshold: 30
          cooldown_period: 300
        placement_constraints:
          - "node.labels.pool == active-agents"
        resource_limits:
          cpu_request: "2000m"
          cpu_limit: "4000m"
          memory_request: "4Gi"
          memory_limit: "8Gi"
        health_check:
          interval: 60
          timeout: 15
          retries: 5
          
      # Pool 3: On-Demand ML/AI (Burst Capacity)
      ml_compute:
        name: "ML/AI Compute Pool"
        description: "Heavy compute workloads activated as needed"
        priority: 600
        resources:
          cpu_cores: 2
          memory_gb: 5
          cpu_percentage: 17
          memory_percentage: 17
        services:
          - sutazai-pytorch
          - sutazai-tensorflow
          - sutazai-jax
          - sutazai-autogen
          - sutazai-crewai
          - sutazai-langflow
          - sutazai-flowise
        scaling_policy:
          type: "burst"
          min_replicas: 0
          max_replicas: 2
          auto_scale: true
          scale_up_threshold: 60
          scale_down_threshold: 20
          cooldown_period: 600
          preemption_allowed: true
        placement_constraints:
          - "node.labels.pool == ml-compute"
        resource_limits:
          cpu_request: "500m"
          cpu_limit: "4000m"
          memory_request: "1Gi"
          memory_limit: "8Gi"
        health_check:
          interval: 120
          timeout: 30
          retries: 3
          
      # Pool 4: Development Tools (Limited Resources)
      development:
        name: "Development Tools"
        description: "Code generation and development assistance tools"
        priority: 400
        resources:
          cpu_cores: 1
          memory_gb: 2
          cpu_percentage: 8
          memory_percentage: 7
        services:
          - sutazai-aider
          - sutazai-gpt-engineer
          - sutazai-code-improver
          - sutazai-opendevin
          - sutazai-awesome-code-ai
        scaling_policy:
          type: "limited"
          min_replicas: 0
          max_replicas: 2
          auto_scale: false
          concurrent_limit: 2
        placement_constraints:
          - "node.labels.pool == development"
        resource_limits:
          cpu_request: "250m"
          cpu_limit: "1000m"
          memory_request: "256Mi"
          memory_limit: "1Gi"
        health_check:
          interval: 180
          timeout: 20
          retries: 2
          
      # Pool 5: Background Services (Lowest Priority)
      background:
        name: "Background Services"
        description: "Batch jobs and background processing"
        priority: 200
        resources:
          cpu_cores: 1
          memory_gb: 1
          cpu_percentage: 8
          memory_percentage: 3
        services:
          - sutazai-semgrep
          - sutazai-tabbyml
          - sutazai-documind
          - sutazai-finrobot
        scaling_policy:
          type: "batch"
          min_replicas: 0 
          max_replicas: 1
          auto_scale: false
          schedule_based: true
        placement_constraints:
          - "node.labels.pool == background"
        resource_limits:
          cpu_request: "100m"
          cpu_limit: "500m"
          memory_request: "128Mi"
          memory_limit: "512Mi"
        health_check:
          interval: 300
          timeout: 30
          retries: 1

    # CPU Core Affinity Mapping
    cpu_affinity:
      infrastructure:
        cores: [2, 3, 4, 5]
        ollama_cores: [6, 7, 8, 9]
      active_agents:
        cores: [10, 11]
      ml_compute:
        cores: [8, 9, 10, 11]
      development:
        cores: [11]
      background:
        cores: [11]
      system_reserved:
        cores: [0, 1]

    # Memory Pool Allocation
    memory_pools:
      infrastructure:
        total: "14Gi"
        backend: "2Gi"
        frontend: "1Gi" 
        postgres: "2Gi"
        redis: "512Mi"
        ollama: "8Gi"
        neo4j: "2Gi"
      active_agents:
        total: "8Gi"
        per_service: "1Gi"
        monitoring: "2Gi"
      ml_compute:
        total: "5Gi"
        burst_capacity: "8Gi"
      development:
        total: "2Gi"
        per_tool: "512Mi"
      background:
        total: "1Gi"
      system_buffer:
        reserved: "2Gi"
        emergency: "512Mi"

    # Quality of Service Classes
    qos_classes:
      guaranteed:
        pools: ["infrastructure"]
        cpu_limit_equals_request: true
        memory_limit_equals_request: true  
        priority: 1000
      burstable:
        pools: ["active_agents", "ml_compute"]
        cpu_request_less_than_limit: true
        memory_request_less_than_limit: true
        priority: 600
      best_effort:
        pools: ["development", "background"]
        no_resource_requests: false
        no_resource_limits: false
        priority: 200

    # Auto-scaling Policies
    autoscaling:
      horizontal_pod_autoscaler:
        enabled: true
        pools: ["active_agents", "ml_compute"]
        metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 70
          - type: Resource
            resource:
              name: memory
              target:
                type: Utilization
                averageUtilization: 80
        behavior:
          scaleUp:
            stabilizationWindowSeconds: 60
            policies:
              - type: Percent
                value: 100
                periodSeconds: 15
          scaleDown:
            stabilizationWindowSeconds: 300
            policies:
              - type: Percent
                value: 50
                periodSeconds: 60

    # Node Labeling Strategy
    node_labels:
      pool_assignments:
        infrastructure: "node.kubernetes.io/pool=infrastructure"
        active_agents: "node.kubernetes.io/pool=active-agents"
        ml_compute: "node.kubernetes.io/pool=ml-compute"
        development: "node.kubernetes.io/pool=development"
        background: "node.kubernetes.io/pool=background"
      tier_assignments:
        critical: "node.kubernetes.io/tier=critical"
        high: "node.kubernetes.io/tier=high"
        medium: "node.kubernetes.io/tier=medium"
        low: "node.kubernetes.io/tier=low"

    # Resource Monitoring and Alerts
    monitoring:
      metrics_collection:
        interval: 30
        retention: "7d"
        exporters:
          - node-exporter
          - cadvisor
          - prometheus
      alerting_rules:
        cpu_high:
          threshold: 80
          duration: "5m"
          severity: warning
        memory_high:
          threshold: 85
          duration: "3m"
          severity: warning
        pool_exhausted:
          threshold: 95
          duration: "1m"
          severity: critical
        container_restart:
          threshold: 3
          duration: "10m"
          severity: warning

    # Placement Preferences
    placement_policies:
      anti_affinity:
        database_services:
          - sutazai-postgres
          - sutazai-neo4j
          - sutazai-redis
        ai_agents:
          - sutazai-hardware-resource-optimizer
          - sutazai-health-monitor
      pod_disruption_budgets:
        infrastructure:
          min_available: "80%"
        active_agents:
          min_available: "50%"
        ml_compute:
          min_available: "25%"

    # Network Policies
    network_qos:
      infrastructure:
        bandwidth_limit: "1Gbps"
        priority_class: "high"
      active_agents:
        bandwidth_limit: "500Mbps"
        priority_class: "medium"
      ml_compute:
        bandwidth_limit: "100Mbps"
        priority_class: "low"
      development:
        bandwidth_limit: "50Mbps"
        priority_class: "low"