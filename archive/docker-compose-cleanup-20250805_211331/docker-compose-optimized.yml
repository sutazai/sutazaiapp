version: '3.8'

# Shared configuration anchors
x-common-variables: &common-env
  TZ: ${TZ:-UTC}
  SUTAZAI_ENV: ${SUTAZAI_ENV:-production}

x-ollama-config: &ollama-env
  OLLAMA_BASE_URL: http://ollama:11434
  OLLAMA_API_KEY: local
  OLLAMA_HOST: 0.0.0.0
  OLLAMA_ORIGINS: '*'

x-resource-limits: &resource-limits
  deploy:
    resources:
      limits:
        cpus: '2'
        memory: 2G
      reservations:
        cpus: '0.5'
        memory: 512M

networks:
  sutazai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
  redis_data:
  consul_data:
  rabbitmq_data:
  kong_data:
  ollama_data:
  models_data:
  shared_runtime_data:
  prometheus_data:
  grafana_data:

services:
  # Service Mesh Infrastructure
  consul:
    image: consul:1.17
    container_name: sutazai-consul
    restart: unless-stopped
    ports:
      - "10040:8500"  # UI and HTTP API
      - "10041:8600/udp"  # DNS
    environment:
      CONSUL_BIND_INTERFACE: eth0
      CONSUL_CLIENT_INTERFACE: eth0
    volumes:
      - consul_data:/consul/data
    command: agent -server -ui -bootstrap-expect=1 -client=0.0.0.0
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD", "consul", "members"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Message Queue for Async Processing
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: sutazai-rabbitmq
    restart: unless-stopped
    ports:
      - "10042:5672"   # AMQP port
      - "10043:15672"  # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-sutazai}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-sutazai_rmq}
      RABBITMQ_DEFAULT_VHOST: sutazai
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  # API Gateway
  kong:
    image: kong:3.5-alpine
    container_name: sutazai-kong
    restart: unless-stopped
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /kong/declarative/kong.yml
      KONG_PROXY_LISTEN: 0.0.0.0:8000
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_STATUS_LISTEN: 0.0.0.0:8100
      KONG_LOG_LEVEL: info
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
    volumes:
      - kong_data:/usr/local/kong/declarative
      - ./configs/kong.yml:/kong/declarative/kong.yml:ro
    ports:
      - "10001:8000"  # Proxy port
      - "10044:8001"  # Admin API
      - "10045:8100"  # Status
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Core Data Services
  postgres:
    image: postgres:16-alpine
    container_name: sutazai-postgres
    restart: unless-stopped
    <<: *resource-limits
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-sutazai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-sutazai}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "10000:5432"
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-sutazai}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: sutazai-redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_data:/data
    ports:
      - "10002:6379"
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Shared AI Runtime (Single Ollama Instance)
  ollama:
    image: ollama/ollama:latest
    container_name: sutazai-ollama
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 8G
        reservations:
          cpus: '4'
          memory: 4G
    volumes:
      - ollama_data:/root/.ollama
      - models_data:/models
      - shared_runtime_data:/shared
      - ./configs/ollama-models.txt:/etc/ollama/models.txt:ro
    ports:
      - "10104:11434"
    environment:
      <<: *ollama-env
      OLLAMA_NUM_PARALLEL: 2
      OLLAMA_NUM_THREADS: 8
      OLLAMA_MAX_LOADED_MODELS: 1
      OLLAMA_KEEP_ALIVE: 2m
      OLLAMA_FLASH_ATTENTION: 1
      OLLAMA_CPU_ONLY: 1
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Shared Python AI Runtime Container
  ai-runtime:
    image: python:3.11-slim
    container_name: sutazai-ai-runtime
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
    volumes:
      - shared_runtime_data:/app/shared
      - models_data:/app/models
      - ./scripts/ai-runtime-init.py:/app/init.py:ro
    environment:
      <<: *common-env
      <<: *ollama-env
      PYTHONUNBUFFERED: 1
      TRANSFORMERS_CACHE: /app/models/transformers
      TORCH_HOME: /app/models/torch
      HF_HOME: /app/models/huggingface
    command: >
      sh -c "
        pip install --no-cache-dir torch==2.1.0 --index-url https://download.pytorch.org/whl/cpu &&
        pip install --no-cache-dir transformers langchain langchain-community &&
        pip install --no-cache-dir chromadb qdrant-client faiss-cpu &&
        pip install --no-cache-dir fastapi uvicorn redis asyncio &&
        python /app/init.py &&
        uvicorn app:app --host 0.0.0.0 --port 8000 --workers 2
      "
    ports:
      - "11000:8000"
    networks:
      - sutazai-network
    depends_on:
      - ollama
      - consul
      - redis

  # Service Registry and Health Check
  registrator:
    image: gliderlabs/registrator:latest
    container_name: sutazai-registrator
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock
    command: -internal consul://consul:8500
    networks:
      - sutazai-network
    depends_on:
      - consul

  # Load Balancer for AI Services
  haproxy:
    image: haproxy:2.9-alpine
    container_name: sutazai-haproxy
    restart: unless-stopped
    volumes:
      - ./configs/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    ports:
      - "10047:8080"  # Stats
      - "10048:80"    # HTTP
    networks:
      - sutazai-network
    depends_on:
      - consul

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: sutazai-prometheus
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    ports:
      - "10200:9090"
    networks:
      - sutazai-network

  grafana:
    image: grafana/grafana:latest
    container_name: sutazai-grafana
    restart: unless-stopped
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-sutazai}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=redis-datasource
    ports:
      - "10201:3000"
    networks:
      - sutazai-network
    depends_on:
      - prometheus

  # Vector Database Services (using official images)
  chromadb:
    image: chromadb/chroma:latest
    container_name: sutazai-chromadb
    restart: unless-stopped
    <<: *resource-limits
    environment:
      - CHROMA_SERVER_AUTH_PROVIDER=chromadb.auth.token.TokenAuthenticationServerProvider
      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMADB_API_KEY:-test-token}
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    ports:
      - "10100:8000"
    networks:
      - sutazai-network

  qdrant:
    image: qdrant/qdrant:latest
    container_name: sutazai-qdrant
    restart: unless-stopped
    <<: *resource-limits
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
    ports:
      - "10101:6333"
      - "10102:6334"
    networks:
      - sutazai-network

  # AI Agent Services (Official Images with Ollama Adapters)
  langflow:
    image: langflowai/langflow:latest
    container_name: sutazai-langflow
    restart: unless-stopped
    environment:
      <<: *common-env
      <<: *ollama-env
      LANGFLOW_DATABASE_URL: postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres:5432/langflow
    ports:
      - "10400:7860"
    networks:
      - sutazai-network
    depends_on:
      - postgres
      - ollama
      - ai-runtime

  flowise:
    image: flowiseai/flowise:latest
    container_name: sutazai-flowise
    restart: unless-stopped
    environment:
      <<: *common-env
      PORT: 3000
      DATABASE_PATH: /opt/flowise/.flowise
      FLOWISE_USERNAME: ${FLOWISE_USERNAME:-admin}
      FLOWISE_PASSWORD: ${FLOWISE_PASSWORD:-flowise}
    ports:
      - "10401:3000"
    networks:
      - sutazai-network

  n8n:
    image: n8nio/n8n:latest
    container_name: sutazai-n8n
    restart: unless-stopped
    environment:
      <<: *common-env
      N8N_BASIC_AUTH_ACTIVE: "true"
      N8N_BASIC_AUTH_USER: ${N8N_USER:-admin}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_PASSWORD:-n8n}
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: ${POSTGRES_USER:-sutazai}
      DB_POSTGRESDB_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "10403:5678"
    networks:
      - sutazai-network
    depends_on:
      - postgres

  # Caddy as reverse proxy (lightweight alternative)
  caddy:
    image: caddy:2-alpine
    container_name: sutazai-caddy
    restart: unless-stopped
    ports:
      - "10049:80"
      - "10050:443"
    volumes:
      - ./configs/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - sutazai-network

volumes:
  caddy_data:
  caddy_config: