# Docker Compose for Ollama Integration Deployment
# Resource-optimized configuration for WSL2 environment (48GB RAM, 4GB GPU)
# Supports blue-green deployment with zero downtime

version: '3.8'

networks:
  sutazai-network:
    external: true
    name: sutazai-network
  ollama-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  ollama-models:
    driver: local
  agent-configs:
    driver: local
  monitoring-data:
    driver: local
  deployment-logs:
    driver: local

services:
  # Ollama service optimized for resource constraints
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-optimized
    restart: unless-stopped
    networks:
      - sutazai-network
      - ollama-network
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
      - /opt/sutazaiapp/config/ollama.yaml:/etc/ollama/config.yaml:ro
    environment:
      # Resource optimization for WSL2
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=3
      - OLLAMA_MAX_VRAM=3584  # 3.5GB out of 4GB GPU
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=10m
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_NOPRUNE=false
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

  # Enhanced Base Agent Template (for deployment)
  base-agent-v2-template:
    image: sutazai-agent-v2:latest
    build:
      context: ./agents/core
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: python:3.11-slim
        REQUIREMENTS_FILE: requirements.txt
    environment: &agent-env
      # Core configuration
      - AGENT_VERSION=2.0.0
      - BACKEND_URL=http://backend:8000
      - OLLAMA_URL=http://ollama-optimized:11434
      - REDIS_URL=redis://redis:6379
      - POSTGRES_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/sutazai
      
      # Ollama optimization
      - OLLAMA_MAX_CONNECTIONS=2
      - OLLAMA_REQUEST_TIMEOUT=60
      - OLLAMA_RETRY_ATTEMPTS=3
      - OLLAMA_CIRCUIT_BREAKER_THRESHOLD=5
      - OLLAMA_CIRCUIT_BREAKER_TIMEOUT=60
      
      # Resource limits
      - MAX_CONCURRENT_TASKS=3
      - MEMORY_LIMIT=256M
      - CPU_LIMIT=0.5
      
      # Monitoring
      - HEALTH_CHECK_INTERVAL=30
      - HEARTBEAT_INTERVAL=30
      - METRICS_ENABLED=true
      - LOG_LEVEL=INFO
      
      # Deployment specific
      - DEPLOYMENT_MODE=blue-green
      - GRACEFUL_SHUTDOWN_TIMEOUT=30
    networks:
      - sutazai-network
      - ollama-network
    volumes:
      - agent-configs:/app/configs:ro
      - deployment-logs:/app/logs
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "2"
    profiles:
      - template  # Only used as template, not started by default

  # Deployment Orchestrator
  deployment-orchestrator:
    image: sutazai-deployment:latest
    build:
      context: ./scripts
      dockerfile: Dockerfile.deployment
    container_name: deployment-orchestrator
    restart: "no"  # Run once per deployment
    networks:
      - sutazai-network
    environment:
      - DEPLOYMENT_ID=${DEPLOYMENT_ID:-ollama-integration}
      - MAX_CONCURRENT_DEPLOYMENTS=5
      - BATCH_SIZE=3
      - DEPLOYMENT_TIMEOUT=300
      - ROLLBACK_ENABLED=true
      - MONITORING_ENABLED=true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /opt/sutazaiapp:/app/project:ro
      - deployment-logs:/app/logs
      - ./deployment/ollama-integration:/app/config:ro
    command: ["/app/deploy-ollama-integration.sh", "deploy"]
    depends_on:
      - ollama
      - monitoring-stack
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    profiles:
      - deployment

  # Monitoring Stack for Deployment
  monitoring-stack:
    image: prom/prometheus:latest
    container_name: deployment-monitoring
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "9090:9090"
    volumes:
      - ./deployment/ollama-integration/monitoring-setup.yaml:/etc/prometheus/prometheus.yml:ro
      - monitoring-data:/prometheus
    environment:
      - DEPLOYMENT_ID=${DEPLOYMENT_ID:-ollama-integration}
      - ALERT_MANAGER_URL=http://alertmanager:9093
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - monitoring

  # Alert Manager for Deployment Monitoring
  alertmanager:
    image: prom/alertmanager:latest
    container_name: deployment-alertmanager
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    environment:
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - PAGER_DUTY_KEY=${PAGER_DUTY_KEY}
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    profiles:
      - monitoring

  # Grafana for Deployment Visualization
  grafana:
    image: grafana/grafana:latest
    container_name: deployment-grafana
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "3000:3000"
    volumes:
      - monitoring-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    profiles:
      - monitoring

  # Health Check Service
  health-checker:
    image: sutazai-health-checker:latest
    build:
      context: ./scripts
      dockerfile: Dockerfile.health-checker
    container_name: deployment-health-checker
    restart: unless-stopped
    networks:
      - sutazai-network
    environment:
      - CHECK_INTERVAL=15
      - ALERT_THRESHOLD=3
      - ROLLBACK_ON_FAILURE=true
      - DEPLOYMENT_ID=${DEPLOYMENT_ID}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - deployment-logs:/app/logs
    depends_on:
      - monitoring-stack
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
    profiles:
      - monitoring

  # Circuit Breaker Monitor
  circuit-breaker-monitor:
    image: sutazai-circuit-monitor:latest
    build:
      context: ./agents/core
      dockerfile: Dockerfile.circuit-monitor
    container_name: circuit-breaker-monitor
    restart: unless-stopped
    networks:
      - sutazai-network
      - ollama-network
    environment:
      - OLLAMA_URL=http://ollama-optimized:11434
      - REDIS_URL=redis://redis:6379
      - CIRCUIT_BREAKER_THRESHOLD=5
      - RECOVERY_TIMEOUT=60
      - MONITORING_INTERVAL=10
    volumes:
      - deployment-logs:/app/logs
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
    profiles:
      - monitoring

  # Load Balancer for Blue-Green Deployment
  nginx-lb:
    image: nginx:alpine
    container_name: deployment-load-balancer
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./nginx/nginx-deployment.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/upstream-template.conf:/etc/nginx/templates/upstream.conf.template:ro
      - ./ssl:/etc/nginx/ssl:ro
    environment:
      - DEPLOYMENT_MODE=blue-green
      - ACTIVE_ENVIRONMENT=blue  # Will be updated during deployment
      - NGINX_ENVSUBST_OUTPUT_DIR=/etc/nginx/conf.d
    depends_on:
      - ollama
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    profiles:
      - deployment

  # Service Discovery for Agent Registration
  consul:
    image: consul:latest
    container_name: deployment-consul
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "8500:8500"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
      - CONSUL_CLIENT_INTERFACE=eth0
    command: >
      consul agent
      -server
      -bootstrap-expect=1
      -ui
      -bind=0.0.0.0
      -client=0.0.0.0
      -datacenter=sutazai
      -data-dir=/consul/data
      -log-level=INFO
    volumes:
      - ./consul/config:/consul/config:ro
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    profiles:
      - deployment

  # Deployment State Manager
  state-manager:
    image: redis:alpine
    container_name: deployment-state-manager
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "6380:6379"  # Different port to avoid conflict
    command: >
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save ""
      --appendonly no
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
    profiles:
      - deployment

# Agent service templates for dynamic generation
x-agent-template: &agent-template
  image: sutazai-agent-v2:latest
  restart: unless-stopped
  networks:
    - sutazai-network
    - ollama-network
  environment: *agent-env
  volumes:
    - agent-configs:/app/configs:ro
    - deployment-logs:/app/logs
  deploy:
    resources:
      limits:
        memory: 256M
        cpus: '0.5'
      reservations:
        memory: 128M
        cpus: '0.25'
  healthcheck:
    test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/health').raise_for_status()"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "2"

# Sample enhanced agents (for canary phase)
# These will be dynamically generated during deployment

# Monitoring agents (Phase 1 - Canary)
  metrics-collector-prometheus-v2:
    <<: *agent-template
    container_name: metrics-collector-prometheus-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=metrics-collector-prometheus
      - AGENT_TYPE=monitoring
    profiles:
      - canary

  log-aggregator-loki-v2:
    <<: *agent-template
    container_name: log-aggregator-loki-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=log-aggregator-loki
      - AGENT_TYPE=monitoring
    profiles:
      - canary

  health-monitor-v2:
    <<: *agent-template
    container_name: health-monitor-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=health-monitor
      - AGENT_TYPE=monitoring
    profiles:
      - canary

  resource-visualiser-v2:
    <<: *agent-template
    container_name: resource-visualiser-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=resource-visualiser
      - AGENT_TYPE=monitoring
    profiles:
      - canary

  observability-dashboard-manager-grafana-v2:
    <<: *agent-template
    container_name: observability-dashboard-manager-grafana-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=observability-dashboard-manager-grafana
      - AGENT_TYPE=monitoring
    profiles:
      - canary

# Development agents (Phase 2 - Limited)
  ai-agent-debugger-v2:
    <<: *agent-template
    container_name: ai-agent-debugger-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=ai-agent-debugger
      - AGENT_TYPE=development
    profiles:
      - limited

  code-improver-v2:
    <<: *agent-template
    container_name: code-improver-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=code-improver
      - AGENT_TYPE=development
    profiles:
      - limited

  testing-qa-validator-v2:
    <<: *agent-template
    container_name: testing-qa-validator-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=testing-qa-validator
      - AGENT_TYPE=qa
    profiles:
      - limited

# Production agents (Phase 3 - Production)
  ai-system-architect-v2:
    <<: *agent-template
    container_name: ai-system-architect-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=ai-system-architect
      - AGENT_TYPE=architecture
    profiles:
      - production

  ai-senior-backend-developer-v2:
    <<: *agent-template
    container_name: ai-senior-backend-developer-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=ai-senior-backend-developer
      - AGENT_TYPE=development
    profiles:
      - production

  infrastructure-devops-manager-v2:
    <<: *agent-template
    container_name: infrastructure-devops-manager-v2
    environment:
      <<: *agent-env
      - AGENT_NAME=infrastructure-devops-manager
      - AGENT_TYPE=devops
    profiles:
      - production

# Resource management and optimization
x-resource-constraints: &resource-constraints
  deploy:
    resources:
      limits:
        # Total system limits (48GB RAM, 4GB GPU)
        memory: 45G  # Leave 3GB for OS
        cpus: '15.0'  # Leave 1 core for OS
      reservations:
        memory: 32G
        cpus: '12.0'

# Health check defaults
x-health-check: &health-check
  healthcheck:
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s

# Logging defaults optimized for deployment
x-logging: &logging
  logging:
    driver: "json-file"
    options:
      max-size: "100m"
      max-file: "3"
      labels: "deployment=ollama-integration"

# Network aliases for service discovery
x-network-aliases: &network-aliases
  networks:
    sutazai-network:
      aliases:
        - agents.sutazai.local
    ollama-network:
      aliases:
        - ollama-clients.local