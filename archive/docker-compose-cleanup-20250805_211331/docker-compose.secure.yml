version: '3.8'

networks:
  sutazai-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "false"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    ipam:
      config:
        - subnet: 172.20.0.0/16

services:
  # Backend service with security hardening
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.secure
    container_name: sutazai-backend-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10010:8000"
    
    # Security context
    security_opt:
      - no-new-privileges:true
      - apparmor:unconfined
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    
    # Read-only root filesystem with writable volumes
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
      - /var/tmp:noexec,nosuid,size=50m
    
    volumes:
      - backend_logs:/app/logs:rw
      - backend_data:/app/data:rw
      
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
          pids: 1000
        reservations:
          cpus: '1'
          memory: 1G
    
    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - DEBUG=false
      - API_V1_STR=/api/v1
      - BACKEND_CORS_ORIGINS=["http://localhost:10011"]
      - DATABASE_URL=postgresql://${POSTGRES_USER:-sutazai}:${POSTGRES_PASSWORD}@postgres-secure:5432/${POSTGRES_DB:-sutazai}
      - REDIS_URL=redis://redis-secure:6379/0
      - OLLAMA_BASE_URL=http://ollama-secure:11434
      - SUTAZAI_ENV=${SUTAZAI_ENV:-production}
      - TZ=${TZ:-UTC}
    
    depends_on:
      postgres-secure:
        condition: service_healthy
      redis-secure:
        condition: service_healthy
      ollama-secure:
        condition: service_healthy

  # Frontend service with security hardening
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.secure
    container_name: sutazai-frontend-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10011:8501"
    
    # Security context
    security_opt:
      - no-new-privileges:true
      - apparmor:unconfined
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    
    # Read-only root filesystem
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
      - /var/tmp:noexec,nosuid,size=50m
    
    volumes:
      - frontend_logs:/app/logs:rw
      - frontend_data:/app/data:rw
      
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
          pids: 500
        reservations:
          cpus: '0.5'
          memory: 512M
    
    # Health check
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8501/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    environment:
      - BACKEND_URL=http://backend-secure:8000
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
      - SUTAZAI_ENV=${SUTAZAI_ENV:-production}
      - TZ=${TZ:-UTC}
    
    depends_on:
      backend:
        condition: service_healthy

  # PostgreSQL with security hardening
  postgres-secure:
    image: postgres:16.3-alpine
    container_name: sutazai-postgres-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10000:5432"
    
    # Security context
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - FOWNER
      - SETGID
      - SETUID
    
    # Use non-root user (postgres user in Alpine)
    user: "999:999"
    
    volumes:
      - postgres_data_secure:/var/lib/postgresql/data:rw
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
          pids: 200
        reservations:
          cpus: '0.5'
          memory: 512M
    
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-sutazai}
      - POSTGRES_USER=${POSTGRES_USER:-sutazai}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    
    # Health check
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-sutazai}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s

  # Redis with security hardening
  redis-secure:
    image: redis:7.2-alpine
    container_name: sutazai-redis-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10001:6379"
    
    # Security context
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
    
    # Use non-root user (redis user in Alpine)
    user: "999:999"
    
    # Read-only root filesystem
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    
    volumes:
      - redis_data_secure:/data:rw
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
          pids: 100
        reservations:
          cpus: '0.25'
          memory: 256M
    
    # Custom Redis configuration for security
    command: >
      redis-server
      --save 60 1
      --loglevel warning
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --protected-mode yes
      --port 6379
      --bind 0.0.0.0
    
    # Health check
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Ollama with security hardening
  ollama-secure:
    image: ollama/ollama:latest
    container_name: sutazai-ollama-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10104:11434"
    
    # Security context (minimal for AI workload)
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - FOWNER
      - SETGID
      - SETUID
    
    volumes:
      - ollama_data_secure:/root/.ollama:rw
      - models_data_secure:/models:rw
    
    # Resource limits (generous for AI workload)
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
          pids: 1000
        reservations:
          cpus: '2'
          memory: 4G
    
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_KEEP_ALIVE=10m
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_NUM_PARALLEL=20
      - OLLAMA_TMPDIR=/tmp
    
    # Health check
    healthcheck:
      test: ["CMD-SHELL", "ollama list > /dev/null || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # Monitoring: Prometheus with security hardening
  prometheus-secure:
    image: prom/prometheus:latest
    container_name: sutazai-prometheus-secure
    restart: unless-stopped
    networks:
      - sutazai-network
    ports:
      - "10200:9090"
    
    # Security context
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    
    # Use non-root user
    user: "65534:65534"
    
    # Read-only root filesystem
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data_secure:/prometheus:rw
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
          pids: 200
        reservations:
          cpus: '0.5'
          memory: 512M
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
    
    # Health check
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Security scanner service
  trivy-scanner:
    image: aquasec/trivy:latest
    container_name: sutazai-trivy-scanner
    restart: "no"
    networks:
      - sutazai-network
    
    # Security context
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    
    # Read-only root filesystem
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=200m
    
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - trivy_cache:/root/.cache/trivy:rw
      - ./security-reports:/reports:rw
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
          pids: 100
        reservations:
          cpus: '0.25'
          memory: 256M
    
    command: >
      sh -c "
      echo 'Starting periodic security scans...' &&
      while true; do
        trivy image --severity HIGH,CRITICAL --format table --output /reports/scan_$(date +%Y%m%d_%H%M%S).txt sutazai-backend-secure || true
        trivy image --severity HIGH,CRITICAL --format table --output /reports/scan_$(date +%Y%m%d_%H%M%S).txt sutazai-frontend-secure || true
        echo 'Security scan completed. Sleeping for 24 hours...'
        sleep 86400
      done
      "

volumes:
  # Secure volume definitions
  backend_logs:
    driver: local
  backend_data:
    driver: local
  frontend_logs:
    driver: local
  frontend_data:
    driver: local
  postgres_data_secure:
    driver: local
  redis_data_secure:
    driver: local
  ollama_data_secure:
    driver: local
  models_data_secure:
    driver: local
  prometheus_data_secure:
    driver: local
  trivy_cache:
    driver: local

# Security: Define common configurations
x-security-common: &security-common
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  read_only: true
  tmpfs:
    - /tmp:noexec,nosuid,size=100m

x-resource-limits: &resource-limits
  deploy:
    resources:
      limits:
        pids: 1000
      reservations:
        cpus: '0.25'
        memory: 256M