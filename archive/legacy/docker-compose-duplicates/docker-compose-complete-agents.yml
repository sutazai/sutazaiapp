version: '3.9'

networks:
  sutazai-network:
    external: true

volumes:
  autogpt_data:
  # localagi_data (removed):
  tabby_data:
  semgrep_data:
  browser_data:
  skyvern_data:
  documind_data:
  finrobot_data:
  gpt_engineer_data:
  aider_data:
  # bigagi_data (removed):
  agentzero_data:
  langflow_data:
  dify_data:
  autogen_data:
  crewai_data:
  agentgpt_data:
  privategpt_data:
  llamaindex_data:
  flowise_data:
  shellgpt_data:
  pentestgpt_data:
  pytorch_data:
  tensorflow_data:

services:
  # Letta (Task Automation)
  letta:
    image: letta/letta:latest
    container_name: sutazai-letta
    restart: unless-stopped
    ports:
      - "8200:8283"
    volumes:
      - letta_data:/app/data
    environment:
      - LETTA_SERVER_PASS=sutazai123
    networks:
      - sutazai-network
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8283/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AutoGPT (Task Automation)
  autogpt:
    build:
      context: ./agents/autogpt
      dockerfile: Dockerfile
    container_name: sutazai-autogpt
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - autogpt_data:/app/data
      - ./agents/autogpt/workspace:/app/workspace
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - OPENAI_API_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # LocalAGI (Autonomous AI Orchestration)
  # LocalAGI service removed
    image: mudler/# LocalAGI service removed
    container_name: sutazai-localagi
    restart: unless-stopped
    ports:
      - "8081:8080"
    volumes:
      - # localagi_data (removed):/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # TabbyML (Code Completion)
  tabbyml:
    image: tabbyml/tabby:latest
    container_name: sutazai-tabbyml
    restart: unless-stopped
    ports:
      - "8082:8080"
    volumes:
      - tabby_data:/data
    command: serve --model TabbyML/CodeLlama-7B --device cpu
    networks:
      - sutazai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Semgrep (Code Security)
  semgrep:
    image: semgrep/semgrep:latest
    container_name: sutazai-semgrep
    restart: unless-stopped
    ports:
      - "8083:8080"
    volumes:
      - semgrep_data:/tmp
      - ./agents/semgrep/workspace:/workspace
    environment:
      - SEMGREP_SEND_METRICS=false
    networks:
      - sutazai-network
    command: --config=auto /workspace

  # Browser Use (Web Automation)
  browser-use:
    build:
      context: ./agents/browser-use
      dockerfile: Dockerfile
    container_name: sutazai-browser-use
    restart: unless-stopped
    ports:
      - "8084:8080"
    volumes:
      - browser_data:/app/data
    environment:
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # Skyvern (Advanced Web Automation)
  skyvern:
    image: skyvern/skyvern:latest
    container_name: sutazai-skyvern
    restart: unless-stopped
    ports:
      - "8085:8080"
    volumes:
      - skyvern_data:/app/data
    environment:
      - LLM_PROVIDER=ollama
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # Qdrant (Vector Database)
  qdrant-agent:
    image: qdrant/qdrant:latest
    container_name: sutazai-qdrant-agent
    restart: unless-stopped
    ports:
      - "8086:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - sutazai-network

  # PyTorch (ML Framework)
  pytorch:
    image: pytorch/pytorch:latest
    container_name: sutazai-pytorch
    restart: unless-stopped
    ports:
      - "8087:8888"
    volumes:
      - pytorch_data:/workspace
    environment:
      - JUPYTER_ENABLE_LAB=yes
    networks:
      - sutazai-network
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root

  # TensorFlow (ML Framework)
  tensorflow:
    image: tensorflow/tensorflow:latest-jupyter
    container_name: sutazai-tensorflow
    restart: unless-stopped
    ports:
      - "8088:8888"
    volumes:
      - tensorflow_data:/tf
    networks:
      - sutazai-network

  # JAX (ML Framework)
  jax:
    build:
      context: ./agents/jax
      dockerfile: Dockerfile
    container_name: sutazai-jax
    restart: unless-stopped
    ports:
      - "8089:8080"
    volumes:
      - jax_data:/app/data
    networks:
      - sutazai-network

  # LangFlow (Visual Workflows)
  langflow:
    image: langflowai/langflow:latest
    container_name: sutazai-langflow
    restart: unless-stopped
    ports:
      - "8090:7860"
    volumes:
      - langflow_data:/app/langflow
    environment:
      - LANGFLOW_DATABASE_URL=postgresql://sutazai:sutazai123@postgres:5432/sutazai_main
    networks:
      - sutazai-network
    depends_on:
      - postgres

  # Dify (App Builder)
  dify:
    image: dify/dify-api:latest
    container_name: sutazai-dify
    restart: unless-stopped
    ports:
      - "8091:5001"
    volumes:
      - dify_data:/app/data
    environment:
      - DB_USERNAME=sutazai
      - DB_PASSWORD=sutazai123
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_DATABASE=sutazai_main
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    networks:
      - sutazai-network
    depends_on:
      - postgres
      - redis

  # Documind (Document Processing)
  documind:
    build:
      context: ./agents/documind
      dockerfile: Dockerfile
    container_name: sutazai-documind
    restart: unless-stopped
    ports:
      - "8092:8080"
    volumes:
      - documind_data:/app/data
    environment:
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # FinRobot (Financial Analysis)
  finrobot:
    build:
      context: ./agents/finrobot
      dockerfile: Dockerfile
    container_name: sutazai-finrobot
    restart: unless-stopped
    ports:
      - "8093:8080"
    volumes:
      - finrobot_data:/app/data
    environment:
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # GPT Engineer (Code Generation)
  gpt-engineer:
    build:
      context: ./agents/gpt-engineer
      dockerfile: Dockerfile
    container_name: sutazai-gpt-engineer
    restart: unless-stopped
    ports:
      - "8094:8080"
    volumes:
      - gpt_engineer_data:/app/data
      - ./agents/gpt-engineer/projects:/app/projects
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - MODEL_NAME=codellama:7b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # Aider (AI Code Editor)
  aider:
    build:
      context: ./agents/aider
      dockerfile: Dockerfile
    container_name: sutazai-aider
    restart: unless-stopped
    ports:
      - "8095:8080"
    volumes:
      - aider_data:/app/data
      - ./agents/aider/workspace:/app/workspace
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - OPENAI_API_MODEL=codellama:7b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # CrewAI (Multi-Agent Collaboration)
  crewai:
    build:
      context: ./agents/crewai
      dockerfile: Dockerfile
    container_name: sutazai-crewai
    restart: unless-stopped
    ports:
      - "8096:8080"
    volumes:
      - crewai_data:/app/data
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - OPENAI_MODEL_NAME=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # PrivateGPT (Private LLM Interface)
  privategpt:
    image: zylon/private-gpt:latest
    container_name: sutazai-privategpt
    restart: unless-stopped
    ports:
      - "8097:8001"
    volumes:
      - privategpt_data:/app/data
    environment:
      - LLM_MODE=ollama
      - OLLAMA_BASE_URL=http://ollama:11434
      - EMBEDDING_MODE=ollama
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # LlamaIndex (Data Framework)
  llamaindex:
    build:
      context: ./agents/llamaindex
      dockerfile: Dockerfile
    container_name: sutazai-llamaindex
    restart: unless-stopped
    ports:
      - "8098:8080"
    volumes:
      - llamaindex_data:/app/data
    environment:
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # FlowiseAI (LLM Flows)
  flowise:
    image: flowiseai/flowise:latest
    container_name: sutazai-flowise
    restart: unless-stopped
    ports:
      - "8099:3000"
    volumes:
      - flowise_data:/root/.flowise
    environment:
      - DATABASE_PATH=/root/.flowise
      - APIKEY_PATH=/root/.flowise
      - SECRETKEY_PATH=/root/.flowise
      - LOG_LEVEL=info
    networks:
      - sutazai-network

  # ShellGPT (CLI Assistant)
  shellgpt:
    build:
      context: ./agents/shellgpt
      dockerfile: Dockerfile
    container_name: sutazai-shellgpt
    restart: unless-stopped
    volumes:
      - shellgpt_data:/app/data
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # PentestGPT (Security Testing)
  pentestgpt:
    build:
      context: ./agents/pentestgpt
      dockerfile: Dockerfile
    container_name: sutazai-pentestgpt
    restart: unless-stopped
    ports:
      - "8100:8080"
    volumes:
      - pentestgpt_data:/app/data
    environment:
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=local
      - MODEL=deepseek-r1:8b
    networks:
      - sutazai-network
    depends_on:
      - ollama

  # RealtimeSTT (Speech-to-Text)
  realtime-stt:
    build:
      context: ./agents/realtime-stt
      dockerfile: Dockerfile
    container_name: sutazai-realtime-stt
    restart: unless-stopped
    ports:
      - "8101:8080"
    volumes:
      - realtime_stt_data:/app/data
    environment:
      - WHISPER_MODEL=base
    networks:
      - sutazai-network

  letta_data:
  qdrant_data:
  jax_data:
  realtime_stt_data: