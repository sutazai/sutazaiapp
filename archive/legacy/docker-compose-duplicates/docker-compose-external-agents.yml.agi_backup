version: '3.8'

services:
  # AutoGPT Container
  autogpt:
    image: significantgravitas/autogpt:latest
    container_name: sutazai-autogpt
    ports:
      - "8080:8080"
    volumes:
      - ./external_agents/autogpt:/app/autogpt
      - ./data/autogpt:/app/data
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY:-dummy}
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-dummy}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-dummy}
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # LocalAGI Container
  localagi:
    build:
      context: ./external_agents/LocalAGI
      dockerfile: Dockerfile
    container_name: sutazai-localagi
    ports:
      - "8081:8081"
    volumes:
      - ./data/localagi:/app/data
    environment:
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - MODEL_NAME=llama3.2:1b
      - API_PORT=8081
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # TabbyML Container
  tabbyml:
    image: tabbyml/tabby:latest
    container_name: sutazai-tabbyml
    ports:
      - "8082:8082"
    volumes:
      - ./data/tabbyml:/data
    environment:
      - TABBY_MODEL=deepseek-coder:7b
      - TABBY_PORT=8082
      - TABBY_DEVICE=cpu
    command: serve --model deepseek-coder:7b --port 8082 --device cpu
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # Semgrep Container
  semgrep:
    image: returntocorp/semgrep:latest
    container_name: sutazai-semgrep
    ports:
      - "8083:8083"
    volumes:
      - ./data/semgrep:/app/data
      - ./external_agents/semgrep:/app/rules
    environment:
      - SEMGREP_RULES=p/security-audit
      - SEMGREP_PORT=8083
    command: |
      sh -c "
        echo 'Starting Semgrep service...'
        python3 -m http.server 8083 --directory /app/data
      "
    networks:
      - sutazai-network
    restart: unless-stopped

  # LangChain Agents Container
  langchain-agents:
    build:
      context: ./docker/langchain-agents
      dockerfile: Dockerfile
    container_name: sutazai-langchain-agents
    ports:
      - "8084:8084"
    volumes:
      - ./data/langchain:/app/data
    environment:
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - LANGCHAIN_MODEL=llama3.2:1b
      - LANGCHAIN_PORT=8084
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # AutoGen Container
  autogen:
    build:
      context: ./docker/autogen
      dockerfile: Dockerfile
    container_name: sutazai-autogen
    ports:
      - "8085:8085"
    volumes:
      - ./data/autogen:/app/data
    environment:
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - AUTOGEN_MODEL=llama3.2:1b
      - AUTOGEN_PORT=8085
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # AgentZero Container
  agent-zero:
    build:
      context: ./external_agents/agent-zero
      dockerfile: Dockerfile
    container_name: sutazai-agent-zero
    ports:
      - "8086:8086"
    volumes:
      - ./data/agent-zero:/app/data
    environment:
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - AGENT_ZERO_MODEL=llama3.2:1b
      - AGENT_ZERO_PORT=8086
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # BigAGI Container
  big-agi:
    build:
      context: ./external_agents/big-AGI
      dockerfile: Dockerfile
    container_name: sutazai-big-agi
    ports:
      - "8087:8087"
    volumes:
      - ./data/big-agi:/app/data
    environment:
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - BIG_AGI_MODEL=llama3.2:1b
      - BIG_AGI_PORT=8087
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # Browser Use Container
  browser-use:
    build:
      context: ./docker/browser-use
      dockerfile: Dockerfile
    container_name: sutazai-browser-use
    ports:
      - "8088:8088"
    volumes:
      - ./data/browser-use:/app/data
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
    environment:
      - DISPLAY=:0
      - BROWSER_USE_MODEL=llama3.2:1b
      - BROWSER_USE_PORT=8088
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # Skyvern Container
  skyvern:
    build:
      context: ./external_agents/skyvern
      dockerfile: Dockerfile
    container_name: sutazai-skyvern
    ports:
      - "8089:8089"
    volumes:
      - ./data/skyvern:/app/data
    environment:
      - SKYVERN_MODEL=llama3.2:1b
      - SKYVERN_PORT=8089
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # OpenWebUI Container
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: sutazai-open-webui
    ports:
      - "8090:8080"
    volumes:
      - ./data/open-webui:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://sutazai-ollama:11434
      - WEBUI_SECRET_KEY=your-secret-key
      - WEBUI_AUTH=false
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # Documind Container
  documind:
    build:
      context: ./docker/documind
      dockerfile: Dockerfile
    container_name: sutazai-documind
    ports:
      - "8091:8091"
    volumes:
      - ./data/documind:/app/data
      - ./data/documents:/app/documents
    environment:
      - DOCUMIND_MODEL=llama3.2:1b
      - DOCUMIND_PORT=8091
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # FinRobot Container
  finrobot:
    build:
      context: ./docker/finrobot
      dockerfile: Dockerfile
    container_name: sutazai-finrobot
    ports:
      - "8092:8092"
    volumes:
      - ./data/finrobot:/app/data
    environment:
      - FINROBOT_MODEL=llama3.2:1b
      - FINROBOT_PORT=8092
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
      - ALPHA_VANTAGE_API_KEY=${ALPHA_VANTAGE_API_KEY:-dummy}
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # GPT Engineer Container
  gpt-engineer:
    build:
      context: ./docker/gpt-engineer
      dockerfile: Dockerfile
    container_name: sutazai-gpt-engineer
    ports:
      - "8093:8093"
    volumes:
      - ./data/gpt-engineer:/app/data
      - ./data/projects:/app/projects
    environment:
      - GPT_ENGINEER_MODEL=deepseek-coder:7b
      - GPT_ENGINEER_PORT=8093
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # Aider Container
  aider:
    build:
      context: ./docker/aider
      dockerfile: Dockerfile
    container_name: sutazai-aider
    ports:
      - "8094:8094"
    volumes:
      - ./data/aider:/app/data
      - ./data/projects:/app/projects
    environment:
      - AIDER_MODEL=deepseek-coder:7b
      - AIDER_PORT=8094
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-ollama:ollama
    networks:
      - sutazai-network
    restart: unless-stopped

  # LangFlow Container
  langflow:
    image: langflowai/langflow:latest
    container_name: sutazai-langflow
    ports:
      - "8095:7860"
    volumes:
      - ./data/langflow:/app/data
    environment:
      - LANGFLOW_DATABASE_URL=sqlite:///./data/langflow.db
      - LANGFLOW_HOST=0.0.0.0
      - LANGFLOW_PORT=7860
    networks:
      - sutazai-network
    restart: unless-stopped

  # Dify Container
  dify:
    image: langgenius/dify-web:latest
    container_name: sutazai-dify
    ports:
      - "8096:3000"
    volumes:
      - ./data/dify:/app/data
    environment:
      - DIFY_API_URL=http://sutazai-dify-api:5001
      - DIFY_APP_URL=http://localhost:8096
    external_links:
      - sutazai-dify-api:dify-api
    networks:
      - sutazai-network
    restart: unless-stopped

  # Dify API Container
  dify-api:
    image: langgenius/dify-api:latest
    container_name: sutazai-dify-api
    ports:
      - "8097:5001"
    volumes:
      - ./data/dify-api:/app/data
    environment:
      - SECRET_KEY=your-secret-key
      - DATABASE_URL=postgresql://sutazai:sutazai_password@sutazai-postgres:5432/sutazai
      - REDIS_URL=redis://sutazai-redis:6379
      - OLLAMA_API_BASE=http://sutazai-ollama:11434
    external_links:
      - sutazai-postgres:postgres
      - sutazai-redis:redis
    networks:
      - sutazai-network
    restart: unless-stopped

  # PyTorch Container (for ML workloads)
  pytorch:
    image: pytorch/pytorch:latest
    container_name: sutazai-pytorch
    ports:
      - "8098:8098"
    volumes:
      - ./data/pytorch:/workspace
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_PORT=8098
    command: |
      sh -c "
        pip install jupyter jupyterlab
        jupyter lab --ip=0.0.0.0 --port=8098 --no-browser --allow-root
      "
    networks:
      - sutazai-network
    restart: unless-stopped

  # TensorFlow Container (for ML workloads)
  tensorflow:
    image: tensorflow/tensorflow:latest-jupyter
    container_name: sutazai-tensorflow
    ports:
      - "8099:8888"
    volumes:
      - ./data/tensorflow:/tf/notebooks
    environment:
      - JUPYTER_ENABLE_LAB=yes
    networks:
      - sutazai-network
    restart: unless-stopped

networks:
  sutazai-network:
    external: true

volumes:
  autogpt-data:
  localagi-data:
  tabbyml-data:
  semgrep-data:
  langchain-data:
  autogen-data:
  agent-zero-data:
  big-agi-data:
  browser-use-data:
  skyvern-data:
  open-webui-data:
  documind-data:
  finrobot-data:
  gpt-engineer-data:
  aider-data:
  langflow-data:
  dify-data:
  pytorch-data:
  tensorflow-data: