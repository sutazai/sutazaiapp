version: '3.9'

x-common-variables: &common-variables
  TZ: ${TZ:-UTC}

x-gpu-config: &gpu-config
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

services:

volumes:
  # Core volumes
  shared-storage:
  postgres-primary-data:
  postgres-replica-data:
  redis-data:
  redis-replica-data:

  # Model volumes
  ollama-models:
  model-cache:
  deepseek-models:
  qwen-models:

  # Vector DB volumes
  chromadb-data:
  qdrant-data:
  faiss-data:

  # Agent volumes
  gpt-engineer-data:
  autogpt-data:
  localagi-data:
  tabbyml-data:
  semgrep-data:
  langchain-data:
  autogen-data:
  agentzero-data:
  bigagi-data:
  browser-use-data:
  skyvern-data:
  agentgpt-data:
  crewai-data:
  privategpt-data:
  llamaindex-data:
  flowise-data:
  shellgpt-data:
  pentestgpt-data:

  # Service volumes
  documind-data:
  finrobot-data:
  aider-data:
  opendevin-data:
  context-engineering-data:
  fsdp-data:
  realtimestt-data:

  # ML Framework volumes
  pytorch-data:
  tensorflow-data:
  jax-data:

  # Workflow volumes
  langflow-data:
  dify-data:

  # Monitoring volumes
  prometheus-data:
  grafana-data:
  elasticsearch-data:

  # Infrastructure volumes
  consul-data:
  vault-data:
  minio-data:

services:
  # ========== GATEWAY LAYER ==========
  nginx:
    image: nginx:alpine
    container_name: sutazai-gateway
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx-v9.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/ssl:ro
    networks:
      - sutazai-public
      - sutazai-internal
    depends_on:
      - backend
      - frontend

  # ========== CORE SERVICES LAYER ==========
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.v9
    container_name: sutazai-backend
    environment:
      <<: *common-env
      DATABASE_URL: postgresql://sutazai:${DB_PASSWORD:-sutazai_password}@postgres-primary:5432/sutazai
      REDIS_URL: redis://redis-primary:6379
      CHROMADB_URL: http://chromadb-primary:8000
      QDRANT_URL: http://qdrant-primary:6333
      OLLAMA_URL: http://ollama-primary:11434
      DEEPSEEK_URL: http://deepseek-server:8084
      QWEN_URL: http://qwen-server:8085
    volumes:
      - ./backend:/app
      - shared-storage:/shared
    networks:
      - sutazai-internal
      - sutazai-data
      - sutazai-agents
    depends_on:
      postgres-primary:
        condition: service_healthy
      redis-primary:
        condition: service_healthy

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.v9
    container_name: sutazai-frontend
    ports:
      - "8501:8501"
    environment:
      <<: *common-env
      BACKEND_URL: http://backend:8000
    networks:
      - sutazai-internal
    depends_on:
      - backend

  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    container_name: sutazai-orchestrator
    environment:
      <<: *common-env
      CONSUL_URL: http://consul:8500
      VAULT_URL: http://vault:8200
    networks:
      - sutazai-internal
      - sutazai-agents
    depends_on:
      - consul
      - vault

  # ========== MODEL MANAGEMENT LAYER ==========
  ollama-primary:
    image: ollama/ollama:latest
    container_name: sutazai-ollama-primary
    <<: *gpu-resources
    environment:
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_MODELS: /models
      OLLAMA_NUM_PARALLEL: 4
    volumes:
      - ollama-models:/models
      - model-cache:/cache
      - ./scripts/model-loader-v9.sh:/startup.sh:ro
    command: ["/bin/bash", "/startup.sh"]
    networks:
      - sutazai-models
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  ollama-secondary:
    image: ollama/ollama:latest
    container_name: sutazai-ollama-secondary
    <<: *gpu-resources
    environment:
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_MODELS: /models
    volumes:
      - ollama-models:/models:ro
      - model-cache:/cache
    networks:
      - sutazai-models
    ports:
      - "11435:11434"

  deepseek-server:
    build:
      context: ./models/deepseek
      dockerfile: Dockerfile
    container_name: sutazai-deepseek
    <<: *gpu-resources
    environment:
      MODEL_NAME: deepseek-r1:8b
      MODEL_PATH: /models/deepseek-r1-8b
      INFERENCE_PORT: 8084
      MAX_BATCH_SIZE: 32
      CACHE_SIZE: 8GB
    volumes:
      - deepseek-models:/models
      - model-cache:/cache
    networks:
      - sutazai-models
    ports:
      - "8084:8084"

  qwen-server:
    build:
      context: ./models/qwen
      dockerfile: Dockerfile
    container_name: sutazai-qwen
    <<: *gpu-resources
    environment:
      MODEL_NAME: qwen3:8b
      MODEL_PATH: /models/qwen3-8b
      INFERENCE_PORT: 8085
      MAX_BATCH_SIZE: 32
      CACHE_SIZE: 8GB
    volumes:
      - qwen-models:/models
      - model-cache:/cache
    networks:
      - sutazai-models
    ports:
      - "8085:8085"

  # ========== AI AGENTS LAYER - CODE GENERATION CLUSTER ==========
  gpt-engineer:
    build:
      context: ./agents/gpt-engineer
      dockerfile: Dockerfile
    container_name: sutazai-gpt-engineer
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: gpt-engineer
      API_PORT: 8091
      BACKEND_URL: http://backend:8000
      MODEL_URL: http://ollama-primary:11434
    volumes:
      - gpt-engineer-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8091/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  aider:
    build:
      context: ./agents/aider
      dockerfile: Dockerfile
    container_name: sutazai-aider
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: aider
      API_PORT: 8092
      BACKEND_URL: http://backend:8000
      MODEL_URL: http://ollama-primary:11434
    volumes:
      - aider-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  opendevin:
    build:
      context: ./agents/opendevin
      dockerfile: Dockerfile
    container_name: sutazai-opendevin
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: opendevin
      API_PORT: 8093
      BACKEND_URL: http://backend:8000
    volumes:
      - opendevin-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  tabbyml:
    image: tabbyml/tabby:latest
    container_name: sutazai-tabbyml
    <<: *isolation
    environment:
      TABBY_MODEL: StarCoder-1B
      TABBY_HOST: 0.0.0.0
    volumes:
      - tabbyml-data:/data
    networks:
      - sutazai-agents
    ports:
      - "8081:8080"

  # ========== AI AGENTS LAYER - AUTOMATION CLUSTER ==========
  autogpt:
    build:
      context: ./agents/autogpt
      dockerfile: Dockerfile
    container_name: sutazai-autogpt
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: autogpt
      API_PORT: 8094
      BACKEND_URL: http://backend:8000
      OPENAI_API_BASE: http://ollama-primary:11434/v1
    volumes:
      - autogpt-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  localagi:
    build:
      context: ./agents/localagi
      dockerfile: Dockerfile
    container_name: sutazai-localagi
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: localagi
      API_PORT: 8095
      BACKEND_URL: http://backend:8000
    volumes:
      - localagi-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  agentzero:
    build:
      context: ./agents/agentzero
      dockerfile: Dockerfile
    container_name: sutazai-agentzero
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: agentzero
      API_PORT: 8096
    volumes:
      - agentzero-data:/data
    networks:
      - sutazai-agents

  agentgpt:
    build:
      context: ./agents/agentgpt
      dockerfile: Dockerfile
    container_name: sutazai-agentgpt
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: agentgpt
      API_PORT: 8097
    volumes:
      - agentgpt-data:/data
    networks:
      - sutazai-agents

  crewai:
    build:
      context: ./agents/crewai
      dockerfile: Dockerfile
    container_name: sutazai-crewai
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: crewai
      API_PORT: 8098
    volumes:
      - crewai-data:/data
    networks:
      - sutazai-agents

  # ========== AI AGENTS LAYER - ANALYSIS CLUSTER ==========
  semgrep:
    build:
      context: ./agents/semgrep
      dockerfile: Dockerfile
    container_name: sutazai-semgrep
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: semgrep
      API_PORT: 8099
    volumes:
      - semgrep-data:/data
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  pentestgpt:
    build:
      context: ./agents/pentestgpt
      dockerfile: Dockerfile
    container_name: sutazai-pentestgpt
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: pentestgpt
      API_PORT: 8100
    volumes:
      - pentestgpt-data:/data
    networks:
      - sutazai-agents

  finrobot:
    build:
      context: ./agents/finrobot
      dockerfile: Dockerfile
    container_name: sutazai-finrobot
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: finrobot
      API_PORT: 8101
    volumes:
      - finrobot-data:/data
    networks:
      - sutazai-agents

  documind:
    build:
      context: ./agents/documind
      dockerfile: Dockerfile
    container_name: sutazai-documind
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: documind
      API_PORT: 8102
    volumes:
      - documind-data:/data
    networks:
      - sutazai-agents

  # ========== AI AGENTS LAYER - WEB INTELLIGENCE CLUSTER ==========
  browser-use:
    build:
      context: ./agents/browser-use
      dockerfile: Dockerfile
    container_name: sutazai-browser-use
    environment:
      <<: *common-env
      SERVICE_NAME: browser-use
      API_PORT: 8103
    volumes:
      - browser-use-data:/data
    networks:
      - sutazai-agents

  skyvern:
    build:
      context: ./agents/skyvern
      dockerfile: Dockerfile
    container_name: sutazai-skyvern
    environment:
      <<: *common-env
      SERVICE_NAME: skyvern
      API_PORT: 8104
    volumes:
      - skyvern-data:/data
    networks:
      - sutazai-agents

  shellgpt:
    build:
      context: ./agents/shellgpt
      dockerfile: Dockerfile
    container_name: sutazai-shellgpt
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: shellgpt
      API_PORT: 8105
    volumes:
      - shellgpt-data:/data
    networks:
      - sutazai-agents

  # ========== AI AGENTS LAYER - SPECIALIZED AGENTS ==========
  bigagi:
    build:
      context: ./agents/bigagi
      dockerfile: Dockerfile
    container_name: sutazai-bigagi
    environment:
      <<: *common-env
      SERVICE_NAME: bigagi
      API_PORT: 8106
    volumes:
      - bigagi-data:/data
    networks:
      - sutazai-agents
    ports:
      - "8089:8106"

  privategpt:
    build:
      context: ./agents/privategpt
      dockerfile: Dockerfile
    container_name: sutazai-privategpt
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: privategpt
      API_PORT: 8107
    volumes:
      - privategpt-data:/data
    networks:
      - sutazai-agents

  llamaindex:
    build:
      context: ./agents/llamaindex
      dockerfile: Dockerfile
    container_name: sutazai-llamaindex
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: llamaindex
      API_PORT: 8108
    volumes:
      - llamaindex-data:/data
    networks:
      - sutazai-agents

  flowise:
    build:
      context: ./agents/flowise
      dockerfile: Dockerfile
    container_name: sutazai-flowise
    environment:
      <<: *common-env
      SERVICE_NAME: flowise
      API_PORT: 8109
      FLOWISE_USERNAME: admin
      FLOWISE_PASSWORD: ${FLOWISE_PASSWORD:-flowise123}
    volumes:
      - flowise-data:/data
    networks:
      - sutazai-agents
    ports:
      - "3001:8109"

  # ========== AI AGENTS LAYER - ORCHESTRATION ==========
  langchain:
    build:
      context: ./agents/langchain
      dockerfile: Dockerfile
    container_name: sutazai-langchain
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: langchain
      API_PORT: 8110
    volumes:
      - langchain-data:/data
    networks:
      - sutazai-agents

  autogen:
    build:
      context: ./agents/autogen
      dockerfile: Dockerfile
    container_name: sutazai-autogen
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: autogen
      API_PORT: 8111
    volumes:
      - autogen-data:/data
    networks:
      - sutazai-agents

  langflow:
    build:
      context: ./agents/langflow
      dockerfile: Dockerfile
    container_name: sutazai-langflow
    environment:
      <<: *common-env
      SERVICE_NAME: langflow
      API_PORT: 8112
    volumes:
      - langflow-data:/data
    networks:
      - sutazai-agents
    ports:
      - "7860:8112"

  dify:
    build:
      context: ./agents/dify
      dockerfile: Dockerfile
    container_name: sutazai-dify
    environment:
      <<: *common-env
      SERVICE_NAME: dify
      API_PORT: 8113
    volumes:
      - dify-data:/data
    networks:
      - sutazai-agents
    ports:
      - "3002:8113"

  # ========== AI AGENTS LAYER - SUPPORT SERVICES ==========
  awesome-code-ai:
    build:
      context: ./agents/awesome-code-ai
      dockerfile: Dockerfile
    container_name: sutazai-awesome-code-ai
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: awesome-code-ai
      API_PORT: 8114
    volumes:
      - shared-storage:/shared:ro
    networks:
      - sutazai-agents

  context-engineering:
    build:
      context: ./agents/context-engineering
      dockerfile: Dockerfile
    container_name: sutazai-context-engineering
    <<: *isolation
    environment:
      <<: *common-env
      SERVICE_NAME: context-engineering
      API_PORT: 8115
    volumes:
      - context-engineering-data:/data
    networks:
      - sutazai-agents

  fms-fsdp:
    build:
      context: ./agents/fms-fsdp
      dockerfile: Dockerfile
    container_name: sutazai-fms-fsdp
    <<: *gpu-resources
    environment:
      <<: *common-env
      SERVICE_NAME: fms-fsdp
      API_PORT: 8116
    volumes:
      - fsdp-data:/data
    networks:
      - sutazai-agents

  realtimestt:
    build:
      context: ./agents/realtimestt
      dockerfile: Dockerfile
    container_name: sutazai-realtimestt
    environment:
      <<: *common-env
      SERVICE_NAME: realtimestt
      API_PORT: 8117
    volumes:
      - realtimestt-data:/data
    networks:
      - sutazai-agents
    ports:
      - "8117:8117"

  # ========== DATA LAYER - VECTOR DATABASES ==========
  chromadb-primary:
    image: chromadb/chroma:latest
    container_name: sutazai-chromadb-primary
    environment:
      CHROMA_SERVER_HOST: 0.0.0.0
      CHROMA_SERVER_HTTP_PORT: 8000
      ALLOW_RESET: "false"
      ANONYMIZED_TELEMETRY: "false"
    volumes:
      - chromadb-data:/chroma/chroma
    networks:
      - sutazai-data
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 5

  qdrant-primary:
    image: qdrant/qdrant:latest
    container_name: sutazai-qdrant-primary
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: INFO
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - sutazai-data
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5

  faiss-service:
    build:
      context: ./services/faiss
      dockerfile: Dockerfile
    container_name: sutazai-faiss
    environment:
      <<: *common-env
      SERVICE_NAME: faiss
      API_PORT: 8200
    volumes:
      - faiss-data:/data
    networks:
      - sutazai-data
    ports:
      - "8200:8200"

  # ========== DATA LAYER - TRADITIONAL DATABASES ==========
  postgres-primary:
    image: postgres:16-alpine
    container_name: sutazai-postgres-primary
    environment:
      POSTGRES_DB: sutazai
      POSTGRES_USER: sutazai
      POSTGRES_PASSWORD: ${DB_PASSWORD:-sutazai_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres-primary-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - sutazai-data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sutazai"]
      interval: 30s
      timeout: 10s
      retries: 5

  postgres-replica:
    image: postgres:16-alpine
    container_name: sutazai-postgres-replica
    environment:
      POSTGRES_DB: sutazai
      POSTGRES_USER: sutazai
      POSTGRES_PASSWORD: ${DB_PASSWORD:-sutazai_password}
      POSTGRES_MASTER_SERVICE: postgres-primary
    volumes:
      - postgres-replica-data:/var/lib/postgresql/data
    networks:
      - sutazai-data
    depends_on:
      postgres-primary:
        condition: service_healthy

  redis-primary:
    image: redis:7-alpine
    container_name: sutazai-redis-primary
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - sutazai-data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis-replica:
    image: redis:7-alpine
    container_name: sutazai-redis-replica
    command: redis-server --replicaof redis-primary 6379
    volumes:
      - redis-replica-data:/data
    networks:
      - sutazai-data
    depends_on:
      redis-primary:
        condition: service_healthy

  # ========== DATA LAYER - STORAGE SERVICES ==========
  minio:
    image: minio/minio:latest
    container_name: sutazai-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio-data:/data
    networks:
      - sutazai-data
    ports:
      - "9000:9000"
      - "9001:9001"

  # ========== ML FRAMEWORKS ==========
  pytorch:
    build:
      context: ./ml/pytorch
      dockerfile: Dockerfile
    container_name: sutazai-pytorch
    <<: *gpu-resources
    environment:
      <<: *common-env
      SERVICE_NAME: pytorch
    volumes:
      - pytorch-data:/data
    networks:
      - sutazai-agents

  tensorflow:
    build:
      context: ./ml/tensorflow
      dockerfile: Dockerfile
    container_name: sutazai-tensorflow
    <<: *gpu-resources
    environment:
      <<: *common-env
      SERVICE_NAME: tensorflow
    volumes:
      - tensorflow-data:/data
    networks:
      - sutazai-agents

  jax:
    build:
      context: ./ml/jax
      dockerfile: Dockerfile
    container_name: sutazai-jax
    <<: *gpu-resources
    environment:
      <<: *common-env
      SERVICE_NAME: jax
    volumes:
      - jax-data:/data
    networks:
      - sutazai-agents

  # ========== INFRASTRUCTURE SERVICES - MONITORING ==========
  prometheus:
    image: prom/prometheus:latest
    container_name: sutazai-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus-v9.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - sutazai-monitoring
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    container_name: sutazai-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - sutazai-monitoring
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: sutazai-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - sutazai-monitoring
    ports:
      - "9200:9200"

  # ========== INFRASTRUCTURE SERVICES - SERVICE MESH ==========
  consul:
    image: consul:latest
    container_name: sutazai-consul
    command: agent -server -bootstrap-expect=1 -ui -client=0.0.0.0
    environment:
      CONSUL_BIND_INTERFACE: eth0
    volumes:
      - consul-data:/consul/data
    networks:
      - sutazai-internal
    ports:
      - "8500:8500"

  vault:
    image: vault:latest
    container_name: sutazai-vault
    cap_add:
      - IPC_LOCK
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_TOKEN:-vault-token}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    volumes:
      - vault-data:/vault/data
    networks:
      - sutazai-internal
    ports:
      - "8200:8200"