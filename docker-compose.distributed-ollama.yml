# Distributed Ollama Architecture for 131 AI Agents
# Optimized for WSL2 (48GB RAM, 4GB GPU) with OLLAMA_NUM_PARALLEL=2

version: '3.8'

networks:
  ollama-distributed:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 172.30.0.0/16
    driver_opts:
      encrypted: "true"
      
  agent-mesh:
    driver: bridge
    ipam:
      config:
        - subnet: 172.31.0.0/16

volumes:
  # Distributed cache volumes
  ollama-models:
    driver: local
  redis-data:
    driver: local
  consul-data:
    driver: local
  cache-l3:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  
  # Shared configuration
  agent-configs:
    driver: local
  circuit-breaker-state:
    driver: local

services:
  # Ollama Service with Resource Constraints
  ollama-primary:
    image: ollama/ollama:latest
    container_name: ollama-primary
    hostname: ollama-primary
    restart: unless-stopped
    networks:
      - ollama-distributed
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=3
      - OLLAMA_MAX_VRAM=3584  # 3.5GB of 4GB
      - OLLAMA_KEEP_ALIVE=10m
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_NOPRUNE=false
      - OLLAMA_DEBUG=false
    volumes:
      - ollama-models:/root/.ollama
      - ./config/ollama/models.yaml:/etc/ollama/models.yaml:ro
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        labels: "service=ollama"

  # Ollama Gateway Service
  ollama-gateway:
    image: nginx:alpine
    container_name: ollama-gateway
    restart: unless-stopped
    networks:
      - ollama-distributed
      - agent-mesh
    ports:
      - "11435:80"
    environment:
      - NGINX_ENVSUBST_TEMPLATE_DIR=/etc/nginx/templates
      - NGINX_ENVSUBST_OUTPUT_DIR=/etc/nginx/conf.d
      - UPSTREAM_OLLAMA=ollama-primary:11434
      - MAX_CONNECTIONS=10
      - REQUEST_TIMEOUT=60s
    volumes:
      - ./config/nginx/ollama-gateway.conf.template:/etc/nginx/templates/default.conf.template:ro
      - ./config/nginx/rate-limit.conf:/etc/nginx/conf.d/rate-limit.conf:ro
    depends_on:
      - ollama-primary
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Redis for Queue Management and Caching
  redis-distributed:
    image: redis:7-alpine
    container_name: redis-distributed
    restart: unless-stopped
    networks:
      - ollama-distributed
    ports:
      - "6379:6379"
    command: >
      redis-server
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 60 1000
      --appendonly yes
      --appendfsync everysec
      --tcp-backlog 511
      --timeout 0
      --tcp-keepalive 300
    volumes:
      - redis-data:/data
      - ./config/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Consul for Service Discovery
  consul-server:
    image: consul:latest
    container_name: consul-server
    restart: unless-stopped
    networks:
      - ollama-distributed
      - agent-mesh
    ports:
      - "8500:8500"
      - "8600:8600/udp"
    environment:
      - CONSUL_BIND_INTERFACE=eth0
      - CONSUL_CLIENT_INTERFACE=eth0
      - CONSUL_ENABLE_SCRIPT_CHECKS=true
    command: >
      consul agent
      -server
      -bootstrap-expect=1
      -ui
      -bind=0.0.0.0
      -client=0.0.0.0
      -datacenter=ollama-dc
      -data-dir=/consul/data
      -log-level=INFO
      -enable-script-checks
    volumes:
      - consul-data:/consul/data
      - ./config/consul:/consul/config:ro
    healthcheck:
      test: ["CMD", "consul", "members"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Request Queue Processor
  queue-processor:
    build:
      context: ./services/queue-processor
      dockerfile: Dockerfile
    image: ollama-queue-processor:latest
    container_name: queue-processor
    restart: unless-stopped
    networks:
      - ollama-distributed
    environment:
      - REDIS_URL=redis://redis-distributed:6379
      - OLLAMA_GATEWAY_URL=http://ollama-gateway
      - CONSUL_URL=http://consul-server:8500
      - MAX_WORKERS=5
      - BATCH_SIZE=3
      - BATCH_TIMEOUT_MS=100
      - LOG_LEVEL=INFO
    depends_on:
      - redis-distributed
      - ollama-gateway
      - consul-server
    volumes:
      - ./logs/queue-processor:/app/logs
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Circuit Breaker Service
  circuit-breaker:
    build:
      context: ./services/circuit-breaker
      dockerfile: Dockerfile
    image: ollama-circuit-breaker:latest
    container_name: circuit-breaker
    restart: unless-stopped
    networks:
      - ollama-distributed
    environment:
      - REDIS_URL=redis://redis-distributed:6379
      - FAILURE_THRESHOLD=5
      - RECOVERY_TIMEOUT=60
      - HALF_OPEN_REQUESTS=1
      - MONITOR_INTERVAL=10
    volumes:
      - circuit-breaker-state:/app/state
      - ./logs/circuit-breaker:/app/logs
    depends_on:
      - redis-distributed
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Distributed Cache Manager
  cache-manager:
    build:
      context: ./services/cache-manager
      dockerfile: Dockerfile
    image: ollama-cache-manager:latest
    container_name: cache-manager
    restart: unless-stopped
    networks:
      - ollama-distributed
    environment:
      - REDIS_URL=redis://redis-distributed:6379
      - L1_CACHE_SIZE_MB=10
      - L2_CACHE_SIZE_GB=1
      - L3_CACHE_PATH=/cache/l3
      - L3_CACHE_SIZE_GB=10
      - CACHE_TTL_SECONDS=3600
      - LOG_LEVEL=INFO
    volumes:
      - cache-l3:/cache/l3
      - ./logs/cache-manager:/app/logs
    depends_on:
      - redis-distributed
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Load Balancer for Agent Requests
  agent-load-balancer:
    image: haproxy:alpine
    container_name: agent-load-balancer
    restart: unless-stopped
    networks:
      - ollama-distributed
      - agent-mesh
    ports:
      - "8080:8080"
      - "8404:8404"  # Stats page
    volumes:
      - ./config/haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      - ollama-gateway
      - queue-processor
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus-distributed
    restart: unless-stopped
    networks:
      - ollama-distributed
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    volumes:
      - ./config/prometheus/prometheus-distributed.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  grafana:
    image: grafana/grafana:latest
    container_name: grafana-distributed
    restart: unless-stopped
    networks:
      - ollama-distributed
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Agent Registry Service
  agent-registry:
    build:
      context: ./services/agent-registry
      dockerfile: Dockerfile
    image: ollama-agent-registry:latest
    container_name: agent-registry
    restart: unless-stopped
    networks:
      - ollama-distributed
      - agent-mesh
    environment:
      - CONSUL_URL=http://consul-server:8500
      - REDIS_URL=redis://redis-distributed:6379
      - TOTAL_AGENTS=131
      - OPUS_AGENTS=36
      - SONNET_AGENTS=95
      - UPDATE_INTERVAL=30
    depends_on:
      - consul-server
      - redis-distributed
    volumes:
      - agent-configs:/app/configs
      - ./logs/agent-registry:/app/logs
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Resource Monitor
  resource-monitor:
    build:
      context: ./services/resource-monitor
      dockerfile: Dockerfile
    image: ollama-resource-monitor:latest
    container_name: resource-monitor
    restart: unless-stopped
    networks:
      - ollama-distributed
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - ALERT_WEBHOOK_URL=${ALERT_WEBHOOK_URL}
      - MEMORY_THRESHOLD_PERCENT=85
      - GPU_THRESHOLD_PERCENT=90
      - DEGRADATION_LEVELS=0,60,80,95
      - CHECK_INTERVAL=15
    depends_on:
      - prometheus
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs/resource-monitor:/app/logs
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Distributed Health Checker
  health-checker:
    build:
      context: ./services/health-checker
      dockerfile: Dockerfile
    image: ollama-health-checker:latest
    container_name: health-checker-distributed
    restart: unless-stopped
    networks:
      - ollama-distributed
      - agent-mesh
    environment:
      - CONSUL_URL=http://consul-server:8500
      - PROMETHEUS_URL=http://prometheus:9090
      - CHECK_INTERVAL=30
      - UNHEALTHY_THRESHOLD=3
      - LOG_LEVEL=INFO
    depends_on:
      - consul-server
      - prometheus
    volumes:
      - ./logs/health-checker:/app/logs
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

# Agent service template with distributed features
x-agent-template: &agent-template
  image: sutazai-agent-distributed:latest
  restart: unless-stopped
  networks:
    - agent-mesh
  environment:
    # Core settings
    - AGENT_VERSION=2.1.0
    - BACKEND_URL=http://backend:8000
    - OLLAMA_GATEWAY_URL=http://agent-load-balancer:8080
    
    # Service discovery
    - CONSUL_URL=http://consul-server:8500
    - SERVICE_NAME=${AGENT_NAME}
    - SERVICE_TAGS=ai,distributed
    
    # Queue configuration
    - REDIS_URL=redis://redis-distributed:6379
    - USE_PRIORITY_QUEUE=true
    - REQUEST_TIMEOUT=60
    
    # Circuit breaker
    - CIRCUIT_BREAKER_ENABLED=true
    - CIRCUIT_BREAKER_THRESHOLD=5
    - CIRCUIT_BREAKER_TIMEOUT=60
    
    # Resource limits
    - MAX_CONCURRENT_REQUESTS=3
    - MEMORY_LIMIT_MB=256
    - CPU_LIMIT=0.5
    
    # Monitoring
    - METRICS_PORT=9100
    - HEALTH_CHECK_INTERVAL=30
    - LOG_LEVEL=INFO
    
  deploy:
    resources:
      limits:
        memory: 256M
        cpus: '0.5'
      reservations:
        memory: 128M
        cpus: '0.25'
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:9100/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "2"
      labels: "agent.type,agent.name"

# Example distributed agents (extend template)
services:
  # Critical System Agents (High Priority)
  ai-system-architect-distributed:
    <<: *agent-template
    container_name: ai-system-architect-distributed
    environment:
      <<: *agent-template.environment
      - AGENT_NAME=ai-system-architect
      - AGENT_TYPE=opus
      - AGENT_PRIORITY=1
      - MAX_RETRIES=5

  infrastructure-devops-manager-distributed:
    <<: *agent-template
    container_name: infrastructure-devops-manager-distributed
    environment:
      <<: *agent-template.environment
      - AGENT_NAME=infrastructure-devops-manager
      - AGENT_TYPE=opus
      - AGENT_PRIORITY=1
      - MAX_RETRIES=5

  # Standard Agents (Medium Priority)
  code-improver-distributed:
    <<: *agent-template
    container_name: code-improver-distributed
    environment:
      <<: *agent-template.environment
      - AGENT_NAME=code-improver
      - AGENT_TYPE=sonnet
      - AGENT_PRIORITY=5
      - MAX_RETRIES=3

  testing-qa-validator-distributed:
    <<: *agent-template
    container_name: testing-qa-validator-distributed
    environment:
      <<: *agent-template.environment
      - AGENT_NAME=testing-qa-validator
      - AGENT_TYPE=sonnet
      - AGENT_PRIORITY=5
      - MAX_RETRIES=3

# Global resource constraints
x-resource-management:
  total_memory: 48G
  reserved_system: 3G
  ollama_allocation: 8G
  redis_allocation: 2G
  monitoring_allocation: 2G
  agent_allocation: 33G
  
  agent_distribution:
    opus_per_agent: 300M  # 36 * 300M = 10.8G
    sonnet_per_agent: 256M  # 95 * 256M = 24.3G
    total_agent_memory: 35.1G