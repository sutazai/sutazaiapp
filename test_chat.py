#!/usr/bin/env python3
"""Comprehensive test script to verify REAL JARVIS AI chat functionality
Tests the ACTUAL working endpoints with REAL AI responses from tinyllama
"""

import requests
import json
import sys
import time

def test_ollama_direct():
    """Test direct connection to Ollama"""
    print("Testing direct Ollama connection...")
    
    try:
        # Test from outside docker - note port 11434 not 11435
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "tinyllama:latest",
                "prompt": "Say hello in 5 words",
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 20
                }
            },
            timeout=60
        )
        print(f"  Status: {response.status_code}")
        if response.status_code == 200:
            data = response.json()
            print(f"  Response: {data.get('response', 'No response')[:100]}")
            return True
        else:
            print(f"  Error: {response.text}")
            return False
    except Exception as e:
        print(f"  Failed: {e}")
        return False

def test_backend_chat():
    """Test REAL backend chat endpoint that actually works"""
    print("\nðŸ”¥ Testing REAL Backend Chat Endpoint...")
    print("  Endpoint: http://localhost:10200/api/v1/chat/")
    
    try:
        # This is the ACTUAL working payload structure
        test_message = "What is 5 plus 3? Just give me the number."
        print(f"  Sending: '{test_message}'")
        
        start_time = time.time()
        response = requests.post(
            "http://localhost:10200/api/v1/chat/",
            json={"message": test_message},  # Simple payload that works
            timeout=60
        )
        elapsed = time.time() - start_time
        
        print(f"  Status: {response.status_code}")
        if response.status_code == 200:
            data = response.json()
            
            # Verify REAL response structure
            print(f"  âœ… Success Status: {data.get('status')}")
            print(f"  âœ… Model Used: {data.get('model')}")
            print(f"  âœ… Response Time: {elapsed:.2f}s (API: {data.get('response_time', 0):.2f}s)")
            print(f"  âœ… Session ID: {data.get('session_id')}")
            
            ai_response = data.get('response', '')
            print(f"  âœ… AI Response ({len(ai_response)} chars): {ai_response[:150]}...")
            
            # Check if AI answered correctly
            if '8' in ai_response or 'eight' in ai_response.lower():
                print(f"  âœ… AI answered the math question correctly!")
            else:
                print(f"  âš ï¸ AI response doesn't clearly contain '8'")
            
            return True, data.get('session_id')
        else:
            print(f"  âŒ Error: {response.text[:200]}")
            return False, None
    except Exception as e:
        print(f"  âŒ Failed: {e}")
        return False, None

def test_chat_simple():
    """Test simple chat endpoint"""
    print("\nTesting simple chat endpoint...")
    
    try:
        response = requests.post(
            "http://localhost:10200/api/v1/chat/simple",
            json={
                "message": "Hello, how are you?",
                "model": "tinyllama:latest"
            },
            timeout=60
        )
        print(f"  Status: {response.status_code}")
        if response.status_code == 200:
            data = response.json()
            print(f"  Response: {data.get('response', 'No response')[:100]}")
            print(f"  Success: {data.get('success')}")
            return True
        else:
            print(f"  Error: {response.text}")
            return False
    except Exception as e:
        print(f"  Failed: {e}")
        return False

def test_conversation_context(session_id):
    """Test if AI maintains conversation context"""
    print("\nðŸ§  Testing Conversation Context...")
    
    try:
        # First set context
        response1 = requests.post(
            "http://localhost:10200/api/v1/chat/",
            json={
                "message": "My name is RealTestUser. Remember this.",
                "session_id": session_id
            },
            timeout=60
        )
        
        if response1.status_code == 200:
            data1 = response1.json()
            print(f"  Context set. AI said: {data1['response'][:100]}...")
            
            # Now test memory
            response2 = requests.post(
                "http://localhost:10200/api/v1/chat/",
                json={
                    "message": "What is my name?",
                    "session_id": session_id
                },
                timeout=60
            )
            
            if response2.status_code == 200:
                data2 = response2.json()
                ai_response = data2['response'].lower()
                
                if 'realtestuser' in ai_response or 'real test user' in ai_response:
                    print(f"  âœ… AI REMEMBERS! It recalled the name")
                else:
                    print(f"  âš ï¸ AI responded but didn't recall name (common with tinyllama)")
                
                print(f"  AI response: {data2['response'][:150]}...")
                return True
        
        return False
    except Exception as e:
        print(f"  âŒ Context test failed: {e}")
        return False

def main():
    print("=" * 70)
    print("ðŸš€ JARVIS REAL AI INTEGRATION TEST")
    print("=" * 70)
    print("Testing ACTUAL working endpoints with REAL AI responses")
    
    results = []
    session_id = None
    
    # Test Ollama directly
    results.append(("Ollama Direct", test_ollama_direct()))
    
    # Test REAL backend chat endpoint
    chat_result = test_backend_chat()
    if isinstance(chat_result, tuple):
        success, session_id = chat_result
        results.append(("Backend Chat (REAL)", success))
    else:
        results.append(("Backend Chat (REAL)", chat_result))
    
    # Test conversation context if we have a session
    if session_id:
        results.append(("Conversation Context", test_conversation_context(session_id)))
    
    # Test simple chat endpoint
    results.append(("Simple Chat", test_chat_simple()))
    
    # Summary
    print("\n" + "=" * 70)
    print("ðŸ“Š TEST RESULTS SUMMARY")
    print("-" * 70)
    
    for test_name, success in results:
        status = "âœ… PASSED" if success else "âŒ FAILED"
        print(f"  {test_name:25} {status}")
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    print(f"\nOverall: {passed}/{total} tests passed ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nðŸŽ‰ ALL TESTS PASSED! JARVIS AI is fully operational with REAL AI!")
    elif passed >= total * 0.7:
        print("\nâœ… JARVIS AI is operational. Most tests passed.")
    else:
        print("\nâš ï¸ JARVIS AI has issues. Check the failures above.")
    
    return 0 if passed >= total * 0.7 else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
