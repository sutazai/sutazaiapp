# SutazAI Resource Allocation Strategy
# Optimized for CPU-only systems with intelligent scaling

resource_profiles:
  # CPU-Only System (8 cores, 16GB RAM)
  cpu_optimized:
    total_cpu: 8.0
    total_memory: 16384Mi
    
    allocations:
      # Core Infrastructure (50% of resources)
      ollama:
        cpu_limit: 4.0
        cpu_request: 2.0
        memory_limit: 8Gi
        memory_request: 4Gi
        priority: critical
        scaling: vertical
        
      postgres:
        cpu_limit: 2.0
        cpu_request: 1.0
        memory_limit: 2Gi
        memory_request: 1Gi
        priority: critical
        
      redis:
        cpu_limit: 1.0
        cpu_request: 0.5
        memory_limit: 1Gi
        memory_request: 512Mi
        priority: high
        
      backend:
        cpu_limit: 3.0
        cpu_request: 1.5
        memory_limit: 4Gi
        memory_request: 2Gi
        priority: critical
        scaling: horizontal
        
      # AI Agents (30% of resources)
      agents:
        total_cpu: 2.4
        total_memory: 4800Mi
        
        # High-priority agents
        senior-ai-engineer:
          cpu_limit: 1.5
          memory_limit: 2Gi
          instances: 1
          priority: high
          
        infrastructure-devops-manager:
          cpu_limit: 1.0
          memory_limit: 1.5Gi
          instances: 1
          priority: high
          
        deployment-automation-master:
          cpu_limit: 1.0
          memory_limit: 1.5Gi
          instances: 1
          priority: medium
          
        # Standard agents
        testing-qa-validator:
          cpu_limit: 1.0
          memory_limit: 1Gi
          instances: 1
          priority: medium
          
        ollama-integration-specialist:
          cpu_limit: 1.0
          memory_limit: 1Gi
          instances: 1
          priority: medium
      
      # Monitoring (10% of resources)
      monitoring:
        total_cpu: 0.8
        total_memory: 1600Mi
        
        prometheus:
          cpu_limit: 1.0
          memory_limit: 2Gi
          priority: medium
          
        grafana:
          cpu_limit: 1.0
          memory_limit: 1Gi
          priority: low
          
        loki:
          cpu_limit: 1.0
          memory_limit: 1Gi
          priority: low

  # GPU-Enhanced System (8 cores, 32GB RAM, 8GB VRAM)
  gpu_enhanced:
    total_cpu: 8.0
    total_memory: 32768Mi
    total_gpu: 1
    
    allocations:
      ollama:
        cpu_limit: 4.0
        memory_limit: 16Gi
        gpu_limit: 1
        gpu_memory: 8Gi
        environment:
          - CUDA_VISIBLE_DEVICES=0
          - OLLAMA_GPU_ENABLED=true
        
      backend:
        cpu_limit: 4.0
        memory_limit: 8Gi
        scaling:
          horizontal:
            min_replicas: 2
            max_replicas: 4
            target_cpu: 70
            
      agents:
        scaling:
          horizontal:
            enabled: true
            strategy: queue_based
            metrics:
              - queue_length
              - response_latency
              - cpu_utilization

# Scaling Policies
scaling_policies:
  # Horizontal Scaling Rules
  horizontal:
    backend:
      min_replicas: 1
      max_replicas: 4
      scale_up_threshold: 80  # CPU %
      scale_down_threshold: 30
      scale_up_cooldown: 300s
      scale_down_cooldown: 600s
      
    agents:
      strategy: queue_based
      queue_length_threshold: 10
      response_time_threshold: 30s
      
  # Vertical Scaling Rules  
  vertical:
    ollama:
      cpu_multiplier: 1.5
      memory_multiplier: 2.0
      max_cpu: 6.0
      max_memory: 12Gi
      
# Resource Limits by Environment
environments:
  development:
    resource_multiplier: 0.5  # Half resources
    monitoring_enabled: false
    
  staging:
    resource_multiplier: 0.8  # 80% resources
    monitoring_enabled: true
    
  production:
    resource_multiplier: 1.0  # Full resources
    monitoring_enabled: true
    backup_enabled: true
    security_hardening: true

# Queue Management
queue_management:
  redis_queues:
    high_priority:
      max_length: 100
      timeout: 300s
      retry_attempts: 3
      
    normal_priority:
      max_length: 500
      timeout: 600s
      retry_attempts: 2
      
    low_priority:
      max_length: 1000
      timeout: 1800s
      retry_attempts: 1
      
  processing_limits:
    concurrent_tasks_per_agent: 3
    max_task_duration: 1800s
    circuit_breaker_threshold: 5
    circuit_breaker_timeout: 60s

# Performance Optimization
performance:
  database:
    connection_pooling:
      min_connections: 5
      max_connections: 50
      pool_timeout: 30s
      pool_recycle: 3600s
      
  cache:
    redis_config:
      maxmemory_policy: allkeys-lru
      save_policy: "900 1 300 10 60 10000"
      
  ollama:
    optimization:
      keep_alive: 10m
      max_loaded_models: 2
      num_parallel: 2
      max_queue: 10