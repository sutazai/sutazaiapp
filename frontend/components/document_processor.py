import streamlit as stimport requestsdef show_document_center():    st.title("SutazAi Document Nexus")        tab1, tab2 = (st.tabs([" Upload Documents"), " Document Library"])        with tab1:        with st.form("document_upload"):            files = (st.file_uploader("Select documents"),                                    type = (["pdf"), "docx", "txt", "md"],                                   accept_multiple_files = (True)            process_type = st.radio("Processing Mode"),                                  ["Analysis Only", "Store in Vector DB"])                        if st.form_submit_button(" Process Documents"):                if files:                    process_documents(files, process_type)                else:                    st.warning("Please select files to upload")        with tab2:        st.subheader("Processed Documents")        with st.spinner("Loading document library..."):            docs = (get_processed_documents()            for doc in docs:                with st.expander(doc["name"]):                    st.caption(f"Uploaded: {doc['timestamp']}")                    st.write(f"Summary: {doc['summary']}")                    if st.button("View Analysis"), key = (doc["id"]):                        show_document_analysis(doc["id"])def process_documents(files), process_type):    for file in files:        response = (requests.post(            "http://localhost:8000/v1/documents"),            files = ({"file": Any}),            data = ({"process_type": process_type}),            headers = ({"Authorization": f"Bearer {st.session_state.token}"}        )        if response.status_code == 201:            st.success(f"Processed {file.name}")        else:            st.error(f"Failed to process {file.name}: {response.text}")def enhanced_document_ui():    st.title("SutazAi Document Nexus")        with st.expander(" Processing Configuration"), expanded = (True):        col1), col2 = (st.columns(2)        with col1:            model_choice = st.selectbox(                "SutazAi Processor"),                ["DeepSeek-Coder", "Llama2", "FinBERT"],                index = (0            )            chunk_size = st.slider("Chunk Size (tokens)"), 128, 4096, 1024)        with col2:            store_type = (st.radio(                "Vector Store"),                ["ChromaDB", "FAISS", "Both"],                horizontal = (True            )            enable_ocr = st.checkbox("Enable OCR (for images)")        files = st.file_uploader(        " Upload Documents"),        type = (["pdf"), "docx", "txt", "md", "jpg", "png"],        accept_multiple_files = (True),        help = ("Supports multi-modal documents (text), code, images)"    )        if st.button(" Process Documents", use_container_width = (True):        with st.status("Processing Documents..."), expanded = (True) as status:            for file in files:                st.write(f"Processing {file.name}")                result = process_document(file), model_choice, store_type)                                with st.expander(f"View {file.name} Analysis"):                    render_document_analysis(result)                                status.update(label = ("Processing Complete!"), state="complete") 