{
  "id": null,
  "title": "SutazAI v9 AI Models Performance",
  "tags": [
    "sutazai",
    "ai",
    "models",
    "performance"
  ],
  "style": "dark",
  "timezone": "browser",
  "refresh": "30s",
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "panels": [
    {
      "id": 1,
      "title": "AI Model Status",
      "type": "stat",
      "gridPos": {
        "h": 6,
        "w": 8,
        "x": 0,
        "y": 0
      },
      "targets": [
        {
          "expr": "count(ai_model_status == 1)",
          "refId": "A"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "steps": [
              {
                "color": "red",
                "value": 0
              },
              {
                "color": "yellow",
                "value": 5
              },
              {
                "color": "green",
                "value": 10
              }
            ]
          },
          "unit": "short"
        }
      },
      "options": {
        "colorMode": "background",
        "textMode": "value_and_name"
      }
    },
    {
      "id": 2,
      "title": "Total AI Requests",
      "type": "stat",
      "gridPos": {
        "h": 3,
        "w": 8,
        "x": 8,
        "y": 0
      },
      "targets": [
        {
          "expr": "sum(increase(ai_inference_requests_total[1h]))",
          "refId": "A"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "short"
        }
      }
    },
    {
      "id": 3,
      "title": "AI Request Success Rate",
      "type": "stat",
      "gridPos": {
        "h": 3,
        "w": 8,
        "x": 8,
        "y": 3
      },
      "targets": [
        {
          "expr": "(sum(increase(ai_inference_requests_total[1h])) - sum(increase(ai_inference_failures_total[1h]))) / sum(increase(ai_inference_requests_total[1h])) * 100",
          "refId": "A"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "steps": [
              {
                "color": "red",
                "value": 0
              },
              {
                "color": "yellow",
                "value": 95
              },
              {
                "color": "green",
                "value": 99
              }
            ]
          },
          "unit": "percent"
        }
      }
    },
    {
      "id": 4,
      "title": "Average Inference Time by Model",
      "type": "bargauge",
      "gridPos": {
        "h": 6,
        "w": 8,
        "x": 16,
        "y": 0
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(ai_inference_duration_seconds_bucket[5m])) by (le, model))",
          "refId": "A",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "s"
        }
      },
      "options": {
        "orientation": "horizontal",
        "displayMode": "gradient"
      }
    },
    {
      "id": 5,
      "title": "AI Inference Requests per Second",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 6
      },
      "targets": [
        {
          "expr": "sum(rate(ai_inference_requests_total[1m])) by (model)",
          "refId": "A",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "reqps"
        }
      },
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "bottom"
        }
      }
    },
    {
      "id": 6,
      "title": "AI Model Memory Usage",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 6
      },
      "targets": [
        {
          "expr": "ai_model_memory_usage_bytes / 1024 / 1024 / 1024",
          "refId": "A",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "decgbytes"
        }
      }
    },
    {
      "id": 7,
      "title": "AI Inference Duration Distribution",
      "type": "heatmap",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 14
      },
      "targets": [
        {
          "expr": "sum(rate(ai_inference_duration_seconds_bucket[5m])) by (le)",
          "refId": "A",
          "format": "heatmap",
          "legendFormat": "{{le}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "spectrum"
          },
          "unit": "s"
        }
      }
    },
    {
      "id": 8,
      "title": "AI Request Queue Length",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 14
      },
      "targets": [
        {
          "expr": "ai_request_queue_length",
          "refId": "A",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "short"
        }
      }
    },
    {
      "id": 9,
      "title": "Model-Specific Metrics",
      "type": "table",
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 22
      },
      "targets": [
        {
          "expr": "ai_model_info",
          "refId": "A",
          "format": "table"
        }
      ],
      "transformations": [
        {
          "id": "organize",
          "options": {
            "excludeByName": {
              "__name__": true,
              "instance": true,
              "job": true
            },
            "renameByName": {
              "model": "Model Name",
              "version": "Version",
              "type": "Type",
              "parameters": "Parameters",
              "gpu_memory": "GPU Memory",
              "status": "Status"
            }
          }
        }
      ]
    },
    {
      "id": 10,
      "title": "DeepSeek-R1:8B Performance",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 30
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(ai_inference_duration_seconds_bucket{model=\"deepseek-r1:8b\"}[5m])) by (le))",
          "refId": "A",
          "legendFormat": "95th percentile"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(ai_inference_duration_seconds_bucket{model=\"deepseek-r1:8b\"}[5m])) by (le))",
          "refId": "B",
          "legendFormat": "50th percentile"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "s"
        }
      }
    },
    {
      "id": 11,
      "title": "Qwen3:8B Performance",
      "type": "timeseries",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 30
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(ai_inference_duration_seconds_bucket{model=\"qwen3:8b\"}[5m])) by (le))",
          "refId": "A",
          "legendFormat": "95th percentile"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(ai_inference_duration_seconds_bucket{model=\"qwen3:8b\"}[5m])) by (le))",
          "refId": "B",
          "legendFormat": "50th percentile"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "s"
        }
      }
    }
  ]
}