global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@sutazai.com'
  smtp_auth_username: 'alerts@sutazai.com'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_hello: 'sutazai.com'
  smtp_require_tls: true

  # Global templates
  resolve_timeout: 5m
  http_config:
    tls_config:
      insecure_skip_verify: false

route:
  group_by: ['alertname', 'cluster', 'service', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default-notifications'
  
  routes:
    # Critical alerts - immediate notification via multiple channels
    - match:
        severity: critical
      receiver: 'critical-emergency'
      group_wait: 5s
      repeat_interval: 5m
      continue: true

    # AI Agents specific routing
    - match:
        component: ai_agents
      receiver: 'ai-team-notifications'
      group_wait: 30s
      repeat_interval: 30m
      routes:
        - match:
            severity: critical
          receiver: 'ai-team-critical'
          group_wait: 10s
          repeat_interval: 10m

    # Ollama service specific routing
    - match:
        component: ollama
      receiver: 'ai-infrastructure'
      group_wait: 15s
      repeat_interval: 15m

    # Database alerts routing
    - match:
        component: database
      receiver: 'database-team'
      group_wait: 30s
      repeat_interval: 1h

    # Security alerts - highest priority
    - match:
        component: security
      receiver: 'security-emergency'
      group_wait: 5s
      repeat_interval: 10m
      continue: true

    # Infrastructure alerts
    - match:
        component: infrastructure
      receiver: 'ops-team'
      group_wait: 30s
      repeat_interval: 2h

    # Service mesh alerts
    - match:
        component: service_mesh
      receiver: 'platform-team'
      group_wait: 30s
      repeat_interval: 1h

    # Business metrics alerts
    - match:  
        component: business
      receiver: 'business-team'
      group_wait: 5m
      repeat_interval: 4h

    # Container alerts
    - match:
        component: containers
      receiver: 'ops-team'
      group_wait: 1m
      repeat_interval: 1h

# Inhibition rules to reduce noise
inhibit_rules:
  # Inhibit warning alerts if critical alert for same service is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service', 'instance']
  
  # Inhibit individual service alerts if infrastructure alert is firing
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*High.*'
    equal: ['instance']

  # Inhibit agent-specific alerts if Ollama is down
  - source_match:
      alertname: 'OllamaServiceDown'
    target_match:
      component: 'ai_agents'
    equal: ['cluster']

receivers:
  # Default notification channel
  - name: 'default-notifications'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#sutazai-monitoring'
        title: 'SutazAI Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Component:* {{ .Labels.component }}
          *Time:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

  # Critical emergency notifications - multiple channels
  - name: 'critical-emergency'
    email_configs:
      - to: 'ops-team@sutazai.com,cto@sutazai.com'
        subject: 'üö® CRITICAL: SutazAI System Alert - {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL ALERT DETAILS:
          ======================
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.job }}
          Instance: {{ .Labels.instance }}
          Component: {{ .Labels.component }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ if .Annotations.runbook_url }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}
          
          This alert requires IMMEDIATE attention.
        headers:
          Priority: 'urgent'
          X-Priority: '1'
    
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#sutazai-critical'
        title: 'üö® CRITICAL SYSTEM ALERT - {{ .GroupLabels.alertname }}'
        text: |
          <!channel> CRITICAL ALERT FIRING
          {{ range .Alerts }}
          *üî• Alert:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *üè∑ Service:* {{ .Labels.job }}
          *üñ• Instance:* {{ .Labels.instance }}
          *‚è∞ Started:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: 'danger'

    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        description: '{{ .CommonAnnotations.summary }}'
        severity: 'critical'
        details:
          alert_count: '{{ len .Alerts }}'
          service: '{{ .CommonLabels.job }}'
          component: '{{ .CommonLabels.component }}'
          cluster: '{{ .CommonLabels.cluster }}'
          firing_alerts: |
            {{ range .Alerts }}{{ .Annotations.summary }}
            {{ end }}

  # AI Team notifications
  - name: 'ai-team-notifications'
    slack_configs:
      - api_url: '${SLACK_AI_WEBHOOK_URL}'
        channel: '#ai-models'
        title: 'ü§ñ AI System Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *ü§ñ Agent/Model:* {{ .Labels.job | default "Unknown" }}
          *‚ö†Ô∏è Alert:* {{ .Annotations.summary }}
          *üìù Description:* {{ .Annotations.description }}
          *üè∑ Component:* {{ .Labels.component }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'

  # AI Team critical alerts
  - name: 'ai-team-critical'
    email_configs:
      - to: 'ai-team@sutazai.com'
        subject: 'üö® CRITICAL AI System Alert - {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL AI SYSTEM ALERT:
          ========================
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Service: {{ .Labels.job }}
          Component: {{ .Labels.component }}
          Description: {{ .Annotations.description }}
          Started: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
          
          AI inference may be impacted. Immediate attention required.
        
    slack_configs:
      - api_url: '${SLACK_AI_WEBHOOK_URL}'
        channel: '#ai-critical'
        title: 'üö® CRITICAL AI ALERT - {{ .GroupLabels.alertname }}'
        text: |
          <!here> CRITICAL AI SYSTEM ISSUE
          {{ range .Alerts }}
          *üö® Alert:* {{ .Annotations.summary }}
          *ü§ñ Service:* {{ .Labels.job }}
          *üìã Details:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*üìñ Action Required:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: 'danger'

  # AI Infrastructure (Ollama) specific
  - name: 'ai-infrastructure'
    slack_configs:
      - api_url: '${SLACK_AI_WEBHOOK_URL}'
        channel: '#ollama-monitoring'
        title: '‚öôÔ∏è Ollama Infrastructure Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *‚öôÔ∏è Ollama Alert:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *üè∑ Service:* {{ .Labels.job }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true

  # Database team notifications
  - name: 'database-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#database-alerts'
        title: 'üíæ Database Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *üíæ Database:* {{ .Labels.job }}
          *‚ö†Ô∏è Alert:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true

  # Security emergency notifications
  - name: 'security-emergency'
    email_configs:
      - to: 'security@sutazai.com,ciso@sutazai.com'
        subject: 'üîí SECURITY ALERT - {{ .GroupLabels.alertname }}'
        body: |
          SECURITY INCIDENT DETECTED:
          ==========================
          {{ range .Alerts }}
          Event: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Source: {{ .Labels.instance }}
          User: {{ .Labels.user_id | default "Unknown" }}  
          IP: {{ .Labels.ip_address | default "Unknown" }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ end }}
          
          IMMEDIATE SECURITY INVESTIGATION REQUIRED.
        headers:
          Priority: 'urgent'
          X-Priority: '1'

    slack_configs:
      - api_url: '${SLACK_SECURITY_WEBHOOK_URL}'
        channel: '#security-incidents'
        title: 'üîí SECURITY INCIDENT - {{ .GroupLabels.alertname }}'
        text: |
          <!channel> SECURITY ALERT
          {{ range .Alerts }}
          *üö® Event:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *üåê Source:* {{ .Labels.instance | default "Unknown" }}
          *üë§ User:* {{ .Labels.user_id | default "Unknown" }}
          *üåç IP:* {{ .Labels.ip_address | default "Unknown" }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Response Guide:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true
        color: 'danger'

  # Operations team notifications
  - name: 'ops-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#ops-alerts'
        title: '‚öôÔ∏è Infrastructure Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *‚öôÔ∏è Infrastructure:* {{ .Labels.instance }}
          *‚ö†Ô∏è Alert:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *üè∑ Component:* {{ .Labels.component }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true

  # Platform team notifications
  - name: 'platform-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#platform-alerts'
        title: 'üîó Service Mesh Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *üîó Service:* {{ .Labels.job }}
          *‚ö†Ô∏è Alert:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true

  # Business team notifications
  - name: 'business-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#business-metrics'
        title: 'üìä Business Metrics Alert - {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *üìä Metric:* {{ .Annotations.summary }}
          *üìã Description:* {{ .Annotations.description }}
          *‚è∞ Time:* {{ .StartsAt.Format "15:04:05" }}
          {{ if .Annotations.runbook_url }}*üìñ Analysis Guide:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        send_resolved: true

templates:
  - '/etc/alertmanager/templates/*.tmpl'