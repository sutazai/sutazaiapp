groups:
  # SutazAI Production Critical Infrastructure
  - name: sutazai_infrastructure_critical
    rules:
    - alert: ServiceDown
      expr: up == 0
      for: 2m
      labels:
        severity: critical
        component: infrastructure
        team: ops
      annotations:
        summary: "Service {{ $labels.job }} is down on {{ $labels.instance }}"
        description: "Service {{ $labels.job }} has been down for more than 2 minutes. This requires immediate attention."
        runbook_url: "https://wiki.sutazai.com/runbooks/service-down"

    - alert: CriticalCPUUsage
      expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
      for: 10m
      labels:
        severity: warning
        component: infrastructure
        team: ops
      annotations:
        summary: "High CPU usage on {{ $labels.instance }}"
        description: "CPU usage is {{ $value }}% above 80% for more than 10 minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/high-cpu"

    - alert: CriticalMemoryUsage
      expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
      for: 10m
      labels:
        severity: critical
        component: infrastructure
        team: ops
      annotations:
        summary: "Critical memory usage on {{ $labels.instance }}"
        description: "Memory usage is {{ $value }}% above 90% for more than 10 minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/high-memory"

    - alert: DiskSpaceCritical
      expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 85
      for: 5m
      labels:
        severity: critical
        component: infrastructure
        team: ops
      annotations:
        summary: "Critical disk space on {{ $labels.instance }} - {{ $labels.mountpoint }}"
        description: "Disk space usage is {{ $value }}% above 85% on {{ $labels.mountpoint }}"
        runbook_url: "https://wiki.sutazai.com/runbooks/disk-space"

  # SutazAI AI Agents Monitoring (All 69 Agents)
  - name: sutazai_ai_agents
    rules:
    - alert: AIAgentDown
      expr: up{job=~"sutazai-.*-agent"} == 0
      for: 3m
      labels:
        severity: critical
        component: ai_agents
        team: ai
      annotations:
        summary: "AI Agent {{ $labels.job }} is down"
        description: "AI Agent {{ $labels.job }} on {{ $labels.instance }} has been down for 3+ minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/agent-down"

    - alert: AgentHighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=~"sutazai-.*-agent"}[5m])) > 10
      for: 5m
      labels:
        severity: warning
        component: ai_agents
        team: ai
      annotations:
        summary: "High latency for agent {{ $labels.job }}"
        description: "95th percentile latency is {{ $value }}s above 10 seconds for agent {{ $labels.job }}"
        runbook_url: "https://wiki.sutazai.com/runbooks/agent-performance"

    - alert: AgentErrorRate
      expr: rate(http_requests_total{job=~"sutazai-.*-agent",status=~"5.."}[5m]) / rate(http_requests_total{job=~"sutazai-.*-agent"}[5m]) > 0.05
      for: 3m
      labels:
        severity: critical
        component: ai_agents
        team: ai
      annotations:
        summary: "High error rate for agent {{ $labels.job }}"
        description: "Error rate is {{ $value | humanizePercentage }} above 5% for agent {{ $labels.job }}"
        runbook_url: "https://wiki.sutazai.com/runbooks/agent-errors"

    - alert: AgentMemoryLeak
      expr: increase(container_memory_working_set_bytes{name=~"sutazai-.*-agent"}[1h]) > 100*1024*1024
      for: 30m
      labels:
        severity: warning
        component: ai_agents
        team: ai
      annotations:
        summary: "Potential memory leak in {{ $labels.name }}"
        description: "Memory usage increased by {{ $value | humanize1024 }}B in the last hour"
        runbook_url: "https://wiki.sutazai.com/runbooks/memory-leak"

    - alert: AgentRestartLoop
      expr: rate(container_start_time_seconds{name=~"sutazai-.*-agent"}[10m]) > 0.1
      for: 5m
      labels:
        severity: critical
        component: ai_agents
        team: ai
      annotations:
        summary: "Agent {{ $labels.name }} in restart loop"
        description: "Agent {{ $labels.name }} is restarting frequently ({{ $value }} restarts/min)"
        runbook_url: "https://wiki.sutazai.com/runbooks/restart-loop"

  # Ollama Service Monitoring
  - name: sutazai_ollama_service
    rules:
    - alert: OllamaServiceDown
      expr: up{job="ollama"} == 0
      for: 2m
      labels:
        severity: critical
        component: ollama
        team: ai
      annotations:
        summary: "Ollama service is down"
        description: "Ollama service has been down for more than 2 minutes. All AI inference will fail."
        runbook_url: "https://wiki.sutazai.com/runbooks/ollama-down"

    - alert: OllamaHighLoadAverage
      expr: avg by(instance) (rate(ollama_inference_requests_total[5m])) > 50
      for: 10m
      labels:
        severity: warning
        component: ollama
        team: ai
      annotations:
        summary: "High load on Ollama service"
        description: "Ollama is processing {{ $value }} requests/second, above normal threshold"
        runbook_url: "https://wiki.sutazai.com/runbooks/ollama-performance"

    - alert: OllamaModelLoadFailure
      expr: increase(ollama_model_load_failures_total[5m]) > 0
      for: 1m
      labels:
        severity: critical
        component: ollama
        team: ai
      annotations:
        summary: "Ollama model load failures"
        description: "{{ $value }} model load failures in the last 5 minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/ollama-model-load"

    - alert: OllamaInferenceLatency
      expr: histogram_quantile(0.95, rate(ollama_inference_duration_seconds_bucket[5m])) > 30
      for: 10m
      labels:
        severity: warning
        component: ollama
        team: ai
      annotations:
        summary: "High Ollama inference latency"
        description: "95th percentile inference time is {{ $value }}s above 30 seconds"
        runbook_url: "https://wiki.sutazai.com/runbooks/ollama-latency"

  # Database Health Monitoring
  - name: sutazai_databases
    rules:
    - alert: PostgreSQLDown
      expr: pg_up == 0
      for: 2m
      labels:
        severity: critical
        component: database
        team: data
      annotations:
        summary: "PostgreSQL is down"
        description: "PostgreSQL database is not responding for 2+ minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/postgres-down"

    - alert: PostgreSQLHighConnections
      expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
      for: 10m
      labels:
        severity: warning
        component: database
        team: data
      annotations:
        summary: "PostgreSQL high connection usage"
        description: "Connection usage is {{ $value }}% above 80%"
        runbook_url: "https://wiki.sutazai.com/runbooks/postgres-connections"

    - alert: RedisDown
      expr: redis_up == 0
      for: 2m
      labels:
        severity: critical
        component: database
        team: data
      annotations:
        summary: "Redis is down"
        description: "Redis cache is not responding for 2+ minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/redis-down"

    - alert: RedisMemoryHigh
      expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 85
      for: 10m
      labels:
        severity: warning
        component: database
        team: data
      annotations:
        summary: "Redis high memory usage"
        description: "Redis memory usage is {{ $value }}% above 85%"
        runbook_url: "https://wiki.sutazai.com/runbooks/redis-memory"

  # Service Mesh Monitoring
  - name: sutazai_service_mesh
    rules:
    - alert: ConsulDown
      expr: up{job="consul"} == 0
      for: 3m
      labels:
        severity: critical
        component: service_mesh
        team: ops
      annotations:
        summary: "Consul service discovery is down"
        description: "Consul has been down for 3+ minutes. Service discovery will fail."
        runbook_url: "https://wiki.sutazai.com/runbooks/consul-down"

    - alert: KongGatewayDown
      expr: up{job="kong"} == 0
      for: 2m
      labels:
        severity: critical
        component: service_mesh
        team: ops
      annotations:
        summary: "Kong API Gateway is down"
        description: "Kong gateway has been down for 2+ minutes. API routing will fail."
        runbook_url: "https://wiki.sutazai.com/runbooks/kong-down"

    - alert: RabbitMQDown
      expr: up{job="rabbitmq"} == 0
      for: 2m
      labels:
        severity: critical
        component: service_mesh
        team: ops
      annotations:
        summary: "RabbitMQ message broker is down"
        description: "RabbitMQ has been down for 2+ minutes. Message queuing will fail."
        runbook_url: "https://wiki.sutazai.com/runbooks/rabbitmq-down"

    - alert: RabbitMQHighQueueSize
      expr: rabbitmq_queue_messages > 1000
      for: 15m
      labels:
        severity: warning
        component: service_mesh
        team: ops
      annotations:
        summary: "High RabbitMQ queue size"
        description: "Queue {{ $labels.queue }} has {{ $value }} messages, above 1000 threshold"
        runbook_url: "https://wiki.sutazai.com/runbooks/rabbitmq-queue"

  # Backend Services Monitoring
  - name: sutazai_backend_services
    rules:
    - alert: BackendAPIDown
      expr: up{job="sutazai-backend"} == 0
      for: 2m
      labels:
        severity: critical
        component: backend
        team: backend
      annotations:
        summary: "SutazAI Backend API is down"
        description: "Backend API has been down for 2+ minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/backend-down"

    - alert: BackendHighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="sutazai-backend"}[5m])) > 2
      for: 5m
      labels:
        severity: warning
        component: backend
        team: backend
      annotations:
        summary: "High latency in backend API"
        description: "95th percentile latency is {{ $value }}s above 2 seconds"
        runbook_url: "https://wiki.sutazai.com/runbooks/backend-latency"

    - alert: BackendErrorRate
      expr: rate(http_requests_total{job="sutazai-backend",status=~"5.."}[5m]) / rate(http_requests_total{job="sutazai-backend"}[5m]) > 0.05
      for: 5m
      labels:
        severity: critical
        component: backend
        team: backend
      annotations:
        summary: "High error rate in backend API"
        description: "Error rate is {{ $value | humanizePercentage }} above 5% for more than 5 minutes"
        runbook_url: "https://wiki.sutazai.com/runbooks/backend-errors"

  # Container Health Monitoring
  - name: sutazai_containers
    rules:
    - alert: ContainerKilled
      expr: time() - container_last_seen < 60 and container_start_time_seconds > (time() - 300)
      for: 0m
      labels:
        severity: warning
        component: containers
        team: ops
      annotations:
        summary: "Container {{ $labels.name }} was killed"
        description: "Container {{ $labels.name }} was killed and restarted recently"
        runbook_url: "https://wiki.sutazai.com/runbooks/container-killed"

    - alert: ContainerHighCPU
      expr: (sum(rate(container_cpu_usage_seconds_total[3m])) BY (instance, name) * 100) > 80
      for: 5m
      labels:
        severity: warning
        component: containers
        team: ops
      annotations:
        summary: "Container {{ $labels.name }} high CPU usage"
        description: "Container CPU usage is {{ $value }}% above 80%"
        runbook_url: "https://wiki.sutazai.com/runbooks/container-cpu"

    - alert: ContainerHighMemory
      expr: (sum(container_memory_working_set_bytes) BY (instance, name) / sum(container_spec_memory_limit_bytes > 0) BY (instance, name) * 100) > 85
      for: 5m
      labels:
        severity: warning
        component: containers
        team: ops
      annotations:
        summary: "Container {{ $labels.name }} high memory usage"
        description: "Container memory usage is {{ $value }}% above 85%"
        runbook_url: "https://wiki.sutazai.com/runbooks/container-memory"

  # Security Monitoring
  - name: sutazai_security
    rules:
    - alert: UnauthorizedAccessAttempts
      expr: rate(http_requests_total{status="401"}[5m]) > 10
      for: 5m
      labels:
        severity: warning
        component: security
        team: security
      annotations:
        summary: "High unauthorized access attempts"
        description: "{{ $value }} unauthorized access attempts per minute"
        runbook_url: "https://wiki.sutazai.com/runbooks/unauthorized-access"

    - alert: SuspiciousAPIActivity
      expr: rate(http_requests_total[1m]) > 1000
      for: 5m
      labels:
        severity: warning
        component: security
        team: security
      annotations:
        summary: "Suspicious API activity on {{ $labels.instance }}"
        description: "Unusually high API request rate: {{ $value }} requests/minute"
        runbook_url: "https://wiki.sutazai.com/runbooks/suspicious-activity"

    - alert: FailedSSHAttempts
      expr: rate(node_systemd_unit_state{name="ssh.service",state="failed"}[5m]) > 5
      for: 2m
      labels:
        severity: critical
        component: security
        team: security
      annotations:
        summary: "Multiple failed SSH attempts"
        description: "{{ $value }} failed SSH attempts per minute on {{ $labels.instance }}"
        runbook_url: "https://wiki.sutazai.com/runbooks/ssh-attacks"

  # Business Logic & Performance
  - name: sutazai_business_metrics
    rules:
    - alert: LowUserActivity
      expr: rate(user_sessions_created[1h]) < 0.1 * rate(user_sessions_created[1h] offset 1d)
      for: 30m
      labels:
        severity: warning
        component: business
        team: product
      annotations:
        summary: "Abnormally low user activity"
        description: "User sessions are 90% below normal daily pattern"
        runbook_url: "https://wiki.sutazai.com/runbooks/low-activity"

    - alert: HighAPIRateLimitHits
      expr: rate(api_rate_limit_exceeded_total[5m]) > 50
      for: 5m
      labels:
        severity: warning
        component: business
        team: product
      annotations:
        summary: "High API rate limit violations"
        description: "{{ $value }} rate limit violations per minute"
        runbook_url: "https://wiki.sutazai.com/runbooks/rate-limits"

    - alert: DataPipelineFailures
      expr: data_pipeline_success_rate < 0.95
      for: 10m
      labels:
        severity: critical
        component: business
        team: data
      annotations:
        summary: "Data pipeline failure rate high"
        description: "Data pipeline success rate is {{ $value | humanizePercentage }} below 95%"
        runbook_url: "https://wiki.sutazai.com/runbooks/data-pipeline"