# SutazAI Resource Optimization Override
# Auto-generated based on system capabilities: 20 CPUs, 20267MB RAM

x-database-resources: &database-resources
  deploy:
    resources:
      limits:
        cpus: '1.0'
        memory: 397M
      reservations:
        cpus: '0.5'
        memory: 198M
    restart_policy:
      condition: unless-stopped
      delay: 5s

x-ai-service-resources: &ai-service-resources
  deploy:
    resources:
      limits:
        cpus: '2.0'
        memory: 794M
      reservations:
        cpus: '1.0'
        memory: 397M
    restart_policy:
      condition: unless-stopped
      delay: 10s

x-agent-resources: &agent-resources
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 256M
      reservations:
        cpus: '0.25'
        memory: 128M
    restart_policy:
      condition: unless-stopped
      delay: 5s

x-monitoring-resources: &monitoring-resources
  deploy:
    resources:
      limits:
        cpus: '0.5'
        memory: 256M
      reservations:
        cpus: '0.25'
        memory: 128M

# GPU-enabled services (if GPU available)
services:
  # Core Infrastructure with optimized resources
  postgres:
    <<: *database-resources
    
  redis:
    <<: *database-resources
    
  neo4j:
    <<: *database-resources
    
  # AI/Vector Services with high resource allocation
  ollama:
    <<: *ai-service-resources
    
  chromadb:
    <<: *ai-service-resources
    
  qdrant:
    <<: *ai-service-resources
    
  faiss:
    <<: *ai-service-resources
    
  # Core Application Services
  backend-agi:
    <<: *ai-service-resources
    
  frontend-agi:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 397M
        reservations:
          cpus: '0.5'
          memory: 198M
    
  # Monitoring Services
  prometheus:
    <<: *monitoring-resources
    
  grafana:
    <<: *monitoring-resources
    
  loki:
    <<: *monitoring-resources
    
  # ML Framework Services
  pytorch:
    <<: *ai-service-resources
  tensorflow:
    <<: *ai-service-resources
  jax:
    <<: *ai-service-resources

# Set global defaults
x-defaults: &defaults
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  
  # Enable BuildKit for all builds
  x-build-args:
    BUILDKIT_INLINE_CACHE: 1
    DOCKER_BUILDKIT: 1
