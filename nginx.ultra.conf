worker_processes auto;
worker_rlimit_nofile 65535;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 100;
    reset_timedout_connection on;
    client_body_timeout 10;
    client_header_timeout 10;
    send_timeout 10;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss 
               application/rss+xml application/atom+xml image/svg+xml 
               text/x-js text/x-cross-domain-policy application/x-font-ttf 
               application/x-font-opentype application/vnd.ms-fontobject 
               image/x-icon;

    # Cache settings
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:100m 
                     max_size=1g inactive=60m use_temp_path=off;
    
    proxy_cache_path /var/cache/nginx/static levels=1:2 keys_zone=static_cache:50m 
                     max_size=500m inactive=24h use_temp_path=off;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=ollama_limit:10m rate=10r/s;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

    # Backend upstream with health checks
    upstream backend_cluster {
        least_conn;
        
        server backend:10010 max_fails=3 fail_timeout=30s;
        
        # Add more backend instances for scaling
        # server backend2:10010 max_fails=3 fail_timeout=30s;
        # server backend3:10010 max_fails=3 fail_timeout=30s;
        
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }

    # Ollama upstream
    upstream ollama_cluster {
        least_conn;
        
        server ollama:11434 max_fails=2 fail_timeout=60s;
        
        # Add more Ollama instances for scaling
        # server ollama2:11434 max_fails=2 fail_timeout=60s;
        
        keepalive 16;
        keepalive_requests 50;
        keepalive_timeout 120s;
    }

    # Frontend upstream
    upstream frontend_cluster {
        server frontend:10011 max_fails=3 fail_timeout=30s;
        
        keepalive 16;
    }

    # Main server block
    server {
        listen 80 default_server;
        server_name _;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        
        # API endpoints with caching
        location /api/ {
            # Rate limiting
            limit_req zone=api_limit burst=50 nodelay;
            limit_conn conn_limit 50;
            
            # Proxy settings
            proxy_pass http://backend_cluster;
            proxy_http_version 1.1;
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";
            
            # Timeouts optimized for fast response
            proxy_connect_timeout 2s;
            proxy_send_timeout 10s;
            proxy_read_timeout 30s;
            
            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # Cache for GET requests
            proxy_cache api_cache;
            proxy_cache_methods GET HEAD;
            proxy_cache_key "$scheme$request_method$host$request_uri$is_args$args";
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_cache_lock on;
            proxy_cache_lock_timeout 5s;
            
            add_header X-Cache-Status $upstream_cache_status;
        }
        
        # Ollama endpoints with special handling
        location /ollama/ {
            # Rate limiting for LLM requests
            limit_req zone=ollama_limit burst=5 nodelay;
            limit_conn conn_limit 10;
            
            # Rewrite to remove /ollama prefix
            rewrite ^/ollama/(.*) /api/$1 break;
            
            # Proxy to Ollama
            proxy_pass http://ollama_cluster;
            proxy_http_version 1.1;
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header Connection "";
            
            # Longer timeouts for LLM operations
            proxy_connect_timeout 5s;
            proxy_send_timeout 30s;
            proxy_read_timeout 120s;
            
            # Streaming support
            proxy_buffering off;
            chunked_transfer_encoding on;
            
            # Cache for model listings only
            location ~* ^/ollama/tags$ {
                proxy_cache api_cache;
                proxy_cache_valid 200 10m;
                add_header X-Cache-Status $upstream_cache_status;
            }
        }
        
        # Frontend
        location / {
            proxy_pass http://frontend_cluster;
            proxy_http_version 1.1;
            
            # WebSocket support for Streamlit
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts
            proxy_connect_timeout 2s;
            proxy_send_timeout 60s;
            proxy_read_timeout 86400s;
            
            # Disable buffering for WebSocket
            proxy_buffering off;
        }
        
        # Health check endpoint
        location /health {
            access_log off;
            
            default_type application/json;
            return 200 '{"status":"healthy","timestamp":"$time_iso8601"}';
        }
        
        # Metrics endpoint
        location /metrics {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 172.20.0.0/16;
            deny all;
        }
        
        # Static files with aggressive caching
        location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf|eot)$ {
            proxy_pass http://frontend_cluster;
            
            # Cache settings
            proxy_cache static_cache;
            proxy_cache_valid 200 24h;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            
            # Browser cache
            expires 7d;
            add_header Cache-Control "public, immutable";
            add_header X-Cache-Status $upstream_cache_status;
        }
    }
    
    # HTTPS server (when SSL is configured)
    server {
        listen 443 ssl http2 default_server;
        server_name _;
        
        # SSL configuration (add certificates)
        # ssl_certificate /etc/nginx/ssl/cert.pem;
        # ssl_certificate_key /etc/nginx/ssl/key.pem;
        # ssl_protocols TLSv1.2 TLSv1.3;
        # ssl_ciphers HIGH:!aNULL:!MD5;
        # ssl_prefer_server_ciphers on;
        # ssl_session_cache shared:SSL:10m;
        # ssl_session_timeout 10m;
        
        # Include all location blocks from above
        # ... (same as port 80 configuration)
    }
}