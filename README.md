# SutazAI AGI/ASI Autonomous System

A lightweight, fully local AGI system running on TinyLlama.

## ğŸš€ Quick Start

```bash
# Using Make commands (symlinked for convenience)
make setup      # Initial setup
make deploy     # Deploy the system
make status     # Check status
make verify     # Verify configuration
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ agents/         # Agent configurations and definitions
â”œâ”€â”€ archive/        # Archived files (scripts, docs, configs)
â”œâ”€â”€ backend/        # Backend API service
â”œâ”€â”€ brain/          # AGI brain components
â”œâ”€â”€ build/          # Build tools and Makefile
â”œâ”€â”€ config/         # All configuration files
â”‚   â”œâ”€â”€ docker/     # Docker compose files
â”‚   â”œâ”€â”€ project/    # Project configs (package.json, pyproject.toml)
â”‚   â””â”€â”€ security/   # Security configurations
â”œâ”€â”€ data/           # Application data
â”œâ”€â”€ docs/           # Documentation
â”œâ”€â”€ frontend/       # Frontend UI
â”œâ”€â”€ localagi/       # LocalAGI components
â”œâ”€â”€ logs/           # Application logs
â”œâ”€â”€ models/         # AI models
â”œâ”€â”€ monitoring/     # Prometheus, Grafana configs
â”œâ”€â”€ ollama/         # Ollama model definitions
â”œâ”€â”€ reports/        # Generated reports
â”œâ”€â”€ scripts/        # Organized scripts
â””â”€â”€ tests/          # Test suites
```

## ğŸ”§ Configuration Files

- **Docker Compose**: `config/docker/docker-compose.tinyllama.yml`
- **Makefile**: `build/make/Makefile`
- **Environment**: `.env`, `.env.tinyllama`

## ğŸ“š Documentation

- Quick Start: `docs/guides/quickstart/`
- Architecture: `docs/system/architecture/`
- Agent Specs: `.claude/agents/` (preserved)

## ğŸ¯ Key Commands

```bash
# Deployment
./scripts/deployment/system/start_tinyllama.sh

# Verification
./scripts/utils/verification/verify_tinyllama_config.sh
./scripts/utils/verification/verify_litellm_removal.sh

# Using Make (recommended)
make help       # Show all available commands
```

## ğŸ¤– System Status

- **Model**: TinyLlama (637MB)
- **API**: Native Ollama
- **Agents**: 37 specialized AI agents
- **External APIs**: None (100% local)

---

For detailed documentation, see the `docs/` directory.
