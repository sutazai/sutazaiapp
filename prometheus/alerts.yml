groups:
- name: system
  rules:
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance)(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is above 90% for 5 minutes"

  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is above 85% for 10 minutes"

- name: deployment_alerts
  rules:
  - alert: DeploymentFailed
    expr: up{job="sutazai_deployment"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Deployment failed"
      description: "The SutazAI deployment process has failed"

- name: example
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > (avg_over_time(error_rate[1h]) * 2)
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: High error rate detected
      priority: "P1"
      runbook: https://wiki/error-rate-resolution
      team: sre

- name: ai_agents
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[1m]) > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is above 5% for the last 5 minutes"

- alert: AIHighLatency
  expr: |
    histogram_quantile(0.95, sum by(le) (
      rate(ai_request_duration_seconds_bucket[5m])
    )) > 2.5
  for: 10m
  labels:
    severity: warning
  annotations:
    summary: "P95 latency above 2.5s for 10 minutes"

- name: ai-system
  rules:
  - alert: AIHighErrorRate
    expr: |
      (sum by(service, namespace) (
        rate(ai_errors_total{job="ai-service"}[5m])
      ) / 
      sum by(service, namespace) (
        rate(ai_requests_total{job="ai-service"}[5m])
      )) > 0.1
    for: 5m
    labels:
      severity: critical
      namespace: '{{ $labels.namespace }}'
    annotations:
      summary: "High AI error rate in {{ $labels.namespace }}"
      description: "AI error rate is above 10% for 5 minutes (current: {{ $value }})"
  
  - alert: AIHighMemoryUsage
    expr: process_resident_memory_bytes{job="ai_service"} > 2e9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High AI memory usage"
      description: "AI service memory usage is above 2GB for 5 minutes"

  - alert: HighLatency
    expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[1m])) > 1
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High latency detected"
      description: "99th percentile latency is above 1 second for the last 10 minutes"

- name: super-ai-agent
  rules:
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance)(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is above 90% for 5 minutes"

  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is above 80% for 5 minutes"

- alert: HighAIErrorRate
  expr: (sum(rate(ai_api_errors_total[5m])) by (service)) / (sum(rate(ai_api_requests_total[5m])) by (service)) > 0.05
  for: 10m
  labels:
    severity: critical
  annotations:
    summary: "High error rate in AI services ({{ $value }} errors/s)"
    description: "AI services experiencing elevated error rates - requires immediate investigation"

- alert: MemoryPressure
  expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 15)
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Memory pressure detected"
    description: "Available memory is below 15% for 5 minutes"

- alert: AIEngineDown
  expr: up{job="ai_engine"} == 0
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "AI Engine service down"
    description: "The AI inference engine has been down for more than 5 minutes"

- name: instance
  rules:
  - alert: HighCpuUsage
    expr: 100 - (avg by(instance)(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: critical
    annotations:
      description: 'CPU usage on {{ $labels.instance }} is {{ $value }}%'
      runbook_url: 'https://ourwiki/runbook/cpu-usage'

- Added dynamic baseline alerts for error rates 

- alert: HighErrorRate
  expr: job:request_error_rate{service="ai-service"} > 0.5
  labels:
    severity: critical
    namespace: {{ $labels.namespace }}
  annotations:
    description: AI service error rate is high 

- alert: NodeDown
  expr: up{job="node-exporter"} == 0
  labels:
    severity: critical
  annotations:
    description: "Node {{ $labels.instance }} is down" 

- alert: ServiceDependenciesDown
  expr: |
    sum by(service) (
      rate(service_dependencies_failed_total[5m])
    ) / 
    sum by(service) (
      rate(service_dependencies_total[5m])
    ) > 0.5
  for: 5m
  labels:
    severity: warning
  annotations:
    description: "Over 50% of service dependencies failing for {{ $labels.service }}" 

- alert: CriticalSystemFailure
  expr: |
    count(ALERTS{alertstate="firing", severity="critical"} > 3)
  for: 5m
  labels:
    severity: page
  annotations:
    description: "Multiple critical alerts firing simultaneously - possible system-wide failure"
    runbook: "https://wiki/incident-response" 

- alert: APILatencyDegradation
  expr: |
    (
      histogram_quantile(0.99, rate(api_request_duration_seconds_bucket[5m])) 
      - 
      histogram_quantile(0.99, rate(api_request_duration_seconds_bucket[1h] offset 1h))
    ) > 1.5
  for: 15m
  labels:
    severity: warning
  annotations:
    description: "API latency increased by 1.5s over 1 hour baseline"
    impact: "User experience degradation" 

- alert: HighPodRestarts
  expr: rate(kube_pod_container_status_restarts_total[5m]) > 0.5
  for: 5m
  annotations:
    runbook: "https://wiki/HighPodRestarts"

- alert: APIHighLatency
  expr: histogram_quantile(0.9, rate(api_request_duration_seconds_bucket[5m])) > 2
  for: 10m
  labels:
    severity: "critical"
    team: "sre"
  annotations:
    playbook: "https://wiki/HighAPILatency" 