services:
  ai-agent:
    min_replicas: 3
    max_replicas: 50
    cooldown_scale_up: 60
    cooldown_scale_down: 300
    rules:
    - metric: avg(rate(container_cpu_usage_seconds_total{service="${service}"}[1m])) * 100
      target: 70
      scale_up_threshold: 80
      scale_down_threshold: 30
      scale_up_change: 2
      scale_down_change: 1
    - metric: avg(container_memory_usage_bytes{service="${service}"} / container_spec_memory_limit_bytes{service="${service}"}) * 100
      target: 70
      scale_up_threshold: 85
      scale_down_threshold: 40
    - metric: sum(rate(celery_tasks_total{task_name=~"ai.inference.*"}[1m]))
      target: 10
      scale_up_threshold: 20
      scale_down_threshold: 5
      scale_up_change: 3
      scale_down_change: 1
  
  celery-worker-inference:
    min_replicas: 2
    max_replicas: 20
    cooldown_scale_up: 30
    cooldown_scale_down: 180
    rules:
    - metric: sum(celery_queue_length{queue_name="inference"})
      target: 50
      scale_up_threshold: 100
      scale_down_threshold: 10
      scale_up_change: 2
    - metric: avg(celery_active_tasks{queue_name="inference"})
      target: 20
      scale_up_threshold: 30
      scale_down_threshold: 5
  
  celery-worker-processing:
    min_replicas: 2
    max_replicas: 15
    cooldown_scale_up: 45
    cooldown_scale_down: 180
    rules:
    - metric: sum(celery_queue_length{queue_name="processing"})
      target: 30
      scale_up_threshold: 50
      scale_down_threshold: 5
      scale_up_change: 2
    - metric: avg(rate(celery_task_duration_seconds_sum{queue_name="processing"}[5m]))
      target: 10
      scale_up_threshold: 20
      scale_down_threshold: 5
  
  ollama:
    min_replicas: 2
    max_replicas: 10
    cooldown_scale_up: 120
    cooldown_scale_down: 600
    rules:
    - metric: avg(rate(ollama_request_duration_seconds_sum[1m]) / rate(ollama_request_duration_seconds_count[1m]))
      target: 5
      scale_up_threshold: 10
      scale_down_threshold: 2
    - metric: sum(rate(ollama_requests_total[1m]))
      target: 20
      scale_up_threshold: 40
      scale_down_threshold: 10
    - metric: avg(ollama_model_load_duration_seconds)
      target: 30
      scale_up_threshold: 60
      scale_down_threshold: 15
  
  redis-sentinel:
    min_replicas: 3
    max_replicas: 5
    cooldown_scale_up: 300
    cooldown_scale_down: 600
    rules:
    - metric: count(up{job="redis-sentinel"} == 1)
      target: 3
      scale_up_threshold: 2
      scale_down_threshold: 4
  
  traefik:
    min_replicas: 2
    max_replicas: 5
    cooldown_scale_up: 60
    cooldown_scale_down: 300
    rules:
    - metric: sum(rate(traefik_entrypoint_requests_total[1m]))
      target: 1000
      scale_up_threshold: 2000
      scale_down_threshold: 500
    - metric: histogram_quantile(0.95, rate(traefik_entrypoint_request_duration_seconds_bucket[5m]))
      target: 0.5
      scale_up_threshold: 1
      scale_down_threshold: 0.1