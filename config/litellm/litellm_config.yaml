# LiteLLM Proxy Configuration for SutazAI v17.0
# Provides OpenAI API compatibility for all local Ollama models

model_list:
  # Reasoning Models
  - model_name: deepseek-r1-8b
    litellm_params:
      model: ollama/deepseek-r1:8b
      api_base: http://ollama:11434
      
  - model_name: qwen3-8b  
    litellm_params:
      model: ollama/qwen3:8b
      api_base: http://ollama:11434
      
  # Code Generation Models
  - model_name: codellama-7b
    litellm_params:
      model: ollama/codellama:7b
      api_base: http://ollama:11434
      
  # General Purpose Models
  - model_name: llama3-2-3b
    litellm_params:
      model: ollama/llama3.2:3b
      api_base: http://ollama:11434
      
  - model_name: llama3-2-1b
    litellm_params:
      model: ollama/llama3.2:1b
      api_base: http://ollama:11434
      
  - model_name: qwen2-5-3b
    litellm_params:
      model: ollama/qwen2.5:3b
      api_base: http://ollama:11434
      
  - model_name: nomic-embed-text
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: http://ollama:11434
      
  # OpenAI Compatible Aliases
  - model_name: gpt-4
    litellm_params:
      model: ollama/deepseek-r1:8b
      api_base: http://ollama:11434
      
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: ollama/llama3.2:3b
      api_base: http://ollama:11434
      
  - model_name: text-embedding-ada-002
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: http://ollama:11434

general_settings:
  master_key: sk-local
  # Use PostgreSQL for tracking usage
  database_url: postgresql://sutazai:sutazai_password@postgres:5432/sutazai
  
  # Logging
  set_verbose: false
  json_logs: true
  
  # Cache settings
  cache:
    type: redis
    host: redis
    port: 6379
    password: redis_password
    
  # Rate limiting
  max_budget: 1000000  # Very high for local use
  budget_duration: "1mo"
  
  # Health checks
  health_check_interval: 300
  
  # Custom headers for CORS
  headers:
    Access-Control-Allow-Origin: "*"
    Access-Control-Allow-Methods: "GET, POST, PUT, DELETE, OPTIONS"
    Access-Control-Allow-Headers: "*"

# Router settings for load balancing
router_settings:
  routing_strategy: simple-shuffle
  model_group_alias:
    gpt-4: [deepseek-r1-8b]
    gpt-3.5-turbo: [llama3-2-3b, qwen2-5-3b]
    code-davinci-002: [codellama-7b]
    
# Fallback settings
fallbacks:
  - model: deepseek-r1-8b
    fallbacks: [qwen3-8b, llama3-2-3b]
  - model: qwen3-8b
    fallbacks: [deepseek-r1-8b, llama3-2-3b]
  - model: codellama-7b
    fallbacks: [llama3-2-3b]
    
# Environment variables
environment_variables:
  OLLAMA_API_BASE: http://ollama:11434
  OPENAI_API_KEY: sk-local