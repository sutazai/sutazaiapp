# NGINX Load Balancer Configuration for Ollama High-Concurrency Setup
# Optimized for 174+ concurrent AI agent connections

# Upstream configuration with multiple Ollama instances
upstream ollama_cluster {
    # Load balancing method - least_conn for even distribution
    least_conn;
    
    # Primary Ollama instance (main service)
    server localhost:11434 max_fails=3 fail_timeout=30s weight=3;
    
    # Secondary instances for scaling (will be configured later)
    # server localhost:11435 max_fails=3 fail_timeout=30s weight=2 backup;
    # server localhost:11436 max_fails=3 fail_timeout=30s weight=1 backup;
    
    # Enable keepalive connections to reduce overhead
    keepalive 100;
    keepalive_requests 1000;
    keepalive_timeout 300s;
}

# Rate limiting configuration
limit_req_zone $remote_addr zone=ollama_api:10m rate=100r/s;
limit_req_zone $remote_addr zone=ollama_burst:10m rate=500r/s;

# Connection limiting
limit_conn_zone $remote_addr zone=ollama_conn:10m;

server {
    listen 80;
    listen [::]:80;
    server_name ollama-lb.local localhost;
    
    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    
    # Access and error logs
    access_log /var/log/nginx/ollama-access.log;
    error_log /var/log/nginx/ollama-error.log warn;
    
    # Connection and request limits
    limit_conn ollama_conn 50;  # Max 50 connections per IP
    
    # Ollama API proxy with high-concurrency optimizations
    location /api/ {
        # Rate limiting with burst capability
        limit_req zone=ollama_api burst=20 nodelay;
        limit_req zone=ollama_burst burst=100 nodelay;
        
        # Proxy configuration
        proxy_pass http://ollama_cluster;
        proxy_http_version 1.1;
        
        # Connection management
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts optimized for AI inference
        proxy_connect_timeout 30s;
        proxy_send_timeout 120s;
        proxy_read_timeout 300s;  # Extended for long AI generations
        
        # Buffer settings for large responses
        proxy_buffer_size 128k;
        proxy_buffers 8 128k;
        proxy_busy_buffers_size 256k;
        proxy_temp_file_write_size 256k;
        
        # Disable buffering for streaming responses
        proxy_buffering off;
        proxy_cache off;
        
        # Health check headers
        proxy_set_header X-Forwarded-Health "check";
        
        # Error handling
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
        proxy_next_upstream_timeout 30s;
    }
    
    # Health check endpoint
    location /health {
        access_log off;
        
        proxy_pass http://ollama_cluster/api/tags;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        
        proxy_connect_timeout 5s;
        proxy_send_timeout 5s;
        proxy_read_timeout 5s;
        
        # Simple health response transformation
        proxy_hide_header Content-Type;
        add_header Content-Type application/json;
    }
    
    # Metrics endpoint for monitoring
    location /metrics {
        access_log off;
        
        # Return NGINX status in Prometheus format
        stub_status on;
        
        # Restrict access to monitoring systems
        allow 127.0.0.1;
        allow ::1;
        allow 172.16.0.0/12;  # Docker networks
        deny all;
    }
    
    # Status page for debugging
    location /status {
        access_log off;
        
        # Return basic status information
        stub_status on;
        
        # Restrict access
        allow 127.0.0.1;
        allow ::1;
        deny all;
    }
    
    # Root redirect to health check
    location = / {
        return 302 /health;
    }
    
    # Error pages
    error_page 502 503 504 /50x.html;
    location = /50x.html {
        root /usr/share/nginx/html;
        internal;
    }
}

# HTTPS configuration (optional, for production)
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    server_name ollama-lb.local;
    
    # SSL configuration (use proper certificates in production)
    ssl_certificate /etc/ssl/certs/ssl-cert-snakeoil.pem;
    ssl_certificate_key /etc/ssl/private/ssl-cert-snakeoil.key;
    
    # SSL optimizations
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # Include the same location blocks as HTTP
    include /etc/nginx/conf.d/ollama-locations.conf;
}

# Global NGINX optimizations for high concurrency
worker_processes auto;
worker_rlimit_nofile 65536;

events {
    worker_connections 8192;
    use epoll;
    multi_accept on;
}

http {
    # Connection optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 300s;
    keepalive_requests 1000;
    
    # Buffer optimizations
    client_body_buffer_size 128k;
    client_max_body_size 100m;  # Large for model uploads
    client_header_buffer_size 64k;
    large_client_header_buffers 4 64k;
    
    # Compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1000;
    gzip_types
        application/json
        application/javascript
        text/css
        text/javascript
        text/plain
        text/xml;
    
    # Logging optimizations
    access_log /var/log/nginx/access.log combined buffer=32k flush=5s;
    error_log /var/log/nginx/error.log warn;
    
    # Hide server version
    server_tokens off;
}