{
  "redis": {
    "url": "redis://localhost:6379",
    "namespace": "sutazai"
  },
  "ollama": {
    "url": "http://localhost:11434",
    "default_model": "codellama"
  },
  "system": {
    "max_concurrent_workflows": 10,
    "max_concurrent_tasks": 50,
    "heartbeat_interval": 30,
    "health_check_interval": 60
  },
  "initial_agents": [
    {
      "id": "orchestrator-001",
      "type": "orchestrator",
      "name": "Master Orchestrator",
      "description": "Primary orchestration agent for coordinating complex workflows",
      "config": {
        "model": "llama2",
        "max_concurrent_tasks": 10,
        "temperature": 0.4,
        "capabilities": ["orchestration", "communication", "reasoning", "autonomous_execution"]
      }
    },
    {
      "id": "code-generator-001", 
      "type": "code_generator",
      "name": "Primary Code Generator",
      "description": "Main code generation agent using CodeLlama model",
      "config": {
        "model": "codellama",
        "max_concurrent_tasks": 5,
        "temperature": 0.2,
        "capabilities": ["code_generation", "reasoning"]
      }
    },
    {
      "id": "code-generator-002",
      "type": "code_generator", 
      "name": "Secondary Code Generator",
      "description": "Backup code generation agent for load balancing",
      "config": {
        "model": "codellama",
        "max_concurrent_tasks": 3,
        "temperature": 0.3,
        "capabilities": ["code_generation", "reasoning"]
      }
    },
    {
      "id": "generic-agent-001",
      "type": "generic",
      "name": "Universal Assistant Alpha",
      "description": "Primary general-purpose agent for diverse tasks",
      "config": {
        "model": "llama2",
        "max_concurrent_tasks": 8,
        "temperature": 0.5,
        "capabilities": ["reasoning", "communication"]
      }
    },
    {
      "id": "generic-agent-002",
      "type": "generic", 
      "name": "Universal Assistant Beta",
      "description": "Secondary general-purpose agent for load distribution",
      "config": {
        "model": "mistral",
        "max_concurrent_tasks": 6,
        "temperature": 0.6,
        "capabilities": ["reasoning", "communication", "data_processing"]
      }
    }
  ],
  "logging": {
    "level": "INFO",
    "file": "/opt/sutazaiapp/logs/universal_agents.log",
    "max_size": "100MB",
    "backup_count": 5
  },
  "integration": {
    "autogpt": {
      "enabled": true,
      "url": "http://localhost:8000"
    },
    "crewai": {
      "enabled": true,
      "url": "http://localhost:8001"
    },
    "tabbyml": {
      "enabled": true,
      "url": "http://localhost:8080"
    },
    "litellm": {
      "enabled": true,
      "url": "http://localhost:4000"
    }
  },
  "security": {
    "enable_auth": false,
    "api_key_required": false,
    "rate_limiting": {
      "enabled": true,
      "requests_per_minute": 100
    }
  },
  "monitoring": {
    "enable_metrics": true,
    "metrics_port": 9090,
    "health_check_port": 9091
  }
}