---
# Ollama Model Configuration for SutazAI
# Using GPT-OSS as the exclusive model

default_model: "tinyllama:latest"

models:
  tinyllama:
    name: "tinyllama:latest"
    size: "8GB"
    context_window: 4096
    description: "GPT-OSS - The exclusive model for all tasks"
    pull_command: "ollama pull tinyllama:latest"
    
  # All models use GPT-OSS exclusively
  code_model: "tinyllama:latest"
  reasoning_model: "tinyllama:latest"
  chat_model: "tinyllama:latest"

# Model assignments for agents (all using tinyllama)
agent_models:
  default: "tinyllama:latest"
  
  # GPT-OSS is the exclusive model for all agents

# Resource limits
resource_config:
  max_concurrent_models: 1  # Only one model loaded at a time
  max_memory_per_model: "2GB"
  cpu_threads: 4
  gpu_layers: 0  # CPU only for now

# Model initialization script
init_commands: |
  #!/bin/bash
  echo "Pulling GPT-OSS model..."
  ollama pull tinyllama:latest
  echo "GPT-OSS ready!"
  
  # Test the model
  echo "Testing GPT-OSS..."
  ollama run tinyllama:latest "Hello, I am GPT-OSS. I am ready to help!" --verbose