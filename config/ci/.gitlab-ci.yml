# SutazAI Complete GitLab CI/CD Pipeline
# Production-grade deployment automation with comprehensive testing and security

stages:
  - validate
  - build
  - test
  - security
  - performance
  - staging
  - production
  - rollback

# Global variables
variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  DOCKER_REGISTRY: "registry.gitlab.com"
  IMAGE_PREFIX: "${CI_PROJECT_PATH}"
  KUBERNETES_VERSION: "1.28"
  HELM_VERSION: "3.13.0"
  # Agent configuration
  TOTAL_AGENTS: "69"
  AGENT_BATCH_SIZE: "10"
  # Deployment strategy
  DEPLOYMENT_STRATEGY: "blue-green"
  ROLLBACK_TIMEOUT: "300"
  # Cache settings
  FF_USE_FASTZIP: "true"
  ARTIFACT_COMPRESSION_LEVEL: "fastest"
  CACHE_COMPRESSION_LEVEL: "fastest"

# Cache configuration
cache: &global_cache
  key: "${CI_COMMIT_REF_SLUG}"
  paths:
    - .cache/pip
    - .cache/npm
    - node_modules/
    - venv/
  policy: pull-push

# Default retry policy
.default_retry: &default_retry
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
      - scheduler_failure

# ===============================
# STAGE 1: VALIDATION
# ===============================

validate:codebase:
  stage: validate
  image: python:3.12.8-slim-bookworm
  <<: *default_retry
  before_script:
    - apt-get update && apt-get install -y git
    - pip install --cache-dir .cache/pip black flake8 mypy pylint
  script:
    - echo "Validating codebase structure..."
    - python scripts/validate-container-infrastructure.py
    - echo "Checking code formatting..."
    - black --check backend/ agents/
    - flake8 backend/ agents/ --max-line-length=88 --extend-ignore=E203,W503
    - echo "Running type checks..."
    - mypy backend/app --ignore-missing-imports
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'

validate:hygiene:
  stage: validate
  image: python:3.12.8-slim-bookworm
  <<: *default_retry
  script:
    - echo "Running hygiene validation..."
    - python scripts/hygiene-enforcement-coordinator.py --mode validate
    - python scripts/agents/hygiene-agent-orchestrator.py --check
  artifacts:
    reports:
      junit: hygiene-report.xml
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'

# ===============================
# STAGE 2: BUILD
# ===============================

.build_template: &build_template
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  <<: *default_retry
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - apk add --no-cache git
    - export VERSION=$(date +%Y%m%d-%H%M%S)-${CI_COMMIT_SHORT_SHA}
    - echo "VERSION=$VERSION" >> build.env
  artifacts:
    reports:
      dotenv: build.env
    expire_in: 1 week

build:base-images:
  <<: *build_template
  script:
    - echo "Building base images..."
    - docker build -t ${CI_REGISTRY_IMAGE}/base/python:${VERSION} -f docker/base/Dockerfile.python-agent-base .
    - docker build -t ${CI_REGISTRY_IMAGE}/base/nodejs:${VERSION} -f docker/base/Dockerfile.nodejs-base .
    - docker build -t ${CI_REGISTRY_IMAGE}/base/monitoring:${VERSION} -f docker/base/Dockerfile.monitoring-base .
    - docker build -t ${CI_REGISTRY_IMAGE}/base/gpu:${VERSION} -f docker/base/Dockerfile.gpu-python-base .
    - echo "Pushing base images..."
    - docker push ${CI_REGISTRY_IMAGE}/base/python:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/base/nodejs:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/base/monitoring:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/base/gpu:${VERSION}
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    - if: '$CI_COMMIT_TAG'

build:core-services:
  <<: *build_template
  needs: ["build:base-images"]
  script:
    - echo "Building core services..."
    - docker build -t ${CI_REGISTRY_IMAGE}/coordinator:${VERSION} -f deployment/docker/Dockerfile.coordinator-core .
    - docker build -t ${CI_REGISTRY_IMAGE}/backend:${VERSION} -f backend/Dockerfile .
    - docker build -t ${CI_REGISTRY_IMAGE}/frontend:${VERSION} -f frontend/Dockerfile .
    - docker build -t ${CI_REGISTRY_IMAGE}/api-gateway:${VERSION} -f deployment/docker/Dockerfile.api-gateway .
    - echo "Pushing core services..."
    - docker push ${CI_REGISTRY_IMAGE}/coordinator:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/backend:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/frontend:${VERSION}
    - docker push ${CI_REGISTRY_IMAGE}/api-gateway:${VERSION}

build:agents:
  <<: *build_template
  needs: ["build:base-images"]
  parallel:
    matrix:
      - AGENT_GROUP: [core, specialized, research, security, monitoring]
  script:
    - echo "Building ${AGENT_GROUP} agents..."
    - |
      case ${AGENT_GROUP} in
        core)
          for agent in master analytics-coordinator code-architect db-coordinator devops-orchestrator; do
            docker build -t ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION} -f agents/${agent}/Dockerfile .
            docker push ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION}
          done
          ;;
        specialized)
          for agent in code-optimizer testing-automation documentation-master ml-engineer ui-ux-designer; do
            docker build -t ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION} -f agents/${agent}/Dockerfile .
            docker push ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION}
          done
          ;;
        research)
          for agent in research-analyst pattern-recognition quantum-optimizer nlp-specialist; do
            docker build -t ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION} -f agents/${agent}/Dockerfile .
            docker push ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION}
          done
          ;;
        security)
          for agent in security-auditor vulnerability-scanner compliance-monitor; do
            docker build -t ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION} -f agents/${agent}/Dockerfile .
            docker push ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION}
          done
          ;;
        monitoring)
          for agent in performance-monitor health-checker metrics-aggregator; do
            docker build -t ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION} -f agents/${agent}/Dockerfile .
            docker push ${CI_REGISTRY_IMAGE}/agents/${agent}:${VERSION}
          done
          ;;
      esac

# ===============================
# STAGE 3: TESTING
# ===============================

test:unit:
  stage: test
  image: python:3.12.8
  <<: *default_retry
  services:
    - postgres:15-alpine
    - redis:7-alpine
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: test_user
    POSTGRES_PASSWORD: test_pass
    REDIS_HOST: redis
  before_script:
    - pip install --cache-dir .cache/pip -r backend/requirements.txt
    - pip install --cache-dir .cache/pip pytest pytest-cov pytest-asyncio pytest-Mock
  script:
    - echo "Running unit tests..."
    - cd backend
    - pytest tests/unit/ -v --cov=app --cov-report=xml --cov-report=html --junitxml=../test-results.xml
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    when: always
    reports:
      junit: test-results.xml
      coverage_report:
        coverage_format: cobertura
        path: backend/coverage.xml
    paths:
      - backend/htmlcov/
    expire_in: 30 days

test:integration:
  stage: test
  image: docker:24-dind
  services:
    - docker:24-dind
  <<: *default_retry
  needs: ["build:core-services", "build:agents"]
  before_script:
    - apk add --no-cache docker-compose python3 py3-pip curl
    - pip3 install pytest requests
  script:
    - echo "Starting integration test environment..."
    - docker-compose -f docker-compose.test.yml up -d
    - echo "Waiting for services to be ready..."
    - sleep 60
    - echo "Running integration tests..."
    - python3 tests/integration/test_agent_communication.py
    - python3 tests/integration/test_workflow_orchestration.py
    - python3 tests/integration/test_api_endpoints.py
    - echo "Collecting test results..."
    - docker-compose -f docker-compose.test.yml logs > integration-logs.txt
  after_script:
    - docker-compose -f docker-compose.test.yml down -v
  artifacts:
    when: always
    paths:
      - integration-logs.txt
    expire_in: 7 days

test:e2e:
  stage: test
  image: mcr.microsoft.com/playwright:focal
  <<: *default_retry
  needs: ["test:integration"]
  services:
    - name: selenium/standalone-chrome:latest
      alias: selenium
  script:
    - echo "Running end-to-end tests..."
    - cd frontend
    - npm ci --cache .cache/npm
    - npm run test:e2e
  artifacts:
    when: always
    paths:
      - frontend/test-results/
      - frontend/playwright-report/
    expire_in: 7 days

test:agents:
  stage: test
  image: python:3.12.8
  <<: *default_retry
  parallel:
    matrix:
      - AGENT_BATCH: ["1-10", "11-20", "21-30", "31-40", "41-50", "51-60", "61-69"]
  script:
    - echo "Testing agent batch ${AGENT_BATCH}..."
    - python tests/agents/test_agent_batch.py --batch ${AGENT_BATCH}
  artifacts:
    reports:
      junit: agent-test-${AGENT_BATCH}.xml

# Infrastructure health smoke test (gated by variable to avoid false fails)
test:infra-health:
  stage: test
  image: python:3.12.8-slim-bookworm
  <<: *default_retry
  script:
    - python scripts/devops/check_services_health.py --ollama localhost:10104 --kong localhost:10005 --consul localhost:10006 --vector-range 10100-10103
  allow_failure: false

# ===============================
# STAGE 4: SECURITY
# ===============================

security:sast:
  stage: security
  image: python:3.12.8
  <<: *default_retry
  script:
    - pip install --cache-dir .cache/pip bandit safety semgrep
    - echo "Running SAST analysis..."
    - bandit -r backend/ agents/ -f json -o bandit-report.json
    - safety check --json > safety-report.json
    - semgrep --config=auto --json -o semgrep-report.json backend/ agents/
  artifacts:
    reports:
      sast: 
        - bandit-report.json
        - safety-report.json
        - semgrep-report.json
    expire_in: 30 days

security:container-scan:
  stage: security
  image: aquasec/trivy:latest
  <<: *default_retry
  needs: ["build:core-services", "build:agents"]
  script:
    - echo "Scanning container images..."
    - trivy image --exit-code 0 --no-progress --format json -o trivy-core.json ${CI_REGISTRY_IMAGE}/backend:${VERSION}
    - trivy image --exit-code 0 --no-progress --format json -o trivy-agents.json ${CI_REGISTRY_IMAGE}/agents/master:${VERSION}
    - trivy image --exit-code 1 --severity CRITICAL --no-progress ${CI_REGISTRY_IMAGE}/backend:${VERSION}
  artifacts:
    reports:
      container_scanning:
        - trivy-core.json
        - trivy-agents.json
    expire_in: 30 days

security:dependency-check:
  stage: security
  image: owasp/dependency-check:latest
  <<: *default_retry
  script:
    - echo "Running OWASP dependency check..."
    - /usr/share/dependency-check/bin/dependency-check.sh \
        --project "SutazAI" \
        --scan . \
        --format ALL \
        --enableExperimental \
        --out reports/
  artifacts:
    paths:
      - reports/
    expire_in: 30 days

security:license-scan:
  stage: security
  image: licensefinder/license_finder:latest
  <<: *default_retry
  script:
    - echo "Scanning licenses..."
    - license_finder --decisions-file=.license_finder.yml
  artifacts:
    reports:
      license_scanning: license-report.json

# ===============================
# STAGE 5: PERFORMANCE
# ===============================

performance:load-test:
  stage: performance
  image: grafana/k6:latest
  <<: *default_retry
  needs: ["test:integration"]
  script:
    - echo "Running load tests..."
    - k6 run tests/performance/load-test.js --out json=load-results.json
    - k6 run tests/performance/stress-test.js --out json=stress-results.json
    - k6 run tests/performance/spike-test.js --out json=spike-results.json
  artifacts:
    paths:
      - "*-results.json"
    reports:
      performance: load-results.json
    expire_in: 30 days

performance:benchmark:
  stage: performance
  image: python:3.12.8
  <<: *default_retry
  script:
    - pip install --cache-dir .cache/pip pytest-benchmark
    - echo "Running performance benchmarks..."
    - pytest tests/benchmarks/ --benchmark-only --benchmark-json=benchmark.json
  artifacts:
    paths:
      - benchmark.json
    expire_in: 30 days

# ===============================
# STAGE 6: STAGING DEPLOYMENT
# ===============================

.deployment_template: &deployment_template
  image: alpine/k8s:1.28.3
  <<: *default_retry
  before_script:
    - apk add --no-cache git curl bash
    - curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    - chmod 700 get_helm.sh
    - ./get_helm.sh
    - kubectl version --client

deploy:staging:
  <<: *deployment_template
  stage: staging
  environment:
    name: staging
    url: https://staging.sutazai.com
    on_stop: stop:staging
  needs: ["security:container-scan", "performance:load-test"]
  script:
    - echo "Deploying to staging environment..."
    - kubectl config use-context ${KUBE_CONTEXT_STAGING}
    - ./ci-cd/scripts/deploy.sh staging ${VERSION}
    - echo "Running post-deployment tests..."
    - ./ci-cd/scripts/smoke-test.sh staging
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    - if: '$CI_COMMIT_BRANCH =~ /^release\/.*$/'

stop:staging:
  <<: *deployment_template
  stage: staging
  environment:
    name: staging
    action: stop
  script:
    - echo "Stopping staging environment..."
    - kubectl config use-context ${KUBE_CONTEXT_STAGING}
    - kubectl delete namespace sutazai-staging --ignore-not-found=true
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'

# ===============================
# STAGE 7: PRODUCTION DEPLOYMENT
# ===============================

deploy:production:prepare:
  <<: *deployment_template
  stage: production
  environment:
    name: production
    url: https://sutazai.com
  needs: ["deploy:staging"]
  script:
    - echo "Preparing production deployment..."
    - ./ci-cd/scripts/pre-deploy-check.sh production
    - ./ci-cd/scripts/backup.sh production
    - echo "Creating deployment plan..."
    - ./ci-cd/scripts/generate-deployment-plan.sh ${VERSION} > deployment-plan.txt
  artifacts:
    paths:
      - deployment-plan.txt
    expire_in: 7 days
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: manual
    - if: '$CI_COMMIT_TAG'
      when: manual

deploy:production:blue-green:
  <<: *deployment_template
  stage: production
  environment:
    name: production
    url: https://sutazai.com
  needs: ["deploy:production:prepare"]
  script:
    - echo "Starting blue-green deployment..."
    - kubectl config use-context ${KUBE_CONTEXT_PRODUCTION}
    - export DEPLOYMENT_COLOR=$(./ci-cd/scripts/get-inactive-color.sh)
    - echo "Deploying to ${DEPLOYMENT_COLOR} environment..."
    - ./ci-cd/scripts/deploy-blue-green.sh ${DEPLOYMENT_COLOR} ${VERSION}
    - echo "Running health checks..."
    - ./ci-cd/scripts/health-check.sh ${DEPLOYMENT_COLOR}
    - echo "Switching traffic to ${DEPLOYMENT_COLOR}..."
    - ./ci-cd/scripts/switch-traffic.sh ${DEPLOYMENT_COLOR}
    - echo "Monitoring new deployment..."
    - ./ci-cd/scripts/monitor-deployment.sh ${DEPLOYMENT_COLOR} 300
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: manual
    - if: '$CI_COMMIT_TAG'
      when: manual

deploy:production:agents:
  <<: *deployment_template
  stage: production
  environment:
    name: production
    url: https://sutazai.com
  needs: ["deploy:production:blue-green"]
  parallel:
    matrix:
      - AGENT_BATCH: ["1-10", "11-20", "21-30", "31-40", "41-50", "51-60", "61-69"]
  script:
    - echo "Deploying agent batch ${AGENT_BATCH}..."
    - kubectl config use-context ${KUBE_CONTEXT_PRODUCTION}
    - ./ci-cd/scripts/deploy-agents.sh ${AGENT_BATCH} ${VERSION}
    - echo "Verifying agent deployment..."
    - ./ci-cd/scripts/verify-agents.sh ${AGENT_BATCH}
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: manual
    - if: '$CI_COMMIT_TAG'
      when: manual

# ===============================
# STAGE 8: ROLLBACK
# ===============================

rollback:automatic:
  <<: *deployment_template
  stage: rollback
  environment:
    name: production
    action: prepare
  needs: ["deploy:production:blue-green"]
  script:
    - echo "Automatic rollback triggered..."
    - kubectl config use-context ${KUBE_CONTEXT_PRODUCTION}
    - export CURRENT_COLOR=$(./ci-cd/scripts/get-active-color.sh)
    - export PREVIOUS_COLOR=$(./ci-cd/scripts/get-inactive-color.sh)
    - echo "Rolling back from ${CURRENT_COLOR} to ${PREVIOUS_COLOR}..."
    - ./ci-cd/scripts/switch-traffic.sh ${PREVIOUS_COLOR}
    - echo "Rollback completed"
    - ./ci-cd/scripts/notify-rollback.sh ${CI_COMMIT_SHA}
  when: on_failure
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    - if: '$CI_COMMIT_TAG'

rollback:manual:
  <<: *deployment_template
  stage: rollback
  environment:
    name: production
    action: rollback
  script:
    - echo "Manual rollback initiated..."
    - kubectl config use-context ${KUBE_CONTEXT_PRODUCTION}
    - ./ci-cd/scripts/rollback.sh ${ROLLBACK_VERSION}
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    - if: '$CI_COMMIT_TAG'

# ===============================
# MONITORING & CLEANUP
# ===============================

monitor:production:
  stage: .post
  image: curlimages/curl:latest
  script:
    - echo "Monitoring production deployment..."
    - curl -f https://sutazai.com/health || exit 1
    - curl -f https://sutazai.com/api/v1/status || exit 1
    - curl -f https://sutazai.com/api/v1/agents/health || exit 1
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
      when: on_success
    - if: '$CI_COMMIT_TAG'
      when: on_success

cleanup:old-images:
  stage: .post
  image: alpine:latest
  script:
    - echo "Cleaning up old images..."
    - apk add --no-cache curl jq
    - ./ci-cd/scripts/cleanup-registry.sh
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
