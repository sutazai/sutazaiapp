#!/usr/bin/env python3
"""
Documentation Quality Gates and Validation System
Ensures comprehensive documentation compliance and quality standards.

Features:
- CHANGELOG.md validation across all directories (Rule 18)
- Documentation completeness checking
- API documentation sync validation
- Architectural diagram accuracy verification
- Technical writing quality assessment

Version: SutazAI v93 - QA Excellence Framework
Author: QA Validation Specialist (Claude Code)
"""

import os
import sys
import json
import re
import time
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DocumentationIssue:
    """Documentation issue data structure."""
    file_path: str
    issue_type: str
    severity: str  # 'critical', 'warning', 'info'
    description: str
    line_number: Optional[int] = None
    suggestion: Optional[str] = None

@dataclass
class DocumentationReport:
    """Documentation validation report."""
    timestamp: str
    overall_score: float
    total_files_checked: int
    issues_found: int
    critical_issues: int
    warnings: int
    info_issues: int
    changelog_compliance: float
    api_doc_sync: float
    completeness_score: float
    quality_score: float
    issues: List[DocumentationIssue]
    recommendations: List[str]

class DocumentationValidator:
    """Comprehensive documentation validation system."""
    
    def __init__(self, project_root: Optional[Path] = None):
        self.project_root = project_root or Path(__file__).parent.parent.parent
        self.issues = []
        self.files_checked = 0
        
        # Required documentation files
        self.required_docs = {
            'README.md': 'Project overview and quick start guide',
            'CLAUDE.md': 'Developer guidance and system documentation',
            'CHANGELOG.md': 'Change tracking and version history',
            'IMPORTANT/Enforcement_Rules': 'System rules and standards',
        }
        
        # Directories that must have CHANGELOG.md (Rule 18)
        self.changelog_required_dirs = [
            'backend', 'frontend', 'tests', 'scripts', 'monitoring', 
            'agents', 'config', 'docker', 'database'
        ]
        
        # Documentation quality patterns
        self.quality_patterns = {
            'headers_structure': r'^#{1,6}\s+.+$',
            'code_blocks': r'```[\w]*\n[\s\S]*?\n```',
            'links': r'\[.+?\]\(.+?\)',
            'tables': r'\|.+\|',
            'lists': r'^[\s]*[-*+]\s+.+$',
        }
    
    def add_issue(self, file_path: str, issue_type: str, severity: str, 
                  description: str, line_number: Optional[int] = None, 
                  suggestion: Optional[str] = None):
        """Add a documentation issue."""
        issue = DocumentationIssue(
            file_path=str(file_path),
            issue_type=issue_type,
            severity=severity,
            description=description,
            line_number=line_number,
            suggestion=suggestion
        )
        self.issues.append(issue)
    
    def validate_changelog_compliance(self) -> float:
        """Validate CHANGELOG.md compliance across the project (Rule 18)."""
        logger.info("📋 Validating CHANGELOG.md compliance...")
        
        compliance_score = 0
        total_checks = 0
        
        # Check root CHANGELOG.md
        total_checks += 1
        root_changelog = self.project_root / "CHANGELOG.md"
        if root_changelog.exists():
            compliance_score += 1
            self._validate_changelog_format(root_changelog)
        else:\n            self.add_issue(\n                str(root_changelog),\n                'missing_changelog',\n                'critical',\n                'Root CHANGELOG.md is missing (Rule 18 violation)',\n                suggestion='Create CHANGELOG.md following Keep a Changelog format'\n            )\n        \n        # Check required directories\n        for dir_name in self.changelog_required_dirs:\n            dir_path = self.project_root / dir_name\n            if dir_path.exists() and dir_path.is_dir():\n                total_checks += 1\n                changelog_path = dir_path / "CHANGELOG.md"\n                if changelog_path.exists():\n                    compliance_score += 1\n                    self._validate_changelog_format(changelog_path)\n                else:\n                    self.add_issue(\n                        str(changelog_path),\n                        'missing_changelog',\n                        'warning',\n                        f'CHANGELOG.md missing in {dir_name}/ directory',\n                        suggestion=f'Create CHANGELOG.md in {dir_name}/ directory'\n                    )\n        \n        compliance_percentage = (compliance_score / total_checks) * 100 if total_checks > 0 else 0\n        logger.info(f"CHANGELOG compliance: {compliance_percentage:.1f}% ({compliance_score}/{total_checks})")\n        \n        return compliance_percentage\n    \n    def _validate_changelog_format(self, changelog_path: Path):\n        """Validate CHANGELOG.md format against Keep a Changelog standard."""\n        try:\n            with open(changelog_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                \n            lines = content.split('\\n')\n            \n            # Check for Keep a Changelog reference\n            has_keepachangelog_ref = any(\n                'keepachangelog.com' in line.lower() or 'keep a changelog' in line.lower() \n                for line in lines\n            )\n            \n            if not has_keepachangelog_ref:\n                self.add_issue(\n                    str(changelog_path),\n                    'format_violation',\n                    'warning',\n                    'CHANGELOG.md does not reference Keep a Changelog standard',\n                    suggestion='Add reference to https://keepachangelog.com/'\n                )\n            \n            # Check for semantic versioning reference\n            has_semver_ref = any(\n                'semver.org' in line.lower() or 'semantic versioning' in line.lower()\n                for line in lines\n            )\n            \n            if not has_semver_ref:\n                self.add_issue(\n                    str(changelog_path),\n                    'format_violation',\n                    'info',\n                    'CHANGELOG.md does not reference Semantic Versioning',\n                    suggestion='Add reference to https://semver.org/'\n                )\n            \n            # Check for proper version headers\n            version_pattern = r'^##\\s+\\[.*?\\]\\s*-\\s*\\d{4}-\\d{2}-\\d{2}'\n            version_headers = [line for line in lines if re.match(version_pattern, line)]\n            \n            if not version_headers:\n                self.add_issue(\n                    str(changelog_path),\n                    'format_violation',\n                    'warning',\n                    'No properly formatted version headers found',\n                    suggestion='Use format: ## [Version] - YYYY-MM-DD'\n                )\n            \n            # Check for recent updates (within last 30 days)\n            if changelog_path.stat().st_mtime < time.time() - (30 * 24 * 60 * 60):\n                self.add_issue(\n                    str(changelog_path),\n                    'outdated_changelog',\n                    'info',\n                    'CHANGELOG.md not updated in last 30 days',\n                    suggestion='Update CHANGELOG.md with recent changes'\n                )\n                \n        except Exception as e:\n            self.add_issue(\n                str(changelog_path),\n                'read_error',\n                'warning',\n                f'Could not read CHANGELOG.md: {e}'\n            )\n    \n    def validate_required_documentation(self) -> float:\n        """Validate presence and quality of required documentation."""\n        logger.info("📚 Validating required documentation...")\n        \n        completeness_score = 0\n        total_required = len(self.required_docs)\n        \n        for doc_path, description in self.required_docs.items():\n            full_path = self.project_root / doc_path\n            if full_path.exists():\n                completeness_score += 1\n                self._analyze_document_quality(full_path, description)\n            else:\n                self.add_issue(\n                    str(full_path),\n                    'missing_required_doc',\n                    'critical',\n                    f'Required documentation missing: {description}',\n                    suggestion=f'Create {doc_path} with comprehensive {description}'\n                )\n        \n        completeness_percentage = (completeness_score / total_required) * 100\n        logger.info(f"Documentation completeness: {completeness_percentage:.1f}% ({completeness_score}/{total_required})")\n        \n        return completeness_percentage\n    \n    def _analyze_document_quality(self, doc_path: Path, description: str):\n        """Analyze quality of a documentation file."""\n        try:\n            with open(doc_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n                \n            lines = content.split('\\n')\n            self.files_checked += 1\n            \n            # Check document length\n            if len(content.strip()) < 500:\n                self.add_issue(\n                    str(doc_path),\n                    'insufficient_content',\n                    'warning',\n                    f'Document appears too short ({len(content)} characters)',\n                    suggestion='Expand documentation with more detailed content'\n                )\n            \n            # Check for proper header structure\n            header_lines = [line for line in lines if re.match(self.quality_patterns['headers_structure'], line)]\n            if not header_lines:\n                self.add_issue(\n                    str(doc_path),\n                    'missing_headers',\n                    'warning',\n                    'No proper markdown headers found',\n                    suggestion='Add structured headers using # ## ### syntax'\n                )\n            \n            # Check for code examples (if appropriate)\n            if doc_path.name in ['README.md', 'CLAUDE.md']:\n                code_blocks = re.findall(self.quality_patterns['code_blocks'], content)\n                if not code_blocks:\n                    self.add_issue(\n                        str(doc_path),\n                        'missing_code_examples',\n                        'info',\n                        'No code examples found in technical documentation',\n                        suggestion='Add code examples to improve usability'\n                    )\n            \n            # Check for links\n            links = re.findall(self.quality_patterns['links'], content)\n            if doc_path.name == 'README.md' and len(links) < 3:\n                self.add_issue(\n                    str(doc_path),\n                    'insufficient_links',\n                    'info',\n                    'README.md has few or no links to other documentation',\n                    suggestion='Add links to other relevant documentation'\n                )\n            \n            # Check for tables (useful for API docs)\n            tables = re.findall(self.quality_patterns['tables'], content)\n            if 'API' in description and not tables:\n                self.add_issue(\n                    str(doc_path),\n                    'missing_tables',\n                    'info',\n                    'API documentation would benefit from tables',\n                    suggestion='Add tables for parameters, endpoints, responses'\n                )\n                \n        except Exception as e:\n            self.add_issue(\n                str(doc_path),\n                'read_error',\n                'warning',\n                f'Could not analyze document: {e}'\n            )\n    \n    def validate_api_documentation_sync(self) -> float:\n        """Validate API documentation is in sync with actual implementation."""\n        logger.info("🔗 Validating API documentation sync...")\n        \n        sync_score = 100.0  # Start with perfect score\n        \n        # Check if OpenAPI documentation exists\n        openapi_files = [\n            self.project_root / "docs" / "backend_openapi.json",\n            self.project_root / "IMPORTANT" / "docs" / "backend_openapi.json"\n        ]\n        \n        openapi_exists = any(f.exists() for f in openapi_files)\n        \n        if not openapi_exists:\n            self.add_issue(\n                "API Documentation",\n                'missing_openapi',\n                'warning',\n                'OpenAPI documentation not found',\n                suggestion='Generate OpenAPI docs with: make docs-api-openapi'\n            )\n            sync_score -= 30\n        \n        # Check if backend endpoints documentation exists\n        endpoints_docs = [\n            self.project_root / "docs" / "backend_endpoints.md",\n            self.project_root / "IMPORTANT" / "docs" / "backend_endpoints.md"\n        ]\n        \n        endpoints_exists = any(f.exists() for f in endpoints_docs)\n        \n        if not endpoints_exists:\n            self.add_issue(\n                "API Documentation",\n                'missing_endpoints_doc',\n                'warning',\n                'Backend endpoints documentation not found',\n                suggestion='Generate endpoints docs with: make docs-api-endpoints'\n            )\n            sync_score -= 20\n        \n        # Check API documentation freshness\n        backend_main = self.project_root / "backend" / "app" / "main.py"\n        if backend_main.exists():\n            backend_mtime = backend_main.stat().st_mtime\n            \n            for doc_file in openapi_files + endpoints_docs:\n                if doc_file.exists():\n                    doc_mtime = doc_file.stat().st_mtime\n                    if doc_mtime < backend_mtime:\n                        self.add_issue(\n                            str(doc_file),\n                            'outdated_api_doc',\n                            'warning',\n                            'API documentation older than backend code',\n                            suggestion='Regenerate API documentation'\n                        )\n                        sync_score -= 10\n        \n        logger.info(f"API documentation sync: {sync_score:.1f}%")\n        return max(0, sync_score)\n    \n    def validate_architectural_diagrams(self) -> float:\n        """Validate architectural diagrams accuracy and completeness."""\n        logger.info("🏗️ Validating architectural diagrams...")\n        \n        diagram_score = 0\n        total_expected = 0\n        \n        # Check for diagram files\n        diagram_locations = [\n            self.project_root / "IMPORTANT" / "diagrams",\n            self.project_root / "docs" / "architecture" / "diagrams",\n        ]\n        \n        diagram_files = []\n        for location in diagram_locations:\n            if location.exists():\n                diagram_files.extend(list(location.glob("*.mmd")))\n                diagram_files.extend(list(location.glob("*.md")))\n                diagram_files.extend(list(location.glob("*.plantuml")))\n        \n        # Expected diagram types\n        expected_diagrams = [\n            'system-architecture',\n            'component-overview',\n            'data-flow',\n            'deployment',\n            'network'\n        ]\n        \n        total_expected = len(expected_diagrams)\n        \n        for expected in expected_diagrams:\n            found = any(expected.lower() in f.name.lower() for f in diagram_files)\n            if found:\n                diagram_score += 1\n            else:\n                self.add_issue(\n                    "Architectural Diagrams",\n                    'missing_diagram',\n                    'info',\n                    f'Missing {expected} diagram',\n                    suggestion=f'Create {expected} diagram in IMPORTANT/diagrams/'\n                )\n        \n        # Check diagram freshness\n        docker_compose = self.project_root / "docker-compose.yml"\n        if docker_compose.exists():\n            compose_mtime = docker_compose.stat().st_mtime\n            \n            for diagram_file in diagram_files:\n                if 'docker' in diagram_file.name.lower() or 'deployment' in diagram_file.name.lower():\n                    diagram_mtime = diagram_file.stat().st_mtime\n                    if diagram_mtime < compose_mtime:\n                        self.add_issue(\n                            str(diagram_file),\n                            'outdated_diagram',\n                            'info',\n                            'Deployment diagram older than docker-compose.yml',\n                            suggestion='Update diagram to reflect current deployment'\n                        )\n        \n        diagram_percentage = (diagram_score / total_expected) * 100 if total_expected > 0 else 0\n        logger.info(f"Architectural diagrams: {diagram_percentage:.1f}% ({diagram_score}/{total_expected})")\n        \n        return diagram_percentage\n    \n    def calculate_overall_quality_score(self, changelog_score: float, completeness_score: float, \n                                       api_sync_score: float, diagram_score: float) -> float:\n        """Calculate overall documentation quality score."""\n        weights = {\n            'changelog': 0.30,  # Rule 18 compliance is critical\n            'completeness': 0.30,\n            'api_sync': 0.25,\n            'diagrams': 0.15\n        }\n        \n        overall_score = (\n            changelog_score * weights['changelog'] +\n            completeness_score * weights['completeness'] +\n            api_sync_score * weights['api_sync'] +\n            diagram_score * weights['diagrams']\n        )\n        \n        return overall_score\n    \n    def generate_recommendations(self) -> List[str]:\n        """Generate improvement recommendations based on findings."""\n        recommendations = []\n        \n        critical_issues = [i for i in self.issues if i.severity == 'critical']\n        warning_issues = [i for i in self.issues if i.severity == 'warning']\n        \n        if critical_issues:\n            recommendations.append("🚨 Address critical documentation issues immediately")\n            for issue in critical_issues[:3]:  # Top 3 critical issues\n                if issue.suggestion:\n                    recommendations.append(f"  • {issue.suggestion}")\n        \n        if warning_issues:\n            recommendations.append("⚠️ Resolve warning-level documentation issues")\n        \n        # Rule 18 specific recommendations\n        changelog_issues = [i for i in self.issues if 'changelog' in i.issue_type]\n        if changelog_issues:\n            recommendations.append("📋 Ensure CHANGELOG.md compliance in all directories (Rule 18)")\n        \n        # API documentation recommendations\n        api_issues = [i for i in self.issues if 'api' in i.issue_type or 'openapi' in i.issue_type]\n        if api_issues:\n            recommendations.append("🔗 Synchronize API documentation with implementation")\n            recommendations.append("  • Run: make docs-api to update API documentation")\n        \n        # General quality recommendations\n        if self.files_checked > 0:\n            issue_rate = len(self.issues) / self.files_checked\n            if issue_rate > 0.5:\n                recommendations.append("📝 Establish documentation review process")\n                recommendations.append("📚 Consider documentation templates for consistency")\n        \n        if not recommendations:\n            recommendations.append("🏆 Excellent! Documentation quality standards met")\n        \n        return recommendations\n    \n    def run_comprehensive_validation(self) -> DocumentationReport:\n        """Run comprehensive documentation validation."""\n        logger.info("🚀 Starting comprehensive documentation validation...")\n        \n        # Reset counters\n        self.issues = []\n        self.files_checked = 0\n        \n        # Run validation phases\n        changelog_score = self.validate_changelog_compliance()\n        completeness_score = self.validate_required_documentation()\n        api_sync_score = self.validate_api_documentation_sync()\n        diagram_score = self.validate_architectural_diagrams()\n        \n        # Calculate overall quality score\n        overall_score = self.calculate_overall_quality_score(\n            changelog_score, completeness_score, api_sync_score, diagram_score\n        )\n        \n        # Count issues by severity\n        critical_issues = len([i for i in self.issues if i.severity == 'critical'])\n        warnings = len([i for i in self.issues if i.severity == 'warning'])\n        info_issues = len([i for i in self.issues if i.severity == 'info'])\n        \n        # Generate recommendations\n        recommendations = self.generate_recommendations()\n        \n        # Create report\n        report = DocumentationReport(\n            timestamp=datetime.now(timezone.utc).isoformat(),\n            overall_score=overall_score,\n            total_files_checked=self.files_checked,\n            issues_found=len(self.issues),\n            critical_issues=critical_issues,\n            warnings=warnings,\n            info_issues=info_issues,\n            changelog_compliance=changelog_score,\n            api_doc_sync=api_sync_score,\n            completeness_score=completeness_score,\n            quality_score=diagram_score,\n            issues=self.issues,\n            recommendations=recommendations\n        )\n        \n        return report\n    \n    def save_report(self, report: DocumentationReport) -> str:\n        """Save documentation validation report."""\n        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")\n        report_file = self.project_root / f"documentation_validation_report_{timestamp}.json"\n        \n        with open(report_file, 'w') as f:\n            json.dump(asdict(report), f, indent=2)\n        \n        logger.info(f"Documentation validation report saved: {report_file}")\n        return str(report_file)\n    \n    def log_summary(self, report: DocumentationReport):\n        """Log validation summary."""\n        logger.info("="*80)\n        logger.info("📚 DOCUMENTATION VALIDATION SUMMARY")\n        logger.info("="*80)\n        logger.info(f"Overall Quality Score: {report.overall_score:.1f}%")\n        logger.info(f"Files Checked: {report.total_files_checked}")\n        logger.info(f"Issues Found: {report.issues_found}")\n        logger.info(f"  • Critical: {report.critical_issues}")\n        logger.info(f"  • Warnings: {report.warnings}")\n        logger.info(f"  • Info: {report.info_issues}")\n        logger.info(f"CHANGELOG Compliance: {report.changelog_compliance:.1f}%")\n        logger.info(f"Documentation Completeness: {report.completeness_score:.1f}%")\n        logger.info(f"API Documentation Sync: {report.api_doc_sync:.1f}%")\n        logger.info(f"Architectural Diagrams: {report.quality_score:.1f}%")\n        \n        if report.critical_issues > 0:\n            logger.error("🚨 CRITICAL ISSUES DETECTED:")\n            for issue in [i for i in report.issues if i.severity == 'critical'][:5]:\n                logger.error(f"  • {issue.description} ({issue.file_path})")\n        \n        if report.recommendations:\n            logger.info("📋 RECOMMENDATIONS:")\n            for rec in report.recommendations[:5]:\n                logger.info(f"  • {rec}")\n        \n        logger.info("="*80)

def main():\n    """Main entry point for documentation validation."""\n    import argparse\n    \n    parser = argparse.ArgumentParser(description="SutazAI Documentation Validation System")\n    parser.add_argument("--project-root", type=Path, help="Project root directory")\n    parser.add_argument("--output", type=str, help="Output report file")\n    \n    args = parser.parse_args()\n    \n    # Initialize validator\n    validator = DocumentationValidator(args.project_root)\n    \n    # Run validation\n    report = validator.run_comprehensive_validation()\n    validator.log_summary(report)\n    \n    # Save report\n    report_file = validator.save_report(report)\n    \n    if args.output:\n        with open(args.output, 'w') as f:\n            json.dump(asdict(report), f, indent=2)\n        logger.info(f"Report also saved to: {args.output}")\n    \n    # Exit with appropriate code\n    if report.critical_issues == 0:\n        sys.exit(0)\n    else:\n        sys.exit(1)

if __name__ == "__main__":\n    main()