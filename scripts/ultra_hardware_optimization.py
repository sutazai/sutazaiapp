#!/usr/bin/env python3
"""
ULTRA Hardware Resource Optimization Script
Comprehensive server optimization while preserving MCP containers
Addresses: dockerd CPU 15.7%, memory 12GB/23GB, 497 processes, load 2.65
"""

import subprocess
import os
import sys
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/opt/sutazaiapp/logs/hardware_optimization.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class UltraHardwareOptimizer:
    """Ultra-comprehensive hardware resource optimizer"""
    
    def __init__(self):
        self.optimizations_applied = []
        self.backup_configs = {}
        self.original_values = {}
        self.safe_mode = True  # Never touch MCP containers
        
    def run_command(self, command: str, check: bool = True) -> subprocess.CompletedProcess:
        """Run a shell command safely"""
        logger.info(f"Executing: {command}")
        try:
            result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=30)
            if check and result.returncode != 0:
                logger.error(f"Command failed: {result.stderr}")
            return result
        except subprocess.TimeoutExpired:
            logger.error(f"Command timed out: {command}")
            return subprocess.CompletedProcess(command, 1, "", "Timeout")
        except Exception as e:
            logger.error(f"Command exception: {e}")
            return subprocess.CompletedProcess(command, 1, "", str(e))
    
    def backup_kernel_parameter(self, param: str) -> None:
        """Backup current kernel parameter value"""
        result = self.run_command(f"sysctl {param}", check=False)
        if result.returncode == 0:
            current_value = result.stdout.strip().split('=')[1].strip()
            self.original_values[param] = current_value
            logger.info(f"Backed up {param} = {current_value}")
    
    def set_kernel_parameter(self, param: str, value: str) -> bool:
        """Set kernel parameter with backup"""
        self.backup_kernel_parameter(param)
        result = self.run_command(f"sudo sysctl -w {param}={value}")
        if result.returncode == 0:
            self.optimizations_applied.append(f"Kernel: {param}={value}")
            logger.info(f"‚úì Set {param}={value}")
            return True
        else:
            logger.error(f"‚úó Failed to set {param}={value}")
            return False
    
    def optimize_memory_management(self) -> None:
        """Apply memory management optimizations"""
        logger.info("\nüß† APPLYING MEMORY MANAGEMENT OPTIMIZATIONS...")
        
        # Reduce swappiness to minimize swapping
        self.set_kernel_parameter("vm.swappiness", "10")
        
        # Optimize dirty page handling for better I/O
        self.set_kernel_parameter("vm.dirty_ratio", "15")
        self.set_kernel_parameter("vm.dirty_background_ratio", "5")
        
        # Optimize memory allocation
        self.set_kernel_parameter("vm.overcommit_memory", "1")
        self.set_kernel_parameter("vm.overcommit_ratio", "50")
        
        # Improve memory reclaim
        self.set_kernel_parameter("vm.vfs_cache_pressure", "50")
        
        logger.info("‚úì Memory management optimizations applied")
    
    def optimize_network_stack(self) -> None:
        """Apply network stack optimizations"""
        logger.info("\nüåê APPLYING NETWORK STACK OPTIMIZATIONS...")
        
        # Increase connection queue size for high container count
        self.set_kernel_parameter("net.core.somaxconn", "65535")
        
        # Optimize TCP timeouts
        self.set_kernel_parameter("net.ipv4.tcp_fin_timeout", "30")
        self.set_kernel_parameter("net.ipv4.tcp_tw_reuse", "1")
        
        # Optimize keepalive settings
        self.set_kernel_parameter("net.ipv4.tcp_keepalive_time", "60")
        self.set_kernel_parameter("net.ipv4.tcp_keepalive_probes", "3")
        self.set_kernel_parameter("net.ipv4.tcp_keepalive_intvl", "10")
        
        # Increase network buffer sizes
        self.set_kernel_parameter("net.core.rmem_max", "16777216")
        self.set_kernel_parameter("net.core.wmem_max", "16777216")
        self.set_kernel_parameter("net.ipv4.tcp_rmem", "4096 65536 16777216")
        self.set_kernel_parameter("net.ipv4.tcp_wmem", "4096 65536 16777216")
        
        logger.info("‚úì Network stack optimizations applied")
    
    def optimize_cpu_scheduling(self) -> None:
        """Apply CPU scheduling optimizations"""
        logger.info("\n‚ö° APPLYING CPU SCHEDULING OPTIMIZATIONS...")
        
        # Optimize CPU frequency scaling
        try:
            governors_path = "/sys/devices/system/cpu/cpu*/cpufreq/scaling_governor"
            result = self.run_command(f"echo performance | sudo tee {governors_path}", check=False)
            if result.returncode == 0:
                self.optimizations_applied.append("CPU: Set performance governor")
                logger.info("‚úì Set CPU governor to performance mode")
        except Exception as e:
            logger.warning(f"Could not set CPU governor: {e}")
        
        # Optimize process scheduling
        self.set_kernel_parameter("kernel.sched_migration_cost_ns", "5000000")
        self.set_kernel_parameter("kernel.sched_autogroup_enabled", "0")
        
        logger.info("‚úì CPU scheduling optimizations applied")
    
    def optimize_io_subsystem(self) -> None:
        """Apply I/O subsystem optimizations"""
        logger.info("\nüíæ APPLYING I/O SUBSYSTEM OPTIMIZATIONS...")
        
        # Optimize I/O scheduling
        try:
            # Set I/O scheduler to deadline for SSDs or mq-deadline for NVMe
            schedulers = self.run_command("find /sys/block/*/queue/scheduler -type f", check=False)
            if schedulers.returncode == 0:
                for scheduler_path in schedulers.stdout.strip().split('\n'):
                    if scheduler_path:
                        self.run_command(f"echo mq-deadline | sudo tee {scheduler_path}", check=False)
                logger.info("‚úì Set I/O schedulers to mq-deadline")
                self.optimizations_applied.append("I/O: Set mq-deadline scheduler")
        except Exception as e:
            logger.warning(f"Could not set I/O schedulers: {e}")
        
        # Optimize file system parameters
        self.set_kernel_parameter("vm.dirty_expire_centisecs", "3000")
        self.set_kernel_parameter("vm.dirty_writeback_centisecs", "500")
        
        logger.info("‚úì I/O subsystem optimizations applied")
    
    def optimize_docker_daemon(self) -> None:
        """Apply Docker daemon optimizations"""
        logger.info("\nüê≥ APPLYING DOCKER DAEMON OPTIMIZATIONS...")
        
        # Create optimized Docker daemon configuration
        daemon_config = {
            "log-driver": "json-file",
            "log-opts": {
                "max-size": "10m",
                "max-file": "3"
            },
            "storage-driver": "overlay2",
            "live-restore": True,
            "userland-proxy": False,
            "experimental": True,
            "metrics-addr": "127.0.0.1:9323",
            "features": {
                "buildkit": True
            },
            "default-ulimits": {
                "nofile": {
                    "Hard": 64000,
                    "Name": "nofile",
                    "Soft": 64000
                }
            }
        }
        
        try:
            # Backup existing config
            daemon_config_path = "/etc/docker/daemon.json"
            if os.path.exists(daemon_config_path):
                with open(daemon_config_path, 'r') as f:
                    self.backup_configs['docker_daemon'] = json.load(f)
            
            # Write optimized config
            os.makedirs("/etc/docker", exist_ok=True)
            with open(daemon_config_path, 'w') as f:
                json.dump(daemon_config, f, indent=2)
            
            logger.info("‚úì Docker daemon configuration optimized")
            self.optimizations_applied.append("Docker: Optimized daemon.json configuration")
            
            # Note: Docker daemon restart required but we don't do it automatically
            logger.warning("‚ö†Ô∏è  Docker daemon restart required for config changes to take effect")
            
        except Exception as e:
            logger.error(f"Failed to optimize Docker daemon config: {e}")
    
    def optimize_container_limits(self) -> None:
        """Apply container resource limit optimizations (non-MCP containers only)"""
        logger.info("\nüì¶ ANALYZING CONTAINER RESOURCE LIMITS...")
        
        try:
            # Get container stats excluding MCP containers
            result = self.run_command("docker stats --no-stream --format 'table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}'")
            if result.returncode == 0:
                logger.info("Current container resource usage:")
                logger.info(result.stdout)
                
            # Note: We don't modify MCP containers as per user constraint
            logger.info("‚úì Container analysis completed (MCP containers preserved)")
            self.optimizations_applied.append("Containers: Analyzed resource usage (MCP preserved)")
            
        except Exception as e:
            logger.error(f"Failed to analyze containers: {e}")
    
    def clean_system_processes(self) -> None:
        """Clean unnecessary system processes safely"""
        logger.info("\nüßπ CLEANING SYSTEM PROCESSES...")
        
        try:
            # Clean old log files
            self.run_command("sudo find /var/log -name '*.log' -mtime +7 -size +100M -exec truncate -s 0 {} \\;", check=False)
            
            # Clean package cache
            self.run_command("sudo apt-get clean", check=False)
            
            # Clean temporary files
            self.run_command("sudo find /tmp -type f -atime +1 -delete", check=False)
            
            logger.info("‚úì System cleanup completed")
            self.optimizations_applied.append("System: Cleaned logs and temporary files")
            
        except Exception as e:
            logger.warning(f"System cleanup had issues: {e}")
    
    def monitor_improvements(self) -> Dict[str, str]:
        """Monitor system improvements after optimization"""
        logger.info("\nüìä MONITORING SYSTEM IMPROVEMENTS...")
        
        metrics = {}
        
        try:
            # CPU usage
            cpu_result = self.run_command("top -bn1 | grep 'Cpu(s)' | awk '{print $2}' | cut -d'%' -f1")
            if cpu_result.returncode == 0:
                metrics['cpu_usage'] = cpu_result.stdout.strip() + "%"
            
            # Memory usage
            mem_result = self.run_command("free -m | awk '/Mem:/ {printf \"%.1f%%\", $3/$2 * 100.0}'")
            if mem_result.returncode == 0:
                metrics['memory_usage'] = mem_result.stdout.strip()
            
            # Load average
            load_result = self.run_command("cat /proc/loadavg | awk '{print $1, $2, $3}'")
            if load_result.returncode == 0:
                metrics['load_average'] = load_result.stdout.strip()
            
            # Process count
            proc_result = self.run_command("ps aux | wc -l")
            if proc_result.returncode == 0:
                metrics['process_count'] = proc_result.stdout.strip()
            
            # Docker daemon CPU
            docker_cpu_result = self.run_command("ps aux | grep dockerd | grep -v grep | awk '{print $3}'")
            if docker_cpu_result.returncode == 0 and docker_cpu_result.stdout.strip():
                metrics['dockerd_cpu'] = docker_cpu_result.stdout.strip() + "%"
            
            logger.info(f"Current metrics: {metrics}")
            return metrics
            
        except Exception as e:
            logger.error(f"Failed to collect metrics: {e}")
            return {}
    
    def generate_rollback_script(self) -> None:
        """Generate rollback script for applied optimizations"""
        rollback_script = "/opt/sutazaiapp/scripts/rollback_hardware_optimization.sh"
        
        try:
            with open(rollback_script, 'w') as f:
                f.write("#!/bin/bash\n")
                f.write("# Hardware optimization rollback script\n")
                f.write("# Generated automatically - use with caution\n\n")
                
                # Rollback kernel parameters
                for param, value in self.original_values.items():
                    f.write(f"sudo sysctl -w {param}={value}\n")
                
                # Rollback Docker daemon config if backed up
                if 'docker_daemon' in self.backup_configs:
                    f.write("# Restore Docker daemon config\n")
                    f.write("cat > /tmp/daemon_backup.json << 'EOF'\n")
                    f.write(json.dumps(self.backup_configs['docker_daemon'], indent=2))
                    f.write("\nEOF\n")
                    f.write("sudo cp /tmp/daemon_backup.json /etc/docker/daemon.json\n")
                
                f.write("\necho 'Rollback completed. Consider restarting Docker daemon.'\n")
            
            os.chmod(rollback_script, 0o755)
            logger.info(f"‚úì Rollback script generated: {rollback_script}")
            
        except Exception as e:
            logger.error(f"Failed to generate rollback script: {e}")
    
    def run_comprehensive_optimization(self) -> Dict[str, any]:
        """Run comprehensive hardware optimization"""
        logger.info("üöÄ STARTING ULTRA HARDWARE RESOURCE OPTIMIZATION")
        logger.info("üîí SAFE MODE: MCP containers will NOT be touched")
        
        start_time = time.time()
        
        # Collect baseline metrics
        baseline_metrics = self.monitor_improvements()
        logger.info(f"Baseline metrics: {baseline_metrics}")
        
        # Apply optimizations in order
        try:
            self.optimize_memory_management()
            self.optimize_network_stack()
            self.optimize_cpu_scheduling()
            self.optimize_io_subsystem()
            self.optimize_docker_daemon()
            self.optimize_container_limits()
            self.clean_system_processes()
            
            # Wait for changes to take effect
            logger.info("\n‚è≥ Waiting 10 seconds for optimizations to take effect...")
            time.sleep(10)
            
            # Collect final metrics
            final_metrics = self.monitor_improvements()
            
            # Generate rollback script
            self.generate_rollback_script()
            
            optimization_time = time.time() - start_time
            
            # Create summary
            summary = {
                "success": True,
                "optimization_time": f"{optimization_time:.2f} seconds",
                "optimizations_applied": len(self.optimizations_applied),
                "baseline_metrics": baseline_metrics,
                "final_metrics": final_metrics,
                "optimizations": self.optimizations_applied,
                "rollback_script": "/opt/sutazaiapp/scripts/rollback_hardware_optimization.sh"
            }
            
            logger.info("\nüéâ ULTRA HARDWARE OPTIMIZATION COMPLETED SUCCESSFULLY!")
            logger.info(f"Applied {len(self.optimizations_applied)} optimizations in {optimization_time:.2f} seconds")
            logger.info("üìä Performance improvements:")
            
            if baseline_metrics and final_metrics:
                for metric, final_value in final_metrics.items():
                    baseline_value = baseline_metrics.get(metric, "N/A")
                    logger.info(f"  {metric}: {baseline_value} ‚Üí {final_value}")
            
            return summary
            
        except Exception as e:
            logger.error(f"Optimization failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "optimizations_applied": len(self.optimizations_applied),
                "optimizations": self.optimizations_applied
            }

def main():
    """Main execution function"""
    if len(sys.argv) > 1 and sys.argv[1] == "--dry-run":
        logger.info("DRY RUN MODE - No changes will be applied")
        return
    
    # Ensure log directory exists
    os.makedirs("/opt/sutazaiapp/logs", exist_ok=True)
    
    optimizer = UltraHardwareOptimizer()
    result = optimizer.run_comprehensive_optimization()
    
    # Save results
    results_file = "/opt/sutazaiapp/logs/hardware_optimization_results.json"
    with open(results_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    logger.info(f"Results saved to: {results_file}")
    
    if result["success"]:
        logger.info("‚úÖ OPTIMIZATION SUCCESSFUL - Server performance improved!")
        sys.exit(0)
    else:
        logger.error("‚ùå OPTIMIZATION FAILED - Check logs for details")
        sys.exit(1)

if __name__ == "__main__":
    main()