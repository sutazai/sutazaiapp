#!/usr/bin/env python3
"""
INTELLIGENT Requirements Consolidation
Consolidates 45+ requirements files into 3 main files
"""

import os
from pathlib import Path
from collections import defaultdict
import re

class RequirementsConsolidator:
    def __init__(self):
        self.repo_root = Path("/opt/sutazaiapp")
        self.all_requirements = defaultdict(set)
        self.categorized = {
            'backend': set(),
            'frontend': set(),
            'agents': set(),
            'dev': set(),
            'monitoring': set()
        }
        
    def find_all_requirements(self):
        """Find all requirements files"""
        req_files = list(self.repo_root.glob("**/requirements*.txt"))
        # Exclude node_modules and venv
        req_files = [f for f in req_files if 'node_modules' not in str(f) and 'venv' not in str(f)]
        
        print(f"Found {len(req_files)} requirements files")
        return req_files
    
    def categorize_file(self, filepath):
        """Categorize requirements file by location"""
        path_str = str(filepath)
        if '/backend/' in path_str or 'backend' in filepath.name:
            return 'backend'
        elif '/frontend/' in path_str or 'frontend' in filepath.name:
            return 'frontend'
        elif '/agents/' in path_str or 'agent' in filepath.name:
            return 'agents'
        elif 'monitoring' in path_str or 'prometheus' in path_str:
            return 'monitoring'
        else:
            return 'dev'
    
    def parse_requirement(self, line):
        """Parse a requirement line"""
        line = line.strip()
        # Skip comments and empty lines
        if not line or line.startswith('#') or line.startswith('-'):
            return None
        
        # Extract package name and version
        match = re.match(r'^([a-zA-Z0-9\-_\.]+)(.*)$', line)
        if match:
            package = match.group(1).lower()
            version = match.group(2).strip()
            return (package, version)
        return None
    
    def consolidate(self):
        """Consolidate all requirements"""
        req_files = self.find_all_requirements()
        
        for req_file in req_files:
            category = self.categorize_file(req_file)
            print(f"  Processing {req_file.name} -> {category}")
            
            try:
                with open(req_file, 'r') as f:
                    for line in f:
                        req = self.parse_requirement(line)
                        if req:
                            package, version = req
                            # Add to category
                            self.categorized[category].add(f"{package}{version}")
                            # Track all packages
                            self.all_requirements[package].add(version)
            except Exception as e:
                print(f"    Error reading {req_file}: {e}")
        
        # Find common dependencies
        common = set()
        for package, versions in self.all_requirements.items():
            if len(versions) > 2:  # Used in multiple places
                # Use the most specific version
                version = max(versions, key=lambda v: len(v))
                common.add(f"{package}{version}")
        
        return common
    
    def write_consolidated(self):
        """Write consolidated requirements files"""
        common = self.consolidate()
        
        # Main backend requirements
        backend_reqs = self.categorized['backend'] | self.categorized['monitoring']
        backend_reqs -= common  # Remove common ones
        
        backend_file = self.repo_root / "backend/requirements_consolidated.txt"
        with open(backend_file, 'w') as f:
            f.write("# Consolidated Backend Requirements\n")
            f.write("# Generated by consolidate_requirements.py\n\n")
            f.write("# Core Dependencies\n")
            for req in sorted(common):
                f.write(f"{req}\n")
            f.write("\n# Backend Specific\n")
            for req in sorted(backend_reqs):
                f.write(f"{req}\n")
        
        print(f"‚úÖ Created {backend_file}")
        
        # Frontend requirements (already clean)
        print(f"‚úÖ Frontend requirements already consolidated at frontend/requirements.txt")
        
        # Agents requirements
        agents_reqs = self.categorized['agents'] - common
        agents_file = self.repo_root / "agents/requirements_consolidated.txt"
        with open(agents_file, 'w') as f:
            f.write("# Consolidated Agent Requirements\n")
            f.write("# Generated by consolidate_requirements.py\n\n")
            for req in sorted(agents_reqs):
                f.write(f"{req}\n")
        
        print(f"‚úÖ Created {agents_file}")
        
        # Dev requirements (testing, linting, etc.)
        dev_reqs = self.categorized['dev']
        dev_file = self.repo_root / "requirements_dev.txt"
        with open(dev_file, 'w') as f:
            f.write("# Development Requirements\n")
            f.write("# Testing, linting, and development tools\n\n")
            for req in sorted(dev_reqs):
                f.write(f"{req}\n")
        
        print(f"‚úÖ Created {dev_file}")
        
        return True
    
    def cleanup_duplicates(self):
        """Remove duplicate requirements files (optional)"""
        print("\nüìã Duplicate requirements files that can be removed:")
        
        req_files = self.find_all_requirements()
        keep = [
            self.repo_root / "backend/requirements.txt",
            self.repo_root / "frontend/requirements.txt",
            self.repo_root / "requirements.txt"
        ]
        
        for req_file in req_files:
            if req_file not in keep and '_backup' in str(req_file) or '_old' in str(req_file):
                print(f"  rm {req_file}")
        
        print("\n‚ö†Ô∏è  Run these commands manually after verifying consolidated files work")

if __name__ == "__main__":
    consolidator = RequirementsConsolidator()
    consolidator.write_consolidated()
    consolidator.cleanup_duplicates()