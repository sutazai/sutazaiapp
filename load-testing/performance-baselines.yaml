# SutazAI Performance Baselines and SLAs
# These baselines define acceptable performance thresholds for production

system_wide_slas:
  availability: 99.9%  # Maximum 8.77 hours downtime per year
  end_to_end_latency:
    p95: 3000ms        # 95% of requests complete within 3 seconds
    p99: 5000ms        # 99% of requests complete within 5 seconds
  error_rate: 1%       # Less than 1% error rate under normal load
  concurrent_users: 1000  # Support 1000+ simultaneous users

# Individual Agent Performance Baselines
agent_performance:
  response_time:
    simple_queries:
      p95: 2000ms      # Simple queries under 2 seconds
      p99: 4000ms      # 99% under 4 seconds
    complex_queries:
      p95: 8000ms      # Complex queries under 8 seconds
      p99: 15000ms     # 99% under 15 seconds
  
  throughput:
    minimum: 100       # req/s per agent minimum
    target: 500        # req/s per agent target
    maximum: 1000      # req/s per agent burst capacity
  
  resource_utilization:
    cpu: 80%           # Maximum CPU usage per agent
    memory: 1GB        # Maximum memory per agent
    gpu_memory: 2GB    # Maximum GPU memory per agent (if applicable)
  
  specific_agents:
    ai-system-architect:
      response_time_p95: 5000ms    # Architecture tasks take longer
      throughput_min: 50           # Lower throughput for complex tasks
    
    ai-qa-team-lead:
      response_time_p95: 3000ms    # QA analysis moderate complexity
      throughput_min: 100
    
    ai-senior-backend-developer:
      response_time_p95: 4000ms    # Code generation takes time
      throughput_min: 75
    
    jarvis-voice-interface:
      response_time_p95: 1500ms    # Voice interface needs fast response
      throughput_min: 200

# Database Performance Baselines
database_performance:
  postgresql:
    connection_pool:
      max_connections: 200
      idle_connections: 20
      connection_timeout: 5000ms
    query_performance:
      simple_select_p95: 50ms
      complex_join_p95: 200ms
      insert_p95: 100ms
      update_p95: 150ms
    throughput:
      read_ops: 10000            # reads per second
      write_ops: 2000            # writes per second
  
  redis:
    operation_latency:
      get_p95: 5ms
      set_p95: 10ms
      complex_ops_p95: 50ms
    throughput:
      operations_per_second: 50000
    memory_usage: 2GB
  
  neo4j:
    query_performance:
      simple_match_p95: 100ms
      complex_traversal_p95: 1000ms
      write_ops_p95: 200ms
    concurrent_connections: 100
    memory_usage: 4GB
  
  vector_databases:
    chromadb:
      search_latency_p95: 200ms
      index_time_p95: 500ms
      throughput: 1000           # searches per second
    
    qdrant:
      search_latency_p95: 150ms
      index_time_p95: 300ms
      throughput: 1500           # searches per second

# API Gateway Performance
api_gateway:
  throughput:
    requests_per_second: 10000
    concurrent_connections: 5000
  
  latency:
    routing_overhead: 10ms      # Additional latency from gateway
    rate_limit_check: 5ms       # Time to check rate limits
    auth_validation: 20ms       # Time to validate authentication
  
  rate_limiting:
    default_limit: 1000         # requests per minute per user
    burst_limit: 100            # requests per second burst
    premium_limit: 5000         # requests per minute for premium users
  
  availability: 99.95%          # Higher availability for gateway

# Service Mesh Performance
service_mesh:
  communication_overhead: 5ms   # Additional latency from mesh
  circuit_breaker:
    failure_threshold: 50%      # Open circuit at 50% failure rate
    timeout: 30s                # Request timeout
    recovery_time: 60s          # Time before trying to close circuit
  
  retry_policy:
    max_retries: 3
    initial_delay: 100ms
    backoff_multiplier: 2
    max_delay: 10s
  
  load_balancing:
    algorithm: "round_robin"
    health_check_interval: 10s
    unhealthy_threshold: 3

# Monitoring and Observability
monitoring:
  metrics_collection:
    interval: 15s               # Metrics collection frequency
    retention: 30d              # Metrics retention period
  
  alerting:
    response_time: 2s           # Alert delivery time
    notification_channels:
      - email
      - slack
      - webhook
  
  logging:
    ingestion_rate: 10000       # logs per second
    query_latency_p95: 500ms
    retention: 90d

# Load Testing Thresholds
load_test_criteria:
  baseline_load:
    concurrent_users: 50
    duration: 300s              # 5 minutes
    ramp_up_time: 60s
    acceptable_failure_rate: 0.1%
  
  normal_load:
    concurrent_users: 200
    duration: 900s              # 15 minutes
    ramp_up_time: 120s
    acceptable_failure_rate: 0.5%
  
  peak_load:
    concurrent_users: 500
    duration: 600s              # 10 minutes
    ramp_up_time: 180s
    acceptable_failure_rate: 1%
  
  stress_load:
    concurrent_users: 1000
    duration: 300s              # 5 minutes
    ramp_up_time: 300s
    acceptable_failure_rate: 5%
  
  spike_load:
    baseline_users: 100
    spike_users: 1000
    spike_duration: 60s
    acceptable_failure_rate: 10%

# Breaking Point Identification
breaking_point_tests:
  cpu_exhaustion:
    target_utilization: 95%
    duration: 300s
    recovery_time_max: 120s
  
  memory_exhaustion:
    target_utilization: 90%
    duration: 180s
    recovery_time_max: 60s
  
  connection_exhaustion:
    max_connections_test: true
    recovery_graceful: true
  
  disk_io_saturation:
    target_iops: 10000
    duration: 600s
    degradation_threshold: 50%

# Environment-Specific Baselines
environments:
  development:
    scale_factor: 0.1           # 10% of production load
    relaxed_slas: true
    extended_timeouts: true
  
  staging:
    scale_factor: 0.5           # 50% of production load
    production_like_slas: true
    full_integration_tests: true
  
  production:
    scale_factor: 1.0           # Full production baselines
    strict_slas: true
    business_hours_priority: true

# Hardware Resource Baselines
hardware_requirements:
  minimum:
    cpu_cores: 8
    ram_gb: 16
    disk_gb: 100
    network_mbps: 1000
  
  recommended:
    cpu_cores: 16
    ram_gb: 32
    disk_gb: 500
    network_mbps: 10000
  
  optimal:
    cpu_cores: 32
    ram_gb: 64
    disk_gb: 1000
    network_mbps: 10000
    gpu_vram_gb: 8              # For AI model inference

# Scaling Thresholds
autoscaling:
  scale_up_triggers:
    cpu_threshold: 70%
    memory_threshold: 80%
    response_time_p95: 2000ms
    queue_length: 100
  
  scale_down_triggers:
    cpu_threshold: 30%
    memory_threshold: 40%
    response_time_p95: 500ms
    queue_length: 10
  
  scaling_policies:
    max_instances: 20
    min_instances: 2
    scale_up_cooldown: 300s
    scale_down_cooldown: 600s