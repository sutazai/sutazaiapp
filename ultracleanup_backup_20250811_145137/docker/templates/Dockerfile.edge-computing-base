# ============================================================================
# SUTAZAI MASTER TEMPLATE: Edge Computing Base
# ============================================================================
# Purpose: Production-ready edge computing service
# Security: Non-root user, edge-optimized security
# Performance: Minimal footprint, low-latency processing
# Compatibility: IoT, edge AI, distributed computing
# Author: ULTRA DEPLOYMENT ENGINEER
# Date: August 10, 2025
# Version: v1.0.0
# ============================================================================

FROM alpine:3.19 as base

# ============================================================================
# EDGE-OPTIMIZED SYSTEM CONFIGURATION
# ============================================================================

# Install minimal edge computing dependencies
RUN apk add --no-cache \
        python3 \
        python3-dev \
        py3-pip \
        curl \
        ca-certificates \
        build-base \
        linux-headers \
        && python3 -m pip install --upgrade pip --no-cache-dir

# Create edge user
RUN addgroup -g 1000 -S edge && \
    adduser -u 1000 -S edge -G edge

# ============================================================================
# EDGE COMPUTING DEPENDENCIES
# ============================================================================

WORKDIR /app

# Install lightweight edge dependencies
RUN pip3 install --no-cache-dir \
        fastapi==0.104.1 \
        uvicorn==0.24.0 \
        pydantic==2.5.1 \
        aiofiles==23.2.1 \
        aiohttp==3.9.1 \
        redis==5.0.1 \
        numpy==1.26.4 \
        structlog==23.2.0 \
        prometheus-client==0.19.0

# Create edge service application
RUN cat > /app/edge_service.py << 'EOF'
"""Edge Computing Service"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio
import time
import logging
import json
from typing import Dict, Any

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="SutazAI Edge Service",
    version="1.0.0",
    description="Edge computing service for distributed processing"
)

# Data models
class EdgeData(BaseModel):
    sensor_id: str
    timestamp: float
    data: Dict[str, Any]
    location: str = "edge"

class ProcessingResult(BaseModel):
    processed_data: Dict[str, Any]
    processing_time: float
    edge_node: str = "local"

# In-memory data store for edge caching
edge_cache = {}
processing_stats = {
    "requests_processed": 0,
    "average_processing_time": 0.0,
    "cache_hits": 0
}

@app.get("/health")
async def health_check():
    """Edge service health check"""
    return {
        "status": "healthy",
        "service": "edge-computing",
        "timestamp": time.time(),
        "stats": processing_stats
    }

@app.post("/process", response_model=ProcessingResult)
async def process_edge_data(data: EdgeData):
    """Process data at the edge"""
    start_time = time.time()
    
    try:
        # Check cache first
        cache_key = f"{data.sensor_id}_{hash(str(data.data))}"
        if cache_key in edge_cache:
            processing_stats["cache_hits"] += 1
            result = edge_cache[cache_key]
            result["from_cache"] = True
            return ProcessingResult(**result)
        
        # Process data (simulate edge processing)
        processed_data = {
            "sensor_id": data.sensor_id,
            "processed_value": sum(v for v in data.data.values() if isinstance(v, (int, float))),
            "timestamp": data.timestamp,
            "location": data.location,
            "processed_at": time.time()
        }
        
        processing_time = time.time() - start_time
        
        result = {
            "processed_data": processed_data,
            "processing_time": processing_time,
            "edge_node": "local"
        }
        
        # Cache result
        edge_cache[cache_key] = result
        
        # Update stats
        processing_stats["requests_processed"] += 1
        processing_stats["average_processing_time"] = (
            processing_stats["average_processing_time"] + processing_time
        ) / 2
        
        return ProcessingResult(**result)
        
    except Exception as e:
        logger.error(f"Processing error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/stats")
async def get_stats():
    """Get edge processing statistics"""
    return {
        "stats": processing_stats,
        "cache_size": len(edge_cache),
        "uptime": time.time()
    }

@app.delete("/cache")
async def clear_cache():
    """Clear edge cache"""
    global edge_cache
    cache_size = len(edge_cache)
    edge_cache.clear()
    return {"message": f"Cache cleared, removed {cache_size} entries"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
EOF

# Create IoT data simulator
RUN cat > /app/iot_simulator.py << 'EOF'
"""IoT Data Simulator for Edge Testing"""
import asyncio
import aiohttp
import json
import time
import random
from datetime import datetime

class IoTSimulator:
    def __init__(self, edge_endpoint="http://localhost:8000"):
        self.edge_endpoint = edge_endpoint
        self.sensors = ["temp_01", "humidity_01", "pressure_01", "motion_01"]
    
    def generate_sensor_data(self, sensor_id):
        """Generate simulated sensor data"""
        data_types = {
            "temp": lambda: random.uniform(20.0, 30.0),
            "humidity": lambda: random.uniform(30.0, 80.0),
            "pressure": lambda: random.uniform(990.0, 1020.0),
            "motion": lambda: random.choice([0, 1])
        }
        
        sensor_type = sensor_id.split("_")[0]
        return {
            "sensor_id": sensor_id,
            "timestamp": time.time(),
            "data": {
                "value": data_types.get(sensor_type, lambda: random.random())()
            },
            "location": "edge_node_1"
        }
    
    async def send_data(self, session, data):
        """Send data to edge service"""
        try:
            async with session.post(f"{self.edge_endpoint}/process", json=data) as response:
                result = await response.json()
                print(f"Processed {data['sensor_id']}: {result['processing_time']:.4f}s")
        except Exception as e:
            print(f"Error sending data: {e}")
    
    async def run_simulation(self, duration=60, interval=1):
        """Run IoT simulation"""
        print(f"Starting IoT simulation for {duration} seconds...")
        async with aiohttp.ClientSession() as session:
            start_time = time.time()
            while time.time() - start_time < duration:
                tasks = []
                for sensor_id in self.sensors:
                    data = self.generate_sensor_data(sensor_id)
                    task = self.send_data(session, data)
                    tasks.append(task)
                
                await asyncio.gather(*tasks)
                await asyncio.sleep(interval)
        
        print("Simulation completed")

if __name__ == "__main__":
    simulator = IoTSimulator()
    asyncio.run(simulator.run_simulation())
EOF

# ============================================================================
# EDGE DEPLOYMENT CONFIGURATION
# ============================================================================

# Create deployment scripts
RUN cat > /app/deploy_edge.sh << 'EOF'
#!/bin/sh
# Edge deployment script
set -e

echo "Deploying edge computing service..."

# Check system resources
MEM_AVAILABLE=$(free -m | awk 'NR==2{printf "%.1f", $7*100/$2}')
DISK_AVAILABLE=$(df -h / | awk 'NR==2{print $4}')

echo "Memory available: ${MEM_AVAILABLE}%"
echo "Disk available: ${DISK_AVAILABLE}"

# Start edge service
if [ "$DEPLOYMENT_MODE" = "production" ]; then
    echo "Starting in production mode..."
    exec uvicorn edge_service:app --host 0.0.0.0 --port 8000 --workers 1
else
    echo "Starting in development mode..."
    exec uvicorn edge_service:app --host 0.0.0.0 --port 8000 --reload
fi
EOF

RUN chmod +x /app/deploy_edge.sh

# ============================================================================
# APPLICATION SETUP
# ============================================================================

# Set ownership and permissions
RUN chown -R edge:edge /app

# Switch to edge user
USER edge

# ============================================================================
# HEALTH CHECK & MONITORING
# ============================================================================

HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ============================================================================
# RUNTIME CONFIGURATION
# ============================================================================

EXPOSE 8000

ENV DEPLOYMENT_MODE=production \
    EDGE_NODE_ID=edge_01 \
    LOG_LEVEL=INFO \
    CACHE_SIZE_LIMIT=1000

VOLUME ["/app/data", "/app/cache"]

# Default command
CMD ["/app/deploy_edge.sh"]

# ============================================================================
# TEMPLATE USAGE INSTRUCTIONS
# ============================================================================
#
# To use this template:
#
# Basic edge service:
# docker build -t edge-service .
# docker run -p 8000:8000 edge-service
#
# With IoT simulation:
# docker run edge-service python iot_simulator.py
#
# Production deployment:
# docker run -e DEPLOYMENT_MODE=production \
#            -e EDGE_NODE_ID=edge_production_01 \
#            -v edge-data:/app/data \
#            -p 8000:8000 edge-service
#
# Features:
# - Ultra-lightweight Alpine base (~50MB)
# - Edge-optimized processing with caching
# - IoT data simulation for testing
# - Real-time processing statistics
# - Minimal resource footprint
# - Non-root execution for security
# - Health monitoring and metrics
#
# API Endpoints:
# - POST /process - Process edge data
# - GET /health - Health check
# - GET /stats - Processing statistics
# - DELETE /cache - Clear edge cache
#
# Use Cases:
# - IoT data processing at the edge
# - Real-time sensor data analysis
# - Distributed computing nodes
# - Edge AI inference
# - Low-latency data processing
# ============================================================================